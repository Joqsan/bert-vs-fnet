{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J9Q70KRp_IW",
        "outputId": "2218cee3-bcbd-4f74-9e2c-776474aa7357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 30 12:31:49 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    26W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1c3ddF4bzxq",
        "outputId": "ab9a5884-b7b1-4f9e-d834-f3b6a4f032c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bert-vs-fnet'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 19 (delta 1), reused 19 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), 10.04 KiB | 2.51 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Joqsan/bert-vs-fnet.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create .env file\n",
        "\n",
        "This file is necessary to make work model checkpointing (with HugginFace) and logging and reporting (with WandB).\n",
        "\n",
        "In `.env` file include the following environment variables:\n",
        "\n",
        "- `write_hub_token`: your HF write-access token.\n",
        "- `WANDB_SILENT`: whether you want to print wandb logs in the terminal (we do want that).\n",
        "- `WANDB_API_KEY`: your wandb API key.\n",
        "- `WANDB_PROJECT`: a project name the reports will be under.\n",
        "- `WANDB_LOG_MODEL`: whether to save the models to wandb as artifacts\n",
        "\n",
        "For example:\n",
        "\n",
        "```bash\n",
        "# .env\n",
        "write_hub_token=hf_aCsG...kjF\n",
        "WANDB_SILENT=false # set to true if silent\n",
        "WANDB_API_KEY=6eff...fgF\n",
        "WANDB_PROJECT=comparison-bert-fnet\n",
        "WANDB_LOG_MODEL=true\n",
        "```"
      ],
      "metadata": {
        "id": "iqgOQFYZUtJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Run this cell to upload the `.env` file.\n",
        "#@markdown ----\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "WORKING_DIR = '/content/bert-vs-fnet'\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "  if filename == '.env':\n",
        "      print('\u001b[1;32m====> Done, .env file uploaded')\n",
        "      shutil.move(filename, WORKING_DIR)\n",
        "      print('\u001b[1;32m====> .env file move to', WORKING_DIR)\n",
        "\n",
        "      os.chdir('/content/bert-vs-fnet')\n",
        "      print('\u001b[1;32m====> New current working directory:', os.getcwd())\n",
        "  else:\n",
        "    ValueError(\"Run cell again to upload .env file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "cellView": "form",
        "id": "kxLGKX82nSRG",
        "outputId": "7ca5fa4e-1759-41e5-e4c4-aed14810daa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fcf4eefc-9367-4e71-8c89-4ac55c01a9c1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fcf4eefc-9367-4e71-8c89-4ac55c01a9c1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving .env to .env\n",
            "\u001b[1;32m====> Done, .env file uploaded\n",
            "\u001b[1;32m====> .env file move to /content/bert-vs-fnet\n",
            "\u001b[1;32m====> New current working directory: /content/bert-vs-fnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOwC8fw2cPUx",
        "outputId": "30136848-2f78-4b2d-8ef3-f7cfa8bb2ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers@ git+https://github.com/Joqsan/transformers.git@823bb6e0f821420a225fb4dcfb8ef7a9dcbcd28b\n",
            "  Cloning https://github.com/Joqsan/transformers.git (to revision 823bb6e0f821420a225fb4dcfb8ef7a9dcbcd28b) to /tmp/pip-install-1pzft9_x/transformers_90bed51f0bfb4c65bf6c70c16ef64149\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Joqsan/transformers.git /tmp/pip-install-1pzft9_x/transformers_90bed51f0bfb4c65bf6c70c16ef64149\n",
            "  Running command git rev-parse -q --verify 'sha^823bb6e0f821420a225fb4dcfb8ef7a9dcbcd28b'\n",
            "  Running command git fetch -q https://github.com/Joqsan/transformers.git 823bb6e0f821420a225fb4dcfb8ef7a9dcbcd28b\n",
            "  Running command git checkout -q 823bb6e0f821420a225fb4dcfb8ef7a9dcbcd28b\n",
            "  Resolved https://github.com/Joqsan/transformers.git to commit 823bb6e0f821420a225fb4dcfb8ef7a9dcbcd28b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp==3.8.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (3.8.3)\n",
            "Requirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: appdirs==1.4.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: async-timeout==4.0.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (4.0.2)\n",
            "Requirement already satisfied: attrs==22.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (22.2.0)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer==2.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (2.1.1)\n",
            "Collecting click==8.1.3\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.9.0\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill==0.3.6 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (0.3.6)\n",
            "Collecting docker-pycreds==0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting environs==9.5.0\n",
            "  Downloading environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: filelock==3.9.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (3.9.0)\n",
            "Requirement already satisfied: frozenlist==1.3.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (1.3.3)\n",
            "Collecting fsspec==2023.1.0\n",
            "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb==4.0.10\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython==3.1.30\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.12.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==3.4\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: marshmallow==3.19.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 20)) (3.19.0)\n",
            "Requirement already satisfied: multidict==6.0.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 21)) (6.0.4)\n",
            "Collecting multiprocess==0.70.14\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.24.1\n",
            "  Downloading numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.0\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools==0.1.2\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf==4.21.12\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 KB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil==5.9.4\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow==11.0.0\n",
            "  Downloading pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 30)) (2.8.2)\n",
            "Collecting python-dotenv==0.21.1\n",
            "  Downloading python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
            "Collecting pytz==2022.7.1\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 KB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 33)) (6.0)\n",
            "Collecting regex==2022.10.31\n",
            "  Downloading regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 KB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.28.2\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses==0.18.0\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting sentry-sdk==1.14.0\n",
            "  Downloading sentry_sdk-1.14.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle==1.3.2\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting six==1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting smmap==5.0.0\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting tokenizers==0.13.2\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 42)) (4.64.1)\n",
            "Requirement already satisfied: typing_extensions==4.4.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 44)) (4.4.0)\n",
            "Collecting urllib3==1.26.14\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb==0.13.9\n",
            "  Downloading wandb-0.13.9-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash==3.2.0\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: yarl==1.8.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 48)) (1.8.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.9.0->-r requirements.txt (line 9)) (2022.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb==0.13.9->-r requirements.txt (line 46)) (57.4.0)\n",
            "Building wheels for collected packages: pathtools, transformers\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=9d2e7cc5eab7c4e89efb08e0913d43ffdb1c6725c2873ccf210d290c53a5192f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.27.0.dev0-py3-none-any.whl size=6399337 sha256=946a9610dd67228d24802d86d16ce6526a449d9d65ff385dc4786858c34fd3af\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/32/a2/49ab1c35051d8784b5bdd5a3d534903dcfa5ffee828ef1e723\n",
            "Successfully built pathtools transformers\n",
            "Installing collected packages: tokenizers, pytz, pathtools, xxhash, urllib3, smmap, six, setproctitle, regex, python-dotenv, psutil, protobuf, packaging, numpy, multiprocess, idna, fsspec, click, sentry-sdk, requests, pyarrow, gitdb, docker-pycreds, responses, pandas, huggingface-hub, GitPython, environs, wandb, transformers, datasets\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.7\n",
            "    Uninstalling pytz-2022.7:\n",
            "      Successfully uninstalled pytz-2022.7\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.6.2\n",
            "    Uninstalling regex-2022.6.2:\n",
            "      Successfully uninstalled regex-2022.6.2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2022.11.0\n",
            "    Uninstalling fsspec-2022.11.0:\n",
            "      Successfully uninstalled fsspec-2022.11.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\n",
            "tensorflow-metadata 1.12.0 requires protobuf<4,>=3.13, but you have protobuf 4.21.12 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.1 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\n",
            "google-cloud-bigquery 3.4.1 requires packaging<22.0.0dev,>=14.3, but you have packaging 23.0 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.30 click-8.1.3 datasets-2.9.0 docker-pycreds-0.4.0 environs-9.5.0 fsspec-2023.1.0 gitdb-4.0.10 huggingface-hub-0.12.0 idna-3.4 multiprocess-0.70.14 numpy-1.24.1 packaging-23.0 pandas-1.5.3 pathtools-0.1.2 protobuf-4.21.12 psutil-5.9.4 pyarrow-11.0.0 python-dotenv-0.21.1 pytz-2022.7.1 regex-2022.10.31 requests-2.28.2 responses-0.18.0 sentry-sdk-1.14.0 setproctitle-1.3.2 six-1.16.0 smmap-5.0.0 tokenizers-0.13.2 transformers-4.27.0.dev0 urllib3-1.26.14 wandb-0.13.9 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary for overwriting the protobuf installation above (not compatible with colab)\n",
        "!pip install protobuf==3.20.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrgG-SiwDDso",
        "outputId": "81ddc0cd-7248-4173-ff4c-1f68cad4c37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.20.*\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.21.12\n",
            "    Uninstalling protobuf-4.21.12:\n",
            "      Successfully uninstalled protobuf-4.21.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "google-cloud-bigquery 3.4.1 requires packaging<22.0.0dev,>=14.3, but you have packaging 23.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/fine_tuning.py bert-base-uncased cola"
      ],
      "metadata": {
        "id": "sSps_IXvByqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46e30ba-3549-4665-ad6d-d9ef21474b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 3.57kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 193kB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:02<00:00, 85.0kB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 466k/466k [00:04<00:00, 115kB/s]\n",
            "Downloading builder script: 100% 28.8k/28.8k [00:00<00:00, 128kB/s] \n",
            "Downloading metadata: 100% 28.7k/28.7k [00:00<00:00, 129kB/s] \n",
            "Downloading readme: 100% 27.9k/27.9k [00:00<00:00, 123kB/s] \n",
            "Downloading and preparing dataset glue/cola to /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n",
            "Downloading data: 100% 377k/377k [00:00<00:00, 429kB/s]\n",
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 1008.00it/s]\n",
            "100% 9/9 [00:00<00:00, 20.17ba/s]\n",
            "100% 2/2 [00:00<00:00, 53.36ba/s]\n",
            "100% 2/2 [00:00<00:00, 55.36ba/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 440M/440M [00:11<00:00, 39.9MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "models/fine_tuning.py:86: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"glue\", actual_task)\n",
            "Downloading builder script: 5.76kB [00:00, 5.34MB/s]       \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoqsan-a\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/bert-vs-fnet/wandb/run-20230130_123450-n459wguu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbert-base-uncased-cola\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/n459wguu\u001b[0m\n",
            "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Cloning https://huggingface.co/Joqsan/bert-base-uncased-finetuned-cola into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/Joqsan/bert-base-uncased-finetuned-cola into local empty directory.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Download file pytorch_model.bin:   0% 58.4k/418M [00:01<2:54:02, 41.9kB/s]\n",
            "Download file training_args.bin: 100% 3.50k/3.50k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Download file pytorch_model.bin:  99% 415M/418M [00:52<00:00, 8.13MB/s]\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   0% 1.00k/418M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   0% 33.0k/418M [00:01<3:42:54, 32.7kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   2% 6.50M/418M [00:02<01:47, 4.00MB/s]  \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   3% 14.0M/418M [00:03<01:13, 5.76MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   5% 21.6M/418M [00:04<01:02, 6.62MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   7% 29.5M/418M [00:05<00:56, 7.20MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   9% 37.6M/418M [00:06<00:52, 7.66MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  11% 46.0M/418M [00:07<00:48, 8.01MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  13% 54.1M/418M [00:08<00:46, 8.16MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  15% 61.8M/418M [00:09<00:45, 8.12MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  17% 69.8M/418M [00:10<00:44, 8.20MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  19% 77.4M/418M [00:11<00:43, 8.14MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  20% 85.3M/418M [00:12<00:42, 8.16MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  22% 93.1M/418M [00:13<00:41, 8.15MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  24% 101M/418M [00:14<00:40, 8.27MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Download file pytorch_model.bin: 100% 418M/418M [01:08<00:00, 8.13MB/s]\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  28% 117M/418M [00:16<00:37, 8.37MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  29% 123M/418M [00:17<00:40, 7.69MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  31% 132M/418M [00:18<00:37, 7.99MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  34% 140M/418M [00:19<00:35, 8.27MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  36% 149M/418M [00:20<00:33, 8.49MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  38% 157M/418M [00:21<00:31, 8.59MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  39% 165M/418M [00:22<00:31, 8.35MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  41% 173M/418M [00:23<00:30, 8.39MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  43% 181M/418M [00:24<00:29, 8.46MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  45% 189M/418M [00:25<00:28, 8.50MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  47% 197M/418M [00:26<00:27, 8.49MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  49% 204M/418M [00:27<00:27, 8.03MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  51% 212M/418M [00:28<00:25, 8.29MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  53% 221M/418M [00:29<00:24, 8.41MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  55% 229M/418M [00:30<00:23, 8.45MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  57% 237M/418M [00:31<00:22, 8.50MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  59% 245M/418M [00:32<00:21, 8.37MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  61% 253M/418M [00:33<00:20, 8.50MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  63% 262M/418M [00:34<00:18, 8.63MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  65% 270M/418M [00:35<00:17, 8.75MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  67% 279M/418M [00:36<00:16, 8.68MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  68% 285M/418M [00:37<00:16, 8.17MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  70% 294M/418M [00:38<00:15, 8.34MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  72% 302M/418M [00:39<00:14, 8.48MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  74% 311M/418M [00:40<00:13, 8.62MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  76% 319M/418M [00:41<00:11, 8.70MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  78% 327M/418M [00:42<00:11, 8.57MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  80% 335M/418M [00:43<00:09, 8.64MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  82% 344M/418M [00:44<00:08, 8.72MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  84% 352M/418M [00:45<00:07, 8.72MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  86% 360M/418M [00:46<00:06, 8.63MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  88% 367M/418M [00:47<00:06, 8.11MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  90% 375M/418M [00:48<00:05, 8.32MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  92% 384M/418M [00:49<00:04, 8.47MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  94% 392M/418M [00:50<00:03, 8.61MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  96% 401M/418M [00:51<00:02, 8.71MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Download file pytorch_model.bin: 100% 418M/418M [01:46<00:00, 4.12MB/s]\n",
            "\n",
            "Download file training_args.bin: 100% 3.50k/3.50k [01:45<?, ?B/s]\u001b[A\n",
            "Download file training_args.bin: 100% 3.50k/3.50k [01:45<?, ?B/s]\n",
            "\n",
            "\n",
            "Clean file training_args.bin: 100% 3.50k/3.50k [01:45<00:00, 24.3B/s]\u001b[A\u001b[A\n",
            "\n",
            "Clean file training_args.bin: 100% 3.50k/3.50k [01:45<00:00, 24.3B/s]\n",
            "\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin: 100% 418M/418M [00:53<00:00, 8.81MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin: 100% 418M/418M [00:53<00:00, 8.24MB/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2675\n",
            "  Number of trainable parameters = 109483778\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "  0% 0/2675 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.4982, 'learning_rate': 1.6261682242990654e-05, 'epoch': 0.93}\n",
            " 20% 534/2675 [00:58<03:46,  9.46it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            "  9% 6/66 [00:00<00:01, 51.04it/s]\u001b[A\n",
            " 18% 12/66 [00:00<00:01, 52.46it/s]\u001b[A\n",
            " 27% 18/66 [00:00<00:00, 54.46it/s]\u001b[A\n",
            " 36% 24/66 [00:00<00:00, 52.36it/s]\u001b[A\n",
            " 45% 30/66 [00:00<00:00, 49.42it/s]\u001b[A\n",
            " 53% 35/66 [00:00<00:00, 48.65it/s]\u001b[A\n",
            " 61% 40/66 [00:00<00:00, 44.23it/s]\u001b[A\n",
            " 68% 45/66 [00:00<00:00, 41.08it/s]\u001b[A\n",
            " 77% 51/66 [00:01<00:00, 44.01it/s]\u001b[A\n",
            " 86% 57/66 [00:01<00:00, 47.62it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.5117807984352112, 'eval_matthews_correlation': 0.5080190295389491, 'eval_runtime': 1.3848, 'eval_samples_per_second': 753.173, 'eval_steps_per_second': 47.66, 'epoch': 1.0}\n",
            " 20% 535/2675 [01:00<03:46,  9.46it/s]\n",
            "100% 66/66 [00:01<00:00, 51.13it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-cola/checkpoint-535\n",
            "Configuration saved in bert-base-uncased-finetuned-cola/checkpoint-535/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-cola/checkpoint-535/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-cola/checkpoint-535/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-cola/checkpoint-535/special_tokens_map.json\n",
            "{'loss': 0.295, 'learning_rate': 1.2523364485981309e-05, 'epoch': 1.87}\n",
            " 40% 1070/2675 [02:01<02:42,  9.86it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            "  9% 6/66 [00:00<00:01, 49.09it/s]\u001b[A\n",
            " 18% 12/66 [00:00<00:01, 51.45it/s]\u001b[A\n",
            " 27% 18/66 [00:00<00:00, 52.95it/s]\u001b[A\n",
            " 36% 24/66 [00:00<00:00, 52.33it/s]\u001b[A\n",
            " 45% 30/66 [00:00<00:00, 49.81it/s]\u001b[A\n",
            " 55% 36/66 [00:00<00:00, 48.32it/s]\u001b[A\n",
            " 62% 41/66 [00:00<00:00, 44.15it/s]\u001b[A\n",
            " 70% 46/66 [00:00<00:00, 41.80it/s]\u001b[A\n",
            " 79% 52/66 [00:01<00:00, 44.76it/s]\u001b[A\n",
            " 88% 58/66 [00:01<00:00, 48.60it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.4488455057144165, 'eval_matthews_correlation': 0.5792266130251226, 'eval_runtime': 1.3731, 'eval_samples_per_second': 759.619, 'eval_steps_per_second': 48.068, 'epoch': 2.0}\n",
            " 40% 1070/2675 [02:02<02:42,  9.86it/s]\n",
            "100% 66/66 [00:01<00:00, 51.09it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-cola/checkpoint-1070\n",
            "Configuration saved in bert-base-uncased-finetuned-cola/checkpoint-1070/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-cola/checkpoint-1070/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-cola/checkpoint-1070/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-cola/checkpoint-1070/special_tokens_map.json\n",
            "{'loss': 0.1858, 'learning_rate': 8.785046728971963e-06, 'epoch': 2.8}\n",
            " 60% 1604/2675 [03:03<01:54,  9.33it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            "  9% 6/66 [00:00<00:01, 47.57it/s]\u001b[A\n",
            " 18% 12/66 [00:00<00:01, 50.86it/s]\u001b[A\n",
            " 27% 18/66 [00:00<00:00, 53.20it/s]\u001b[A\n",
            " 36% 24/66 [00:00<00:00, 51.17it/s]\u001b[A\n",
            " 45% 30/66 [00:00<00:00, 49.44it/s]\u001b[A\n",
            " 53% 35/66 [00:00<00:00, 48.25it/s]\u001b[A\n",
            " 61% 40/66 [00:00<00:00, 44.81it/s]\u001b[A\n",
            " 68% 45/66 [00:00<00:00, 41.29it/s]\u001b[A\n",
            " 77% 51/66 [00:01<00:00, 43.80it/s]\u001b[A\n",
            " 86% 57/66 [00:01<00:00, 47.61it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.6855313181877136, 'eval_matthews_correlation': 0.5495093920893817, 'eval_runtime': 1.3774, 'eval_samples_per_second': 757.228, 'eval_steps_per_second': 47.917, 'epoch': 3.0}\n",
            " 60% 1605/2675 [03:04<01:54,  9.33it/s]\n",
            "100% 66/66 [00:01<00:00, 51.35it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-cola/checkpoint-1605\n",
            "Configuration saved in bert-base-uncased-finetuned-cola/checkpoint-1605/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-cola/checkpoint-1605/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-cola/checkpoint-1605/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-cola/checkpoint-1605/special_tokens_map.json\n",
            "{'loss': 0.1318, 'learning_rate': 5.046728971962617e-06, 'epoch': 3.74}\n",
            " 80% 2140/2675 [04:05<00:52, 10.26it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            "  9% 6/66 [00:00<00:01, 50.55it/s]\u001b[A\n",
            " 18% 12/66 [00:00<00:01, 52.50it/s]\u001b[A\n",
            " 27% 18/66 [00:00<00:00, 54.44it/s]\u001b[A\n",
            " 36% 24/66 [00:00<00:00, 52.00it/s]\u001b[A\n",
            " 45% 30/66 [00:00<00:00, 49.66it/s]\u001b[A\n",
            " 53% 35/66 [00:00<00:00, 48.83it/s]\u001b[A\n",
            " 61% 40/66 [00:00<00:00, 44.46it/s]\u001b[A\n",
            " 68% 45/66 [00:00<00:00, 40.58it/s]\u001b[A\n",
            " 76% 50/66 [00:01<00:00, 42.99it/s]\u001b[A\n",
            " 85% 56/66 [00:01<00:00, 46.48it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.8328033685684204, 'eval_matthews_correlation': 0.5650871771295588, 'eval_runtime': 1.3733, 'eval_samples_per_second': 759.486, 'eval_steps_per_second': 48.059, 'epoch': 4.0}\n",
            " 80% 2140/2675 [04:07<00:52, 10.26it/s]\n",
            "100% 66/66 [00:01<00:00, 51.38it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-cola/checkpoint-2140\n",
            "Configuration saved in bert-base-uncased-finetuned-cola/checkpoint-2140/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-cola/checkpoint-2140/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-cola/checkpoint-2140/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-cola/checkpoint-2140/special_tokens_map.json\n",
            "{'loss': 0.0801, 'learning_rate': 1.308411214953271e-06, 'epoch': 4.67}\n",
            "100% 2674/2675 [05:08<00:00,  9.74it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            "  9% 6/66 [00:00<00:01, 50.08it/s]\u001b[A\n",
            " 18% 12/66 [00:00<00:01, 51.73it/s]\u001b[A\n",
            " 27% 18/66 [00:00<00:00, 54.64it/s]\u001b[A\n",
            " 36% 24/66 [00:00<00:00, 52.87it/s]\u001b[A\n",
            " 45% 30/66 [00:00<00:00, 50.28it/s]\u001b[A\n",
            " 55% 36/66 [00:00<00:00, 48.54it/s]\u001b[A\n",
            " 62% 41/66 [00:00<00:00, 44.08it/s]\u001b[A\n",
            " 70% 46/66 [00:00<00:00, 41.75it/s]\u001b[A\n",
            " 77% 51/66 [00:01<00:00, 43.84it/s]\u001b[A\n",
            " 86% 57/66 [00:01<00:00, 47.84it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.8711270689964294, 'eval_matthews_correlation': 0.5580354863452468, 'eval_runtime': 1.3673, 'eval_samples_per_second': 762.801, 'eval_steps_per_second': 48.269, 'epoch': 5.0}\n",
            "100% 2675/2675 [05:09<00:00,  9.74it/s]\n",
            "100% 66/66 [00:01<00:00, 51.39it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-cola/checkpoint-2675\n",
            "Configuration saved in bert-base-uncased-finetuned-cola/checkpoint-2675/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-cola/checkpoint-2675/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-cola/checkpoint-2675/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-cola/checkpoint-2675/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from bert-base-uncased-finetuned-cola/checkpoint-1070 (score: 0.5792266130251226).\n",
            "{'train_runtime': 316.5965, 'train_samples_per_second': 135.046, 'train_steps_per_second': 8.449, 'train_loss': 0.22730096977447795, 'epoch': 5.0}\n",
            "100% 2675/2675 [05:16<00:00,  9.74it/s]Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/content/bert-vs-fnet/bert-base-uncased-finetuned-cola is already a clone of https://huggingface.co/Joqsan/bert-base-uncased-finetuned-cola. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-vs-fnet/bert-base-uncased-finetuned-cola is already a clone of https://huggingface.co/Joqsan/bert-base-uncased-finetuned-cola. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Saving model checkpoint to /tmp/tmp7g4efb1u\n",
            "Configuration saved in /tmp/tmp7g4efb1u/config.json\n",
            "Model weights saved in /tmp/tmp7g4efb1u/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmp7g4efb1u/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmp7g4efb1u/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-cola\n",
            "Configuration saved in bert-base-uncased-finetuned-cola/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-cola/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-cola/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-cola/special_tokens_map.json\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Upload file pytorch_model.bin:   0% 32.0k/418M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "Upload file pytorch_model.bin:   0% 512k/418M [00:01<14:51, 491kB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 6.12M/418M [00:02<01:57, 3.67MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 14.8M/418M [00:03<01:08, 6.13MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 23.5M/418M [00:04<00:56, 7.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 32.5M/418M [00:05<00:50, 8.06MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 41.3M/418M [00:06<00:46, 8.46MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  12% 50.1M/418M [00:07<00:44, 8.70MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 58.9M/418M [00:08<00:42, 8.87MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 67.6M/418M [00:09<00:41, 8.94MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 76.4M/418M [00:10<00:39, 9.03MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  20% 85.2M/418M [00:11<00:38, 9.09MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  22% 93.8M/418M [00:12<00:37, 9.03MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  24% 102M/418M [00:13<00:36, 9.01MB/s] \u001b[A\n",
            "Upload file pytorch_model.bin:  26% 111M/418M [00:14<00:36, 8.89MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 119M/418M [00:15<00:35, 8.84MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  30% 127M/418M [00:16<00:35, 8.69MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  32% 135M/418M [00:17<00:34, 8.62MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  34% 143M/418M [00:18<00:33, 8.59MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  36% 151M/418M [00:19<00:32, 8.63MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 160M/418M [00:20<00:31, 8.67MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 168M/418M [00:21<00:30, 8.70MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 177M/418M [00:22<00:28, 8.73MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  44% 185M/418M [00:23<00:27, 8.81MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  46% 194M/418M [00:24<00:26, 8.90MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  48% 202M/418M [00:25<00:25, 8.90MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  51% 211M/418M [00:26<00:24, 8.92MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  53% 220M/418M [00:27<00:23, 8.93MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  55% 228M/418M [00:28<00:22, 8.94MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  57% 237M/418M [00:29<00:20, 9.04MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  59% 246M/418M [00:30<00:19, 9.12MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 255M/418M [00:31<00:18, 9.17MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  63% 264M/418M [00:32<00:17, 9.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  65% 272M/418M [00:33<00:16, 9.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 281M/418M [00:34<00:15, 9.15MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 290M/418M [00:35<00:14, 9.08MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  71% 298M/418M [00:36<00:13, 9.03MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  73% 307M/418M [00:37<00:12, 9.02MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  76% 315M/418M [00:38<00:11, 9.04MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 324M/418M [00:39<00:10, 9.02MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  80% 333M/418M [00:40<00:09, 9.08MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  82% 342M/418M [00:41<00:08, 9.11MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  84% 350M/418M [00:42<00:07, 9.06MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 359M/418M [00:43<00:06, 9.08MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  88% 368M/418M [00:44<00:05, 9.08MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  90% 376M/418M [00:45<00:04, 9.06MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 385M/418M [00:46<00:03, 9.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 394M/418M [00:47<00:02, 9.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 403M/418M [00:48<00:01, 9.23MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  99% 412M/418M [00:49<00:00, 9.15MB/s]\u001b[Aremote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-cola\n",
            "   2b96d45..91af79b  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-cola\n",
            "   2b96d45..91af79b  main -> main\n",
            "\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 418M/418M [00:51<00:00, 6.43MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 418M/418M [00:51<00:00, 8.57MB/s]\n",
            "\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:51<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:51<?, ?B/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Logging model artifacts. ...\n",
            "100% 2675/2675 [06:40<00:00,  6.67it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▂▁▅▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/matthews_correlation ▁█▅▇▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▃▅▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁▆▄▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁▆▄▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▃▃▄▅▆▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▃▃▄▅▆▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate █▆▅▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▃▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.87113\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/matthews_correlation 0.55804\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 1.3673\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 762.801\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 48.269\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2675\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0801\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 455462709046680.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.2273\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 316.5965\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 135.046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 8.449\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbert-base-uncased-cola\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/n459wguu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230130_123450-n459wguu/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/fine_tuning.py Joqsan/custom-fnet cola"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JXVJlTSMbLH",
        "outputId": "14f6207e-3cfe-4055-ab9f-2e0daf99619d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100% 3/3 [00:00<00:00, 379.44it/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-92102f4820bbb024.arrow\n",
            "100% 2/2 [00:00<00:00, 30.48ba/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-3a38f57f0fab0d19.arrow\n",
            "Downloading (…)lve/main/config.json: 100% 525/525 [00:00<00:00, 80.8kB/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 353M/353M [00:22<00:00, 15.5MB/s]\n",
            "Some weights of MyFNetForSequenceClassification were not initialized from the model checkpoint at Joqsan/custom-fnet and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "models/fine_tuning.py:86: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"glue\", actual_task)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoqsan-a\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/bert-vs-fnet/wandb/run-20230130_124505-3eegyvqg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcustom-fnet-cola\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/3eegyvqg\u001b[0m\n",
            "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Cloning https://huggingface.co/Joqsan/custom-fnet-finetuned-cola into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/Joqsan/custom-fnet-finetuned-cola into local empty directory.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Download file pytorch_model.bin:   0% 173k/337M [00:01<34:36, 170kB/s]\n",
            "Download file training_args.bin: 100% 3.50k/3.50k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Download file pytorch_model.bin:  99% 333M/337M [00:42<00:00, 8.76MB/s]\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   0% 1.00k/337M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   0% 33.0k/337M [00:01<2:59:39, 32.7kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   2% 7.75M/337M [00:02<01:12, 4.76MB/s]  \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   5% 15.7M/337M [00:03<00:52, 6.36MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   7% 23.5M/337M [00:04<00:46, 7.08MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:   9% 31.6M/337M [00:05<00:42, 7.59MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  12% 39.7M/337M [00:06<00:39, 7.87MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  14% 47.0M/337M [00:07<00:39, 7.78MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  16% 54.4M/337M [00:08<00:37, 7.79MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  18% 61.5M/337M [00:09<00:37, 7.66MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  20% 68.9M/337M [00:10<00:36, 7.69MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Download file pytorch_model.bin: 100% 337M/337M [00:54<00:00, 8.76MB/s]\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  25% 82.9M/337M [00:12<00:35, 7.55MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  27% 90.5M/337M [00:13<00:33, 7.65MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  29% 98.2M/337M [00:14<00:32, 7.79MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  31% 106M/337M [00:15<00:30, 7.85MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  34% 113M/337M [00:16<00:29, 7.81MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  36% 120M/337M [00:17<00:29, 7.64MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  38% 128M/337M [00:18<00:27, 7.85MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  40% 136M/337M [00:19<00:26, 7.98MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  43% 144M/337M [00:20<00:24, 8.11MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  45% 152M/337M [00:21<00:23, 8.17MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  47% 160M/337M [00:22<00:22, 8.16MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  50% 168M/337M [00:23<00:21, 8.36MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  53% 177M/337M [00:24<00:19, 8.54MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  55% 185M/337M [00:25<00:18, 8.68MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  58% 194M/337M [00:26<00:17, 8.76MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  60% 201M/337M [00:27<00:17, 8.19MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  62% 209M/337M [00:28<00:15, 8.45MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  65% 217M/337M [00:29<00:14, 8.49MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  67% 226M/337M [00:30<00:13, 8.59MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  70% 234M/337M [00:31<00:12, 8.57MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  72% 242M/337M [00:32<00:11, 8.54MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  74% 251M/337M [00:33<00:10, 8.63MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  77% 259M/337M [00:34<00:09, 8.68MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  79% 267M/337M [00:35<00:08, 8.70MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  82% 276M/337M [00:36<00:07, 8.72MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  84% 282M/337M [00:37<00:06, 8.19MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  86% 291M/337M [00:38<00:05, 8.38MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  89% 299M/337M [00:39<00:04, 8.50MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  91% 308M/337M [00:40<00:03, 8.58MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin:  94% 316M/337M [00:41<00:02, 8.47MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Download file pytorch_model.bin: 100% 337M/337M [01:26<00:00, 4.09MB/s]\n",
            "\n",
            "Download file training_args.bin: 100% 3.50k/3.50k [01:25<?, ?B/s]\u001b[A\n",
            "Download file training_args.bin: 100% 3.50k/3.50k [01:25<?, ?B/s]\n",
            "\n",
            "\n",
            "Clean file training_args.bin: 100% 3.50k/3.50k [01:25<00:00, 30.0B/s]\u001b[A\u001b[A\n",
            "\n",
            "Clean file training_args.bin: 100% 3.50k/3.50k [01:25<00:00, 30.0B/s]\n",
            "\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin: 100% 337M/337M [00:43<00:00, 10.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Clean file pytorch_model.bin: 100% 337M/337M [00:43<00:00, 8.18MB/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "The following columns in the training set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2675\n",
            "  Number of trainable parameters = 88222466\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "  0% 0/2675 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.6187, 'learning_rate': 1.6261682242990654e-05, 'epoch': 0.93}\n",
            " 20% 535/2675 [00:44<02:47, 12.78it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 7/66 [00:00<00:00, 62.52it/s]\u001b[A\n",
            " 23% 15/66 [00:00<00:00, 67.52it/s]\u001b[A\n",
            " 35% 23/66 [00:00<00:00, 69.66it/s]\u001b[A\n",
            " 45% 30/66 [00:00<00:00, 66.65it/s]\u001b[A\n",
            " 56% 37/66 [00:00<00:00, 61.22it/s]\u001b[A\n",
            " 67% 44/66 [00:00<00:00, 54.96it/s]\u001b[A\n",
            " 77% 51/66 [00:00<00:00, 57.37it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.6418449878692627, 'eval_matthews_correlation': 0.0, 'eval_runtime': 1.0799, 'eval_samples_per_second': 965.82, 'eval_steps_per_second': 61.116, 'epoch': 1.0}\n",
            " 20% 535/2675 [00:45<02:47, 12.78it/s]\n",
            "100% 66/66 [00:01<00:00, 62.35it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-cola/checkpoint-535\n",
            "Configuration saved in custom-fnet-finetuned-cola/checkpoint-535/config.json\n",
            "Model weights saved in custom-fnet-finetuned-cola/checkpoint-535/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-cola/checkpoint-535/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-cola/checkpoint-535/special_tokens_map.json\n",
            "{'loss': 0.6138, 'learning_rate': 1.2523364485981309e-05, 'epoch': 1.87}\n",
            " 40% 1069/2675 [01:32<02:14, 11.92it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 7/66 [00:00<00:00, 64.47it/s]\u001b[A\n",
            " 23% 15/66 [00:00<00:00, 68.75it/s]\u001b[A\n",
            " 35% 23/66 [00:00<00:00, 71.76it/s]\u001b[A\n",
            " 47% 31/66 [00:00<00:00, 68.86it/s]\u001b[A\n",
            " 58% 38/66 [00:00<00:00, 62.03it/s]\u001b[A\n",
            " 68% 45/66 [00:00<00:00, 58.77it/s]\u001b[A\n",
            " 79% 52/66 [00:00<00:00, 60.86it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.623805046081543, 'eval_matthews_correlation': 0.0, 'eval_runtime': 1.0394, 'eval_samples_per_second': 1003.48, 'eval_steps_per_second': 63.499, 'epoch': 2.0}\n",
            " 40% 1070/2675 [01:33<02:14, 11.92it/s]\n",
            "100% 66/66 [00:01<00:00, 65.30it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-cola/checkpoint-1070\n",
            "Configuration saved in custom-fnet-finetuned-cola/checkpoint-1070/config.json\n",
            "Model weights saved in custom-fnet-finetuned-cola/checkpoint-1070/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-cola/checkpoint-1070/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-cola/checkpoint-1070/special_tokens_map.json\n",
            "{'loss': 0.6105, 'learning_rate': 8.785046728971963e-06, 'epoch': 2.8}\n",
            " 60% 1604/2675 [02:20<01:29, 12.02it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 7/66 [00:00<00:00, 62.92it/s]\u001b[A\n",
            " 23% 15/66 [00:00<00:00, 67.48it/s]\u001b[A\n",
            " 35% 23/66 [00:00<00:00, 68.96it/s]\u001b[A\n",
            " 45% 30/66 [00:00<00:00, 67.11it/s]\u001b[A\n",
            " 56% 37/66 [00:00<00:00, 62.93it/s]\u001b[A\n",
            " 67% 44/66 [00:00<00:00, 57.18it/s]\u001b[A\n",
            " 77% 51/66 [00:00<00:00, 59.35it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.6177886128425598, 'eval_matthews_correlation': 0.0, 'eval_runtime': 1.0567, 'eval_samples_per_second': 987.068, 'eval_steps_per_second': 62.461, 'epoch': 3.0}\n",
            " 60% 1605/2675 [02:21<01:29, 12.02it/s]\n",
            "100% 66/66 [00:01<00:00, 64.49it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-cola/checkpoint-1605\n",
            "Configuration saved in custom-fnet-finetuned-cola/checkpoint-1605/config.json\n",
            "Model weights saved in custom-fnet-finetuned-cola/checkpoint-1605/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-cola/checkpoint-1605/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-cola/checkpoint-1605/special_tokens_map.json\n",
            "{'loss': 0.6137, 'learning_rate': 5.046728971962617e-06, 'epoch': 3.74}\n",
            " 80% 2140/2675 [03:08<00:40, 13.22it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 7/66 [00:00<00:00, 64.64it/s]\u001b[A\n",
            " 23% 15/66 [00:00<00:00, 68.55it/s]\u001b[A\n",
            " 35% 23/66 [00:00<00:00, 70.91it/s]\u001b[A\n",
            " 47% 31/66 [00:00<00:00, 67.45it/s]\u001b[A\n",
            " 58% 38/66 [00:00<00:00, 60.97it/s]\u001b[A\n",
            " 68% 45/66 [00:00<00:00, 57.27it/s]\u001b[A\n",
            " 79% 52/66 [00:00<00:00, 60.00it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.6262049674987793, 'eval_matthews_correlation': 0.0, 'eval_runtime': 1.0514, 'eval_samples_per_second': 992.023, 'eval_steps_per_second': 62.774, 'epoch': 4.0}\n",
            " 80% 2140/2675 [03:09<00:40, 13.22it/s]\n",
            "100% 66/66 [00:01<00:00, 65.02it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-cola/checkpoint-2140\n",
            "Configuration saved in custom-fnet-finetuned-cola/checkpoint-2140/config.json\n",
            "Model weights saved in custom-fnet-finetuned-cola/checkpoint-2140/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-cola/checkpoint-2140/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-cola/checkpoint-2140/special_tokens_map.json\n",
            "{'loss': 0.6104, 'learning_rate': 1.308411214953271e-06, 'epoch': 4.67}\n",
            "100% 2675/2675 [03:56<00:00, 12.82it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 7/66 [00:00<00:00, 65.91it/s]\u001b[A\n",
            " 23% 15/66 [00:00<00:00, 70.43it/s]\u001b[A\n",
            " 35% 23/66 [00:00<00:00, 71.72it/s]\u001b[A\n",
            " 47% 31/66 [00:00<00:00, 68.40it/s]\u001b[A\n",
            " 58% 38/66 [00:00<00:00, 62.11it/s]\u001b[A\n",
            " 68% 45/66 [00:00<00:00, 57.87it/s]\u001b[A\n",
            " 79% 52/66 [00:00<00:00, 60.22it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.6197485327720642, 'eval_matthews_correlation': 0.0, 'eval_runtime': 1.0443, 'eval_samples_per_second': 998.753, 'eval_steps_per_second': 63.2, 'epoch': 5.0}\n",
            "100% 2675/2675 [03:57<00:00, 12.82it/s]\n",
            "100% 66/66 [00:01<00:00, 65.19it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-cola/checkpoint-2675\n",
            "Configuration saved in custom-fnet-finetuned-cola/checkpoint-2675/config.json\n",
            "Model weights saved in custom-fnet-finetuned-cola/checkpoint-2675/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-cola/checkpoint-2675/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-cola/checkpoint-2675/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from custom-fnet-finetuned-cola/checkpoint-535 (score: 0.0).\n",
            "{'train_runtime': 243.1711, 'train_samples_per_second': 175.823, 'train_steps_per_second': 11.0, 'train_loss': 0.6131597272926402, 'epoch': 5.0}\n",
            "100% 2675/2675 [04:03<00:00, 12.82it/s]Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/content/bert-vs-fnet/custom-fnet-finetuned-cola is already a clone of https://huggingface.co/Joqsan/custom-fnet-finetuned-cola. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-vs-fnet/custom-fnet-finetuned-cola is already a clone of https://huggingface.co/Joqsan/custom-fnet-finetuned-cola. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Saving model checkpoint to /tmp/tmpnjj10ltx\n",
            "Configuration saved in /tmp/tmpnjj10ltx/config.json\n",
            "Model weights saved in /tmp/tmpnjj10ltx/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmpnjj10ltx/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmpnjj10ltx/special_tokens_map.json\n",
            "Saving model checkpoint to custom-fnet-finetuned-cola\n",
            "Configuration saved in custom-fnet-finetuned-cola/config.json\n",
            "Model weights saved in custom-fnet-finetuned-cola/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-cola/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-cola/special_tokens_map.json\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "100% 2675/2675 [04:14<00:00, 12.82it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Upload file pytorch_model.bin:   0% 32.0k/337M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "Upload file pytorch_model.bin:   0% 512k/337M [00:01<11:57, 491kB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 5.03M/337M [00:02<01:56, 2.99MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 13.4M/337M [00:03<01:00, 5.63MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 21.6M/337M [00:04<00:48, 6.79MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 29.9M/337M [00:05<00:43, 7.48MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  11% 38.2M/337M [00:06<00:39, 7.88MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 46.4M/337M [00:07<00:37, 8.10MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 54.5M/337M [00:08<00:35, 8.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  19% 62.7M/337M [00:09<00:34, 8.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 70.7M/337M [00:10<00:33, 8.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 78.9M/337M [00:11<00:32, 8.42MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  26% 86.9M/337M [00:12<00:31, 8.41MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 94.9M/337M [00:13<00:30, 8.41MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 103M/337M [00:14<00:29, 8.44MB/s] \u001b[A\n",
            "Upload file pytorch_model.bin:  33% 111M/337M [00:15<00:28, 8.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  35% 119M/337M [00:16<00:27, 8.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 127M/337M [00:17<00:26, 8.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 135M/337M [00:18<00:25, 8.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 143M/337M [00:19<00:24, 8.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 151M/337M [00:20<00:23, 8.40MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 159M/337M [00:21<00:22, 8.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 167M/337M [00:22<00:21, 8.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 175M/337M [00:23<00:20, 8.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 183M/337M [00:24<00:19, 8.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  57% 191M/337M [00:25<00:18, 8.42MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  59% 200M/337M [00:26<00:16, 8.56MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  62% 208M/337M [00:27<00:15, 8.64MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 216M/337M [00:28<00:14, 8.66MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 225M/337M [00:29<00:13, 8.70MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 233M/337M [00:30<00:12, 8.69MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 241M/337M [00:31<00:11, 8.73MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 250M/337M [00:32<00:10, 8.78MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 258M/337M [00:33<00:09, 8.84MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  79% 267M/337M [00:34<00:08, 8.81MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  82% 275M/337M [00:35<00:07, 8.84MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  84% 284M/337M [00:36<00:06, 8.86MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 292M/337M [00:37<00:05, 8.86MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 301M/337M [00:38<00:04, 8.88MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 309M/337M [00:39<00:03, 8.90MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 318M/337M [00:40<00:02, 8.93MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 326M/337M [00:41<00:01, 8.92MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 335M/337M [00:42<00:00, 8.93MB/s]\u001b[Aremote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/custom-fnet-finetuned-cola\n",
            "   63aab75..a8e124c  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/custom-fnet-finetuned-cola\n",
            "   63aab75..a8e124c  main -> main\n",
            "\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 337M/337M [00:44<00:00, 5.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 337M/337M [00:44<00:00, 8.00MB/s]\n",
            "\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:44<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:44<?, ?B/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Logging model artifacts. ...\n",
            "100% 2675/2675 [05:19<00:00,  8.38it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▃▁▃▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/matthews_correlation ▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▁▄▃▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁█▅▆▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁█▅▆▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▃▃▄▅▆▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▃▃▄▅▆▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate █▆▅▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▄▁▄▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.61975\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/matthews_correlation 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 1.0443\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 998.753\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 63.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2675\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.6104\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 342398538685848.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.61316\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 243.1711\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 175.823\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 11.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcustom-fnet-cola\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/3eegyvqg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230130_124505-3eegyvqg/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/fine_tuning.py bert-base-uncased qnli"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsUTK7RItpxk",
        "outputId": "d2190d2e-6835-4e16-e0c9-7e9870dad9d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "Downloading and preparing dataset glue/qnli to /root/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n",
            "Downloading data: 100% 10.6M/10.6M [00:02<00:00, 4.44MB/s]\n",
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 692.74it/s]\n",
            "100% 105/105 [00:13<00:00,  7.56ba/s]\n",
            "100% 6/6 [00:00<00:00,  8.84ba/s]\n",
            "100% 6/6 [00:00<00:00,  6.92ba/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "models/fine_tuning.py:86: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"glue\", actual_task)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoqsan-a\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/bert-vs-fnet/wandb/run-20230130_125340-cgukztyx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbert-base-uncased-qnli\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/cgukztyx\u001b[0m\n",
            "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Cloning https://huggingface.co/Joqsan/bert-base-uncased-finetuned-qnli into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/Joqsan/bert-base-uncased-finetuned-qnli into local empty directory.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 104743\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 32735\n",
            "  Number of trainable parameters = 109483778\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "  0% 0/32735 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.4586, 'learning_rate': 1.9694516572475945e-05, 'epoch': 0.08}\n",
            "{'loss': 0.3815, 'learning_rate': 1.9389033144951888e-05, 'epoch': 0.15}\n",
            "{'loss': 0.3493, 'learning_rate': 1.908354971742783e-05, 'epoch': 0.23}\n",
            "{'loss': 0.353, 'learning_rate': 1.8778066289903775e-05, 'epoch': 0.31}\n",
            "{'loss': 0.324, 'learning_rate': 1.8472582862379718e-05, 'epoch': 0.38}\n",
            "{'loss': 0.3323, 'learning_rate': 1.816709943485566e-05, 'epoch': 0.46}\n",
            "{'loss': 0.3263, 'learning_rate': 1.7861616007331604e-05, 'epoch': 0.53}\n",
            "{'loss': 0.2976, 'learning_rate': 1.7556132579807548e-05, 'epoch': 0.61}\n",
            "{'loss': 0.3273, 'learning_rate': 1.725064915228349e-05, 'epoch': 0.69}\n",
            "{'loss': 0.2958, 'learning_rate': 1.6945165724759434e-05, 'epoch': 0.76}\n",
            "{'loss': 0.3022, 'learning_rate': 1.6639682297235374e-05, 'epoch': 0.84}\n",
            "{'loss': 0.2953, 'learning_rate': 1.633419886971132e-05, 'epoch': 0.92}\n",
            "{'loss': 0.2985, 'learning_rate': 1.6028715442187264e-05, 'epoch': 0.99}\n",
            " 20% 6547/32735 [30:12<1:40:20,  4.35it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/342 [00:00<00:18, 18.87it/s]\u001b[A\n",
            "  1% 4/342 [00:00<00:33, 10.13it/s]\u001b[A\n",
            "  2% 6/342 [00:00<00:32, 10.36it/s]\u001b[A\n",
            "  2% 8/342 [00:00<00:32, 10.14it/s]\u001b[A\n",
            "  3% 10/342 [00:00<00:30, 11.06it/s]\u001b[A\n",
            "  4% 12/342 [00:01<00:28, 11.67it/s]\u001b[A\n",
            "  4% 14/342 [00:01<00:29, 11.17it/s]\u001b[A\n",
            "  5% 16/342 [00:01<00:28, 11.44it/s]\u001b[A\n",
            "  5% 18/342 [00:01<00:27, 11.67it/s]\u001b[A\n",
            "  6% 20/342 [00:01<00:27, 11.77it/s]\u001b[A\n",
            "  6% 22/342 [00:01<00:27, 11.69it/s]\u001b[A\n",
            "  7% 24/342 [00:02<00:28, 11.35it/s]\u001b[A\n",
            "  8% 26/342 [00:02<00:30, 10.49it/s]\u001b[A\n",
            "  8% 28/342 [00:02<00:28, 11.03it/s]\u001b[A\n",
            "  9% 30/342 [00:02<00:37,  8.37it/s]\u001b[A\n",
            "  9% 32/342 [00:03<00:32,  9.55it/s]\u001b[A\n",
            " 10% 34/342 [00:03<00:30, 10.11it/s]\u001b[A\n",
            " 11% 36/342 [00:03<00:29, 10.43it/s]\u001b[A\n",
            " 11% 38/342 [00:03<00:28, 10.73it/s]\u001b[A\n",
            " 12% 40/342 [00:03<00:26, 11.39it/s]\u001b[A\n",
            " 12% 42/342 [00:03<00:25, 11.90it/s]\u001b[A\n",
            " 13% 44/342 [00:04<00:25, 11.60it/s]\u001b[A\n",
            " 13% 46/342 [00:04<00:28, 10.46it/s]\u001b[A\n",
            " 14% 48/342 [00:04<00:28, 10.47it/s]\u001b[A\n",
            " 15% 50/342 [00:04<00:30,  9.47it/s]\u001b[A\n",
            " 15% 52/342 [00:04<00:30,  9.43it/s]\u001b[A\n",
            " 16% 54/342 [00:05<00:28, 10.23it/s]\u001b[A\n",
            " 16% 56/342 [00:05<00:26, 10.84it/s]\u001b[A\n",
            " 17% 58/342 [00:05<00:27, 10.22it/s]\u001b[A\n",
            " 18% 60/342 [00:05<00:26, 10.81it/s]\u001b[A\n",
            " 18% 62/342 [00:05<00:27, 10.35it/s]\u001b[A\n",
            " 19% 64/342 [00:06<00:26, 10.55it/s]\u001b[A\n",
            " 19% 66/342 [00:06<00:24, 11.11it/s]\u001b[A\n",
            " 20% 68/342 [00:06<00:24, 11.13it/s]\u001b[A\n",
            " 20% 70/342 [00:06<00:29,  9.14it/s]\u001b[A\n",
            " 21% 72/342 [00:06<00:28,  9.64it/s]\u001b[A\n",
            " 22% 74/342 [00:06<00:25, 10.31it/s]\u001b[A\n",
            " 22% 76/342 [00:07<00:23, 11.50it/s]\u001b[A\n",
            " 23% 78/342 [00:07<00:22, 11.68it/s]\u001b[A\n",
            " 23% 80/342 [00:07<00:21, 12.03it/s]\u001b[A\n",
            " 24% 82/342 [00:07<00:21, 12.11it/s]\u001b[A\n",
            " 25% 84/342 [00:07<00:21, 12.11it/s]\u001b[A\n",
            " 25% 86/342 [00:07<00:21, 12.08it/s]\u001b[A\n",
            " 26% 88/342 [00:08<00:23, 11.00it/s]\u001b[A\n",
            " 26% 90/342 [00:08<00:23, 10.75it/s]\u001b[A\n",
            " 27% 92/342 [00:08<00:22, 11.30it/s]\u001b[A\n",
            " 27% 94/342 [00:08<00:21, 11.57it/s]\u001b[A\n",
            " 28% 96/342 [00:08<00:19, 12.77it/s]\u001b[A\n",
            " 29% 98/342 [00:08<00:20, 11.86it/s]\u001b[A\n",
            " 29% 100/342 [00:09<00:19, 12.21it/s]\u001b[A\n",
            " 30% 102/342 [00:09<00:19, 12.04it/s]\u001b[A\n",
            " 30% 104/342 [00:09<00:19, 12.05it/s]\u001b[A\n",
            " 31% 106/342 [00:09<00:20, 11.48it/s]\u001b[A\n",
            " 32% 108/342 [00:09<00:19, 11.82it/s]\u001b[A\n",
            " 32% 110/342 [00:10<00:19, 11.77it/s]\u001b[A\n",
            " 33% 112/342 [00:10<00:19, 11.92it/s]\u001b[A\n",
            " 33% 114/342 [00:10<00:19, 11.85it/s]\u001b[A\n",
            " 34% 116/342 [00:10<00:21, 10.67it/s]\u001b[A\n",
            " 35% 118/342 [00:10<00:21, 10.40it/s]\u001b[A\n",
            " 35% 120/342 [00:10<00:19, 11.12it/s]\u001b[A\n",
            " 36% 122/342 [00:11<00:21, 10.33it/s]\u001b[A\n",
            " 36% 124/342 [00:11<00:19, 11.02it/s]\u001b[A\n",
            " 37% 126/342 [00:11<00:18, 11.43it/s]\u001b[A\n",
            " 37% 128/342 [00:11<00:17, 11.93it/s]\u001b[A\n",
            " 38% 130/342 [00:11<00:19, 10.84it/s]\u001b[A\n",
            " 39% 132/342 [00:12<00:19, 10.91it/s]\u001b[A\n",
            " 39% 134/342 [00:12<00:18, 11.33it/s]\u001b[A\n",
            " 40% 136/342 [00:12<00:18, 11.01it/s]\u001b[A\n",
            " 40% 138/342 [00:12<00:19, 10.62it/s]\u001b[A\n",
            " 41% 140/342 [00:12<00:18, 10.64it/s]\u001b[A\n",
            " 42% 142/342 [00:12<00:19, 10.52it/s]\u001b[A\n",
            " 42% 144/342 [00:13<00:18, 10.96it/s]\u001b[A\n",
            " 43% 146/342 [00:13<00:17, 11.35it/s]\u001b[A\n",
            " 43% 148/342 [00:13<00:16, 11.64it/s]\u001b[A\n",
            " 44% 150/342 [00:13<00:16, 11.42it/s]\u001b[A\n",
            " 44% 152/342 [00:13<00:18, 10.10it/s]\u001b[A\n",
            " 45% 154/342 [00:14<00:19,  9.51it/s]\u001b[A\n",
            " 46% 156/342 [00:14<00:18, 10.21it/s]\u001b[A\n",
            " 46% 158/342 [00:14<00:19,  9.46it/s]\u001b[A\n",
            " 46% 159/342 [00:14<00:21,  8.49it/s]\u001b[A\n",
            " 47% 161/342 [00:14<00:20,  8.63it/s]\u001b[A\n",
            " 48% 163/342 [00:15<00:19,  9.00it/s]\u001b[A\n",
            " 48% 165/342 [00:15<00:17,  9.84it/s]\u001b[A\n",
            " 49% 167/342 [00:15<00:16, 10.78it/s]\u001b[A\n",
            " 49% 169/342 [00:15<00:14, 11.93it/s]\u001b[A\n",
            " 50% 171/342 [00:15<00:14, 11.63it/s]\u001b[A\n",
            " 51% 173/342 [00:15<00:13, 12.56it/s]\u001b[A\n",
            " 51% 175/342 [00:16<00:14, 11.78it/s]\u001b[A\n",
            " 52% 177/342 [00:16<00:14, 11.19it/s]\u001b[A\n",
            " 52% 179/342 [00:16<00:14, 11.18it/s]\u001b[A\n",
            " 53% 181/342 [00:16<00:14, 10.97it/s]\u001b[A\n",
            " 54% 183/342 [00:16<00:14, 11.36it/s]\u001b[A\n",
            " 54% 185/342 [00:16<00:13, 11.76it/s]\u001b[A\n",
            " 55% 187/342 [00:17<00:14, 10.47it/s]\u001b[A\n",
            " 55% 189/342 [00:17<00:14, 10.87it/s]\u001b[A\n",
            " 56% 191/342 [00:17<00:14, 10.44it/s]\u001b[A\n",
            " 56% 193/342 [00:17<00:14, 10.37it/s]\u001b[A\n",
            " 57% 195/342 [00:17<00:12, 11.35it/s]\u001b[A\n",
            " 58% 197/342 [00:18<00:12, 11.59it/s]\u001b[A\n",
            " 58% 199/342 [00:18<00:13, 10.27it/s]\u001b[A\n",
            " 59% 201/342 [00:18<00:14,  9.45it/s]\u001b[A\n",
            " 59% 203/342 [00:18<00:13, 10.32it/s]\u001b[A\n",
            " 60% 205/342 [00:19<00:15,  9.09it/s]\u001b[A\n",
            " 61% 207/342 [00:19<00:13,  9.85it/s]\u001b[A\n",
            " 61% 209/342 [00:19<00:13,  9.63it/s]\u001b[A\n",
            " 62% 211/342 [00:19<00:13,  9.71it/s]\u001b[A\n",
            " 62% 213/342 [00:19<00:12, 10.32it/s]\u001b[A\n",
            " 63% 215/342 [00:19<00:11, 10.62it/s]\u001b[A\n",
            " 63% 217/342 [00:20<00:11, 11.08it/s]\u001b[A\n",
            " 64% 219/342 [00:20<00:12,  9.88it/s]\u001b[A\n",
            " 65% 221/342 [00:20<00:11, 10.55it/s]\u001b[A\n",
            " 65% 223/342 [00:20<00:10, 11.29it/s]\u001b[A\n",
            " 66% 225/342 [00:20<00:10, 11.61it/s]\u001b[A\n",
            " 66% 227/342 [00:20<00:09, 12.28it/s]\u001b[A\n",
            " 67% 229/342 [00:21<00:08, 12.58it/s]\u001b[A\n",
            " 68% 231/342 [00:21<00:09, 11.91it/s]\u001b[A\n",
            " 68% 233/342 [00:21<00:09, 11.51it/s]\u001b[A\n",
            " 69% 235/342 [00:21<00:09, 11.25it/s]\u001b[A\n",
            " 69% 237/342 [00:21<00:09, 10.94it/s]\u001b[A\n",
            " 70% 239/342 [00:22<00:09, 10.99it/s]\u001b[A\n",
            " 70% 241/342 [00:22<00:08, 11.49it/s]\u001b[A\n",
            " 71% 243/342 [00:22<00:08, 11.81it/s]\u001b[A\n",
            " 72% 245/342 [00:22<00:08, 12.12it/s]\u001b[A\n",
            " 72% 247/342 [00:22<00:08, 11.68it/s]\u001b[A\n",
            " 73% 249/342 [00:22<00:07, 11.85it/s]\u001b[A\n",
            " 73% 251/342 [00:23<00:07, 11.64it/s]\u001b[A\n",
            " 74% 253/342 [00:23<00:07, 12.19it/s]\u001b[A\n",
            " 75% 255/342 [00:23<00:07, 12.15it/s]\u001b[A\n",
            " 75% 257/342 [00:23<00:07, 12.00it/s]\u001b[A\n",
            " 76% 259/342 [00:23<00:07, 11.82it/s]\u001b[A\n",
            " 76% 261/342 [00:23<00:07, 11.12it/s]\u001b[A\n",
            " 77% 263/342 [00:24<00:06, 11.33it/s]\u001b[A\n",
            " 77% 265/342 [00:24<00:06, 11.31it/s]\u001b[A\n",
            " 78% 267/342 [00:24<00:07, 10.41it/s]\u001b[A\n",
            " 79% 269/342 [00:24<00:06, 11.07it/s]\u001b[A\n",
            " 79% 271/342 [00:24<00:06, 11.76it/s]\u001b[A\n",
            " 80% 273/342 [00:24<00:05, 11.59it/s]\u001b[A\n",
            " 80% 275/342 [00:25<00:05, 11.83it/s]\u001b[A\n",
            " 81% 277/342 [00:25<00:05, 12.09it/s]\u001b[A\n",
            " 82% 279/342 [00:25<00:05, 12.10it/s]\u001b[A\n",
            " 82% 281/342 [00:25<00:04, 12.44it/s]\u001b[A\n",
            " 83% 283/342 [00:25<00:04, 12.12it/s]\u001b[A\n",
            " 83% 285/342 [00:26<00:05, 10.23it/s]\u001b[A\n",
            " 84% 287/342 [00:26<00:04, 11.09it/s]\u001b[A\n",
            " 85% 289/342 [00:26<00:04, 11.80it/s]\u001b[A\n",
            " 85% 291/342 [00:26<00:04, 11.18it/s]\u001b[A\n",
            " 86% 293/342 [00:26<00:04, 10.85it/s]\u001b[A\n",
            " 86% 295/342 [00:26<00:04, 11.27it/s]\u001b[A\n",
            " 87% 297/342 [00:27<00:04, 11.21it/s]\u001b[A\n",
            " 87% 299/342 [00:27<00:03, 11.26it/s]\u001b[A\n",
            " 88% 301/342 [00:27<00:03, 11.27it/s]\u001b[A\n",
            " 89% 303/342 [00:27<00:03, 11.12it/s]\u001b[A\n",
            " 89% 305/342 [00:27<00:03, 11.45it/s]\u001b[A\n",
            " 90% 307/342 [00:28<00:03, 10.12it/s]\u001b[A\n",
            " 90% 309/342 [00:28<00:03, 10.78it/s]\u001b[A\n",
            " 91% 311/342 [00:28<00:02, 11.51it/s]\u001b[A\n",
            " 92% 313/342 [00:28<00:02, 11.51it/s]\u001b[A\n",
            " 92% 315/342 [00:28<00:02, 11.42it/s]\u001b[A\n",
            " 93% 317/342 [00:28<00:02, 12.10it/s]\u001b[A\n",
            " 93% 319/342 [00:29<00:02, 10.74it/s]\u001b[A\n",
            " 94% 321/342 [00:29<00:01, 11.26it/s]\u001b[A\n",
            " 94% 323/342 [00:29<00:01, 11.64it/s]\u001b[A\n",
            " 95% 325/342 [00:29<00:01, 11.61it/s]\u001b[A\n",
            " 96% 327/342 [00:29<00:01, 11.05it/s]\u001b[A\n",
            " 96% 329/342 [00:29<00:01, 10.82it/s]\u001b[A\n",
            " 97% 331/342 [00:30<00:01, 10.83it/s]\u001b[A\n",
            " 97% 333/342 [00:30<00:00, 11.06it/s]\u001b[A\n",
            " 98% 335/342 [00:30<00:00, 11.11it/s]\u001b[A\n",
            " 99% 337/342 [00:30<00:00, 11.57it/s]\u001b[A\n",
            " 99% 339/342 [00:30<00:00, 12.39it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.22327840328216553, 'eval_accuracy': 0.9152480322167308, 'eval_runtime': 31.0631, 'eval_samples_per_second': 175.868, 'eval_steps_per_second': 11.01, 'epoch': 1.0}\n",
            " 20% 6547/32735 [30:43<1:40:20,  4.35it/s]\n",
            "100% 342/342 [00:30<00:00, 12.29it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-qnli/checkpoint-6547\n",
            "Configuration saved in bert-base-uncased-finetuned-qnli/checkpoint-6547/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-qnli/checkpoint-6547/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-qnli/checkpoint-6547/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-qnli/checkpoint-6547/special_tokens_map.json\n",
            "{'loss': 0.2014, 'learning_rate': 1.5723232014663207e-05, 'epoch': 1.07}\n",
            "{'loss': 0.2041, 'learning_rate': 1.541774858713915e-05, 'epoch': 1.15}\n",
            "{'loss': 0.1925, 'learning_rate': 1.5112265159615092e-05, 'epoch': 1.22}\n",
            "{'loss': 0.2042, 'learning_rate': 1.4806781732091035e-05, 'epoch': 1.3}\n",
            "{'loss': 0.1956, 'learning_rate': 1.4501298304566977e-05, 'epoch': 1.37}\n",
            "{'loss': 0.1995, 'learning_rate': 1.4195814877042922e-05, 'epoch': 1.45}\n",
            "{'loss': 0.2036, 'learning_rate': 1.3890331449518865e-05, 'epoch': 1.53}\n",
            "{'loss': 0.2044, 'learning_rate': 1.3584848021994808e-05, 'epoch': 1.6}\n",
            "{'loss': 0.207, 'learning_rate': 1.3279364594470752e-05, 'epoch': 1.68}\n",
            "{'loss': 0.1955, 'learning_rate': 1.2973881166946693e-05, 'epoch': 1.76}\n",
            "{'loss': 0.1999, 'learning_rate': 1.2668397739422638e-05, 'epoch': 1.83}\n",
            "{'loss': 0.1973, 'learning_rate': 1.236291431189858e-05, 'epoch': 1.91}\n",
            "{'loss': 0.1922, 'learning_rate': 1.2057430884374523e-05, 'epoch': 1.99}\n",
            " 40% 13094/32735 [1:00:58<1:20:40,  4.06it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/342 [00:00<00:18, 18.39it/s]\u001b[A\n",
            "  1% 4/342 [00:00<00:34,  9.84it/s]\u001b[A\n",
            "  2% 6/342 [00:00<00:32, 10.36it/s]\u001b[A\n",
            "  2% 8/342 [00:00<00:32, 10.17it/s]\u001b[A\n",
            "  3% 10/342 [00:00<00:29, 11.12it/s]\u001b[A\n",
            "  4% 12/342 [00:01<00:27, 11.80it/s]\u001b[A\n",
            "  4% 14/342 [00:01<00:29, 11.29it/s]\u001b[A\n",
            "  5% 16/342 [00:01<00:28, 11.55it/s]\u001b[A\n",
            "  5% 18/342 [00:01<00:27, 11.79it/s]\u001b[A\n",
            "  6% 20/342 [00:01<00:27, 11.87it/s]\u001b[A\n",
            "  6% 22/342 [00:01<00:27, 11.71it/s]\u001b[A\n",
            "  7% 24/342 [00:02<00:28, 11.35it/s]\u001b[A\n",
            "  8% 26/342 [00:02<00:30, 10.48it/s]\u001b[A\n",
            "  8% 28/342 [00:02<00:28, 10.99it/s]\u001b[A\n",
            "  9% 30/342 [00:02<00:37,  8.38it/s]\u001b[A\n",
            "  9% 32/342 [00:03<00:32,  9.55it/s]\u001b[A\n",
            " 10% 34/342 [00:03<00:30, 10.12it/s]\u001b[A\n",
            " 11% 36/342 [00:03<00:29, 10.44it/s]\u001b[A\n",
            " 11% 38/342 [00:03<00:28, 10.71it/s]\u001b[A\n",
            " 12% 40/342 [00:03<00:26, 11.37it/s]\u001b[A\n",
            " 12% 42/342 [00:03<00:25, 11.89it/s]\u001b[A\n",
            " 13% 44/342 [00:04<00:25, 11.59it/s]\u001b[A\n",
            " 13% 46/342 [00:04<00:28, 10.53it/s]\u001b[A\n",
            " 14% 48/342 [00:04<00:28, 10.49it/s]\u001b[A\n",
            " 15% 50/342 [00:04<00:30,  9.47it/s]\u001b[A\n",
            " 15% 52/342 [00:04<00:30,  9.45it/s]\u001b[A\n",
            " 16% 54/342 [00:05<00:28, 10.22it/s]\u001b[A\n",
            " 16% 56/342 [00:05<00:26, 10.86it/s]\u001b[A\n",
            " 17% 58/342 [00:05<00:27, 10.26it/s]\u001b[A\n",
            " 18% 60/342 [00:05<00:26, 10.79it/s]\u001b[A\n",
            " 18% 62/342 [00:05<00:27, 10.34it/s]\u001b[A\n",
            " 19% 64/342 [00:06<00:26, 10.50it/s]\u001b[A\n",
            " 19% 66/342 [00:06<00:24, 11.09it/s]\u001b[A\n",
            " 20% 68/342 [00:06<00:24, 11.19it/s]\u001b[A\n",
            " 20% 70/342 [00:06<00:29,  9.16it/s]\u001b[A\n",
            " 21% 72/342 [00:06<00:27,  9.69it/s]\u001b[A\n",
            " 22% 74/342 [00:06<00:25, 10.33it/s]\u001b[A\n",
            " 22% 76/342 [00:07<00:23, 11.47it/s]\u001b[A\n",
            " 23% 78/342 [00:07<00:22, 11.66it/s]\u001b[A\n",
            " 23% 80/342 [00:07<00:21, 12.01it/s]\u001b[A\n",
            " 24% 82/342 [00:07<00:21, 12.12it/s]\u001b[A\n",
            " 25% 84/342 [00:07<00:21, 12.08it/s]\u001b[A\n",
            " 25% 86/342 [00:07<00:21, 12.06it/s]\u001b[A\n",
            " 26% 88/342 [00:08<00:23, 11.03it/s]\u001b[A\n",
            " 26% 90/342 [00:08<00:23, 10.78it/s]\u001b[A\n",
            " 27% 92/342 [00:08<00:22, 11.28it/s]\u001b[A\n",
            " 27% 94/342 [00:08<00:21, 11.55it/s]\u001b[A\n",
            " 28% 96/342 [00:08<00:19, 12.69it/s]\u001b[A\n",
            " 29% 98/342 [00:08<00:20, 11.85it/s]\u001b[A\n",
            " 29% 100/342 [00:09<00:19, 12.21it/s]\u001b[A\n",
            " 30% 102/342 [00:09<00:19, 12.03it/s]\u001b[A\n",
            " 30% 104/342 [00:09<00:19, 12.12it/s]\u001b[A\n",
            " 31% 106/342 [00:09<00:20, 11.59it/s]\u001b[A\n",
            " 32% 108/342 [00:09<00:19, 11.79it/s]\u001b[A\n",
            " 32% 110/342 [00:09<00:19, 11.73it/s]\u001b[A\n",
            " 33% 112/342 [00:10<00:19, 11.88it/s]\u001b[A\n",
            " 33% 114/342 [00:10<00:19, 11.86it/s]\u001b[A\n",
            " 34% 116/342 [00:10<00:21, 10.65it/s]\u001b[A\n",
            " 35% 118/342 [00:10<00:21, 10.37it/s]\u001b[A\n",
            " 35% 120/342 [00:10<00:19, 11.19it/s]\u001b[A\n",
            " 36% 122/342 [00:11<00:21, 10.36it/s]\u001b[A\n",
            " 36% 124/342 [00:11<00:19, 10.97it/s]\u001b[A\n",
            " 37% 126/342 [00:11<00:18, 11.43it/s]\u001b[A\n",
            " 37% 128/342 [00:11<00:17, 11.92it/s]\u001b[A\n",
            " 38% 130/342 [00:11<00:19, 10.81it/s]\u001b[A\n",
            " 39% 132/342 [00:12<00:19, 10.89it/s]\u001b[A\n",
            " 39% 134/342 [00:12<00:18, 11.32it/s]\u001b[A\n",
            " 40% 136/342 [00:12<00:18, 11.04it/s]\u001b[A\n",
            " 40% 138/342 [00:12<00:19, 10.66it/s]\u001b[A\n",
            " 41% 140/342 [00:12<00:18, 10.65it/s]\u001b[A\n",
            " 42% 142/342 [00:12<00:18, 10.56it/s]\u001b[A\n",
            " 42% 144/342 [00:13<00:18, 10.95it/s]\u001b[A\n",
            " 43% 146/342 [00:13<00:17, 11.37it/s]\u001b[A\n",
            " 43% 148/342 [00:13<00:16, 11.80it/s]\u001b[A\n",
            " 44% 150/342 [00:13<00:16, 11.39it/s]\u001b[A\n",
            " 44% 152/342 [00:13<00:18, 10.11it/s]\u001b[A\n",
            " 45% 154/342 [00:14<00:19,  9.46it/s]\u001b[A\n",
            " 46% 156/342 [00:14<00:18, 10.12it/s]\u001b[A\n",
            " 46% 158/342 [00:14<00:19,  9.42it/s]\u001b[A\n",
            " 46% 159/342 [00:14<00:21,  8.43it/s]\u001b[A\n",
            " 47% 161/342 [00:14<00:21,  8.57it/s]\u001b[A\n",
            " 48% 163/342 [00:15<00:19,  9.02it/s]\u001b[A\n",
            " 48% 165/342 [00:15<00:17,  9.83it/s]\u001b[A\n",
            " 49% 167/342 [00:15<00:16, 10.80it/s]\u001b[A\n",
            " 49% 169/342 [00:15<00:14, 11.94it/s]\u001b[A\n",
            " 50% 171/342 [00:15<00:14, 11.73it/s]\u001b[A\n",
            " 51% 173/342 [00:15<00:13, 12.56it/s]\u001b[A\n",
            " 51% 175/342 [00:16<00:14, 11.82it/s]\u001b[A\n",
            " 52% 177/342 [00:16<00:14, 11.21it/s]\u001b[A\n",
            " 52% 179/342 [00:16<00:14, 11.20it/s]\u001b[A\n",
            " 53% 181/342 [00:16<00:14, 10.97it/s]\u001b[A\n",
            " 54% 183/342 [00:16<00:13, 11.37it/s]\u001b[A\n",
            " 54% 185/342 [00:16<00:13, 11.75it/s]\u001b[A\n",
            " 55% 187/342 [00:17<00:14, 10.46it/s]\u001b[A\n",
            " 55% 189/342 [00:17<00:14, 10.82it/s]\u001b[A\n",
            " 56% 191/342 [00:17<00:14, 10.39it/s]\u001b[A\n",
            " 56% 193/342 [00:17<00:14, 10.24it/s]\u001b[A\n",
            " 57% 195/342 [00:17<00:13, 11.19it/s]\u001b[A\n",
            " 58% 197/342 [00:18<00:12, 11.51it/s]\u001b[A\n",
            " 58% 199/342 [00:18<00:13, 10.25it/s]\u001b[A\n",
            " 59% 201/342 [00:18<00:14,  9.42it/s]\u001b[A\n",
            " 59% 203/342 [00:18<00:13, 10.39it/s]\u001b[A\n",
            " 60% 205/342 [00:19<00:15,  9.07it/s]\u001b[A\n",
            " 61% 207/342 [00:19<00:13,  9.84it/s]\u001b[A\n",
            " 61% 209/342 [00:19<00:13,  9.61it/s]\u001b[A\n",
            " 62% 211/342 [00:19<00:13,  9.69it/s]\u001b[A\n",
            " 62% 213/342 [00:19<00:12, 10.35it/s]\u001b[A\n",
            " 63% 215/342 [00:19<00:12, 10.56it/s]\u001b[A\n",
            " 63% 217/342 [00:20<00:11, 11.00it/s]\u001b[A\n",
            " 64% 219/342 [00:20<00:12,  9.78it/s]\u001b[A\n",
            " 65% 221/342 [00:20<00:11, 10.51it/s]\u001b[A\n",
            " 65% 223/342 [00:20<00:10, 11.27it/s]\u001b[A\n",
            " 66% 225/342 [00:20<00:10, 11.60it/s]\u001b[A\n",
            " 66% 227/342 [00:20<00:09, 12.21it/s]\u001b[A\n",
            " 67% 229/342 [00:21<00:08, 12.59it/s]\u001b[A\n",
            " 68% 231/342 [00:21<00:09, 11.91it/s]\u001b[A\n",
            " 68% 233/342 [00:21<00:09, 11.53it/s]\u001b[A\n",
            " 69% 235/342 [00:21<00:09, 11.34it/s]\u001b[A\n",
            " 69% 237/342 [00:21<00:09, 11.03it/s]\u001b[A\n",
            " 70% 239/342 [00:22<00:09, 11.00it/s]\u001b[A\n",
            " 70% 241/342 [00:22<00:08, 11.38it/s]\u001b[A\n",
            " 71% 243/342 [00:22<00:08, 11.72it/s]\u001b[A\n",
            " 72% 245/342 [00:22<00:08, 12.09it/s]\u001b[A\n",
            " 72% 247/342 [00:22<00:08, 11.74it/s]\u001b[A\n",
            " 73% 249/342 [00:22<00:07, 12.02it/s]\u001b[A\n",
            " 73% 251/342 [00:23<00:07, 11.77it/s]\u001b[A\n",
            " 74% 253/342 [00:23<00:07, 12.26it/s]\u001b[A\n",
            " 75% 255/342 [00:23<00:07, 12.20it/s]\u001b[A\n",
            " 75% 257/342 [00:23<00:07, 11.98it/s]\u001b[A\n",
            " 76% 259/342 [00:23<00:07, 11.86it/s]\u001b[A\n",
            " 76% 261/342 [00:23<00:07, 11.25it/s]\u001b[A\n",
            " 77% 263/342 [00:24<00:06, 11.46it/s]\u001b[A\n",
            " 77% 265/342 [00:24<00:06, 11.42it/s]\u001b[A\n",
            " 78% 267/342 [00:24<00:07, 10.45it/s]\u001b[A\n",
            " 79% 269/342 [00:24<00:06, 11.04it/s]\u001b[A\n",
            " 79% 271/342 [00:24<00:06, 11.81it/s]\u001b[A\n",
            " 80% 273/342 [00:24<00:05, 11.68it/s]\u001b[A\n",
            " 80% 275/342 [00:25<00:05, 11.76it/s]\u001b[A\n",
            " 81% 277/342 [00:25<00:05, 12.02it/s]\u001b[A\n",
            " 82% 279/342 [00:25<00:05, 12.02it/s]\u001b[A\n",
            " 82% 281/342 [00:25<00:04, 12.34it/s]\u001b[A\n",
            " 83% 283/342 [00:25<00:04, 12.11it/s]\u001b[A\n",
            " 83% 285/342 [00:26<00:05, 10.25it/s]\u001b[A\n",
            " 84% 287/342 [00:26<00:04, 11.05it/s]\u001b[A\n",
            " 85% 289/342 [00:26<00:04, 11.70it/s]\u001b[A\n",
            " 85% 291/342 [00:26<00:04, 11.10it/s]\u001b[A\n",
            " 86% 293/342 [00:26<00:04, 10.78it/s]\u001b[A\n",
            " 86% 295/342 [00:26<00:04, 11.20it/s]\u001b[A\n",
            " 87% 297/342 [00:27<00:04, 11.17it/s]\u001b[A\n",
            " 87% 299/342 [00:27<00:03, 11.18it/s]\u001b[A\n",
            " 88% 301/342 [00:27<00:03, 11.16it/s]\u001b[A\n",
            " 89% 303/342 [00:27<00:03, 11.06it/s]\u001b[A\n",
            " 89% 305/342 [00:27<00:03, 11.47it/s]\u001b[A\n",
            " 90% 307/342 [00:28<00:03, 10.30it/s]\u001b[A\n",
            " 90% 309/342 [00:28<00:03, 10.95it/s]\u001b[A\n",
            " 91% 311/342 [00:28<00:02, 11.52it/s]\u001b[A\n",
            " 92% 313/342 [00:28<00:02, 11.51it/s]\u001b[A\n",
            " 92% 315/342 [00:28<00:02, 11.34it/s]\u001b[A\n",
            " 93% 317/342 [00:28<00:02, 12.08it/s]\u001b[A\n",
            " 93% 319/342 [00:29<00:02, 10.75it/s]\u001b[A\n",
            " 94% 321/342 [00:29<00:01, 11.27it/s]\u001b[A\n",
            " 94% 323/342 [00:29<00:01, 11.56it/s]\u001b[A\n",
            " 95% 325/342 [00:29<00:01, 11.53it/s]\u001b[A\n",
            " 96% 327/342 [00:29<00:01, 11.05it/s]\u001b[A\n",
            " 96% 329/342 [00:29<00:01, 10.81it/s]\u001b[A\n",
            " 97% 331/342 [00:30<00:01, 10.86it/s]\u001b[A\n",
            " 97% 333/342 [00:30<00:00, 11.09it/s]\u001b[A\n",
            " 98% 335/342 [00:30<00:00, 11.11it/s]\u001b[A\n",
            " 99% 337/342 [00:30<00:00, 11.54it/s]\u001b[A\n",
            " 99% 339/342 [00:30<00:00, 12.48it/s]\u001b[A\n",
            "                                             \n",
            "\u001b[A{'eval_loss': 0.2820471227169037, 'eval_accuracy': 0.9154310818231741, 'eval_runtime': 31.0699, 'eval_samples_per_second': 175.829, 'eval_steps_per_second': 11.007, 'epoch': 2.0}\n",
            " 40% 13094/32735 [1:01:29<1:20:40,  4.06it/s]\n",
            "100% 342/342 [00:30<00:00, 12.25it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-qnli/checkpoint-13094\n",
            "Configuration saved in bert-base-uncased-finetuned-qnli/checkpoint-13094/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-qnli/checkpoint-13094/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-qnli/checkpoint-13094/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-qnli/checkpoint-13094/special_tokens_map.json\n",
            "{'loss': 0.1209, 'learning_rate': 1.1751947456850468e-05, 'epoch': 2.06}\n",
            "{'loss': 0.1159, 'learning_rate': 1.144646402932641e-05, 'epoch': 2.14}\n",
            "{'loss': 0.1127, 'learning_rate': 1.1140980601802354e-05, 'epoch': 2.21}\n",
            "{'loss': 0.1309, 'learning_rate': 1.0835497174278296e-05, 'epoch': 2.29}\n",
            "{'loss': 0.1228, 'learning_rate': 1.053001374675424e-05, 'epoch': 2.37}\n",
            "{'loss': 0.1354, 'learning_rate': 1.0224530319230184e-05, 'epoch': 2.44}\n",
            "{'loss': 0.1213, 'learning_rate': 9.919046891706126e-06, 'epoch': 2.52}\n",
            "{'loss': 0.1335, 'learning_rate': 9.613563464182069e-06, 'epoch': 2.6}\n",
            "{'loss': 0.1316, 'learning_rate': 9.308080036658012e-06, 'epoch': 2.67}\n",
            "{'loss': 0.1236, 'learning_rate': 9.002596609133956e-06, 'epoch': 2.75}\n",
            "{'loss': 0.1295, 'learning_rate': 8.697113181609899e-06, 'epoch': 2.83}\n",
            "{'loss': 0.125, 'learning_rate': 8.391629754085842e-06, 'epoch': 2.9}\n",
            "{'loss': 0.1332, 'learning_rate': 8.086146326561785e-06, 'epoch': 2.98}\n",
            " 60% 19641/32735 [1:31:41<51:44,  4.22it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/342 [00:00<00:18, 18.60it/s]\u001b[A\n",
            "  1% 4/342 [00:00<00:33,  9.96it/s]\u001b[A\n",
            "  2% 6/342 [00:00<00:32, 10.29it/s]\u001b[A\n",
            "  2% 8/342 [00:00<00:33, 10.02it/s]\u001b[A\n",
            "  3% 10/342 [00:00<00:30, 11.04it/s]\u001b[A\n",
            "  4% 12/342 [00:01<00:28, 11.71it/s]\u001b[A\n",
            "  4% 14/342 [00:01<00:29, 11.20it/s]\u001b[A\n",
            "  5% 16/342 [00:01<00:28, 11.43it/s]\u001b[A\n",
            "  5% 18/342 [00:01<00:27, 11.61it/s]\u001b[A\n",
            "  6% 20/342 [00:01<00:27, 11.65it/s]\u001b[A\n",
            "  6% 22/342 [00:01<00:27, 11.58it/s]\u001b[A\n",
            "  7% 24/342 [00:02<00:28, 11.32it/s]\u001b[A\n",
            "  8% 26/342 [00:02<00:30, 10.48it/s]\u001b[A\n",
            "  8% 28/342 [00:02<00:28, 10.99it/s]\u001b[A\n",
            "  9% 30/342 [00:02<00:37,  8.37it/s]\u001b[A\n",
            "  9% 32/342 [00:03<00:32,  9.48it/s]\u001b[A\n",
            " 10% 34/342 [00:03<00:30, 10.09it/s]\u001b[A\n",
            " 11% 36/342 [00:03<00:29, 10.42it/s]\u001b[A\n",
            " 11% 38/342 [00:03<00:28, 10.71it/s]\u001b[A\n",
            " 12% 40/342 [00:03<00:26, 11.37it/s]\u001b[A\n",
            " 12% 42/342 [00:03<00:25, 11.85it/s]\u001b[A\n",
            " 13% 44/342 [00:04<00:25, 11.58it/s]\u001b[A\n",
            " 13% 46/342 [00:04<00:28, 10.49it/s]\u001b[A\n",
            " 14% 48/342 [00:04<00:28, 10.47it/s]\u001b[A\n",
            " 15% 50/342 [00:04<00:30,  9.46it/s]\u001b[A\n",
            " 15% 52/342 [00:04<00:30,  9.40it/s]\u001b[A\n",
            " 16% 54/342 [00:05<00:28, 10.22it/s]\u001b[A\n",
            " 16% 56/342 [00:05<00:26, 10.84it/s]\u001b[A\n",
            " 17% 58/342 [00:05<00:27, 10.31it/s]\u001b[A\n",
            " 18% 60/342 [00:05<00:25, 10.87it/s]\u001b[A\n",
            " 18% 62/342 [00:05<00:26, 10.39it/s]\u001b[A\n",
            " 19% 64/342 [00:06<00:26, 10.50it/s]\u001b[A\n",
            " 19% 66/342 [00:06<00:24, 11.08it/s]\u001b[A\n",
            " 20% 68/342 [00:06<00:24, 11.09it/s]\u001b[A\n",
            " 20% 70/342 [00:06<00:29,  9.10it/s]\u001b[A\n",
            " 21% 72/342 [00:06<00:28,  9.58it/s]\u001b[A\n",
            " 22% 74/342 [00:07<00:26, 10.17it/s]\u001b[A\n",
            " 22% 76/342 [00:07<00:23, 11.41it/s]\u001b[A\n",
            " 23% 78/342 [00:07<00:22, 11.65it/s]\u001b[A\n",
            " 23% 80/342 [00:07<00:21, 12.00it/s]\u001b[A\n",
            " 24% 82/342 [00:07<00:21, 12.06it/s]\u001b[A\n",
            " 25% 84/342 [00:07<00:21, 12.12it/s]\u001b[A\n",
            " 25% 86/342 [00:07<00:21, 12.06it/s]\u001b[A\n",
            " 26% 88/342 [00:08<00:23, 10.95it/s]\u001b[A\n",
            " 26% 90/342 [00:08<00:23, 10.66it/s]\u001b[A\n",
            " 27% 92/342 [00:08<00:22, 11.21it/s]\u001b[A\n",
            " 27% 94/342 [00:08<00:21, 11.61it/s]\u001b[A\n",
            " 28% 96/342 [00:08<00:19, 12.77it/s]\u001b[A\n",
            " 29% 98/342 [00:09<00:20, 11.84it/s]\u001b[A\n",
            " 29% 100/342 [00:09<00:20, 12.09it/s]\u001b[A\n",
            " 30% 102/342 [00:09<00:19, 12.02it/s]\u001b[A\n",
            " 30% 104/342 [00:09<00:19, 12.04it/s]\u001b[A\n",
            " 31% 106/342 [00:09<00:20, 11.51it/s]\u001b[A\n",
            " 32% 108/342 [00:09<00:19, 11.88it/s]\u001b[A\n",
            " 32% 110/342 [00:10<00:19, 11.87it/s]\u001b[A\n",
            " 33% 112/342 [00:10<00:19, 11.91it/s]\u001b[A\n",
            " 33% 114/342 [00:10<00:19, 11.89it/s]\u001b[A\n",
            " 34% 116/342 [00:10<00:21, 10.57it/s]\u001b[A\n",
            " 35% 118/342 [00:10<00:21, 10.19it/s]\u001b[A\n",
            " 35% 120/342 [00:10<00:20, 10.95it/s]\u001b[A\n",
            " 36% 122/342 [00:11<00:21, 10.17it/s]\u001b[A\n",
            " 36% 124/342 [00:11<00:20, 10.85it/s]\u001b[A\n",
            " 37% 126/342 [00:11<00:19, 11.23it/s]\u001b[A\n",
            " 37% 128/342 [00:11<00:18, 11.74it/s]\u001b[A\n",
            " 38% 130/342 [00:11<00:19, 10.77it/s]\u001b[A\n",
            " 39% 132/342 [00:12<00:19, 10.88it/s]\u001b[A\n",
            " 39% 134/342 [00:12<00:18, 11.31it/s]\u001b[A\n",
            " 40% 136/342 [00:12<00:18, 11.06it/s]\u001b[A\n",
            " 40% 138/342 [00:12<00:19, 10.63it/s]\u001b[A\n",
            " 41% 140/342 [00:12<00:18, 10.65it/s]\u001b[A\n",
            " 42% 142/342 [00:12<00:18, 10.53it/s]\u001b[A\n",
            " 42% 144/342 [00:13<00:18, 10.98it/s]\u001b[A\n",
            " 43% 146/342 [00:13<00:17, 11.36it/s]\u001b[A\n",
            " 43% 148/342 [00:13<00:16, 11.69it/s]\u001b[A\n",
            " 44% 150/342 [00:13<00:16, 11.40it/s]\u001b[A\n",
            " 44% 152/342 [00:13<00:18, 10.06it/s]\u001b[A\n",
            " 45% 154/342 [00:14<00:19,  9.45it/s]\u001b[A\n",
            " 46% 156/342 [00:14<00:18, 10.09it/s]\u001b[A\n",
            " 46% 158/342 [00:14<00:19,  9.43it/s]\u001b[A\n",
            " 46% 159/342 [00:14<00:21,  8.45it/s]\u001b[A\n",
            " 47% 161/342 [00:14<00:21,  8.57it/s]\u001b[A\n",
            " 48% 163/342 [00:15<00:19,  9.03it/s]\u001b[A\n",
            " 48% 165/342 [00:15<00:17,  9.84it/s]\u001b[A\n",
            " 49% 167/342 [00:15<00:16, 10.63it/s]\u001b[A\n",
            " 49% 169/342 [00:15<00:14, 11.81it/s]\u001b[A\n",
            " 50% 171/342 [00:15<00:14, 11.62it/s]\u001b[A\n",
            " 51% 173/342 [00:15<00:13, 12.60it/s]\u001b[A\n",
            " 51% 175/342 [00:16<00:14, 11.86it/s]\u001b[A\n",
            " 52% 177/342 [00:16<00:14, 11.20it/s]\u001b[A\n",
            " 52% 179/342 [00:16<00:14, 11.18it/s]\u001b[A\n",
            " 53% 181/342 [00:16<00:14, 11.04it/s]\u001b[A\n",
            " 54% 183/342 [00:16<00:13, 11.42it/s]\u001b[A\n",
            " 54% 185/342 [00:17<00:13, 11.73it/s]\u001b[A\n",
            " 55% 187/342 [00:17<00:14, 10.46it/s]\u001b[A\n",
            " 55% 189/342 [00:17<00:14, 10.83it/s]\u001b[A\n",
            " 56% 191/342 [00:17<00:14, 10.36it/s]\u001b[A\n",
            " 56% 193/342 [00:17<00:14, 10.22it/s]\u001b[A\n",
            " 57% 195/342 [00:17<00:13, 11.14it/s]\u001b[A\n",
            " 58% 197/342 [00:18<00:12, 11.45it/s]\u001b[A\n",
            " 58% 199/342 [00:18<00:14, 10.20it/s]\u001b[A\n",
            " 59% 201/342 [00:18<00:14,  9.42it/s]\u001b[A\n",
            " 59% 203/342 [00:18<00:13, 10.38it/s]\u001b[A\n",
            " 60% 205/342 [00:19<00:15,  9.05it/s]\u001b[A\n",
            " 61% 207/342 [00:19<00:13,  9.77it/s]\u001b[A\n",
            " 61% 209/342 [00:19<00:13,  9.57it/s]\u001b[A\n",
            " 62% 211/342 [00:19<00:13,  9.64it/s]\u001b[A\n",
            " 62% 213/342 [00:19<00:12, 10.23it/s]\u001b[A\n",
            " 63% 215/342 [00:20<00:12, 10.51it/s]\u001b[A\n",
            " 63% 217/342 [00:20<00:11, 10.97it/s]\u001b[A\n",
            " 64% 219/342 [00:20<00:12,  9.81it/s]\u001b[A\n",
            " 65% 221/342 [00:20<00:11, 10.46it/s]\u001b[A\n",
            " 65% 223/342 [00:20<00:10, 11.21it/s]\u001b[A\n",
            " 66% 225/342 [00:20<00:10, 11.48it/s]\u001b[A\n",
            " 66% 227/342 [00:21<00:09, 12.19it/s]\u001b[A\n",
            " 67% 229/342 [00:21<00:08, 12.61it/s]\u001b[A\n",
            " 68% 231/342 [00:21<00:09, 11.93it/s]\u001b[A\n",
            " 68% 233/342 [00:21<00:09, 11.57it/s]\u001b[A\n",
            " 69% 235/342 [00:21<00:09, 11.28it/s]\u001b[A\n",
            " 69% 237/342 [00:21<00:09, 10.96it/s]\u001b[A\n",
            " 70% 239/342 [00:22<00:09, 10.93it/s]\u001b[A\n",
            " 70% 241/342 [00:22<00:08, 11.38it/s]\u001b[A\n",
            " 71% 243/342 [00:22<00:08, 11.76it/s]\u001b[A\n",
            " 72% 245/342 [00:22<00:08, 12.08it/s]\u001b[A\n",
            " 72% 247/342 [00:22<00:08, 11.57it/s]\u001b[A\n",
            " 73% 249/342 [00:22<00:07, 11.82it/s]\u001b[A\n",
            " 73% 251/342 [00:23<00:07, 11.65it/s]\u001b[A\n",
            " 74% 253/342 [00:23<00:07, 12.05it/s]\u001b[A\n",
            " 75% 255/342 [00:23<00:07, 12.06it/s]\u001b[A\n",
            " 75% 257/342 [00:23<00:07, 11.84it/s]\u001b[A\n",
            " 76% 259/342 [00:23<00:07, 11.71it/s]\u001b[A\n",
            " 76% 261/342 [00:23<00:07, 11.00it/s]\u001b[A\n",
            " 77% 263/342 [00:24<00:07, 11.21it/s]\u001b[A\n",
            " 77% 265/342 [00:24<00:06, 11.21it/s]\u001b[A\n",
            " 78% 267/342 [00:24<00:07, 10.34it/s]\u001b[A\n",
            " 79% 269/342 [00:24<00:06, 11.02it/s]\u001b[A\n",
            " 79% 271/342 [00:24<00:06, 11.69it/s]\u001b[A\n",
            " 80% 273/342 [00:25<00:05, 11.55it/s]\u001b[A\n",
            " 80% 275/342 [00:25<00:05, 11.76it/s]\u001b[A\n",
            " 81% 277/342 [00:25<00:05, 12.10it/s]\u001b[A\n",
            " 82% 279/342 [00:25<00:05, 12.06it/s]\u001b[A\n",
            " 82% 281/342 [00:25<00:04, 12.37it/s]\u001b[A\n",
            " 83% 283/342 [00:25<00:04, 12.11it/s]\u001b[A\n",
            " 83% 285/342 [00:26<00:05, 10.23it/s]\u001b[A\n",
            " 84% 287/342 [00:26<00:04, 11.07it/s]\u001b[A\n",
            " 85% 289/342 [00:26<00:04, 11.77it/s]\u001b[A\n",
            " 85% 291/342 [00:26<00:04, 11.16it/s]\u001b[A\n",
            " 86% 293/342 [00:26<00:04, 10.82it/s]\u001b[A\n",
            " 86% 295/342 [00:26<00:04, 11.23it/s]\u001b[A\n",
            " 87% 297/342 [00:27<00:04, 11.23it/s]\u001b[A\n",
            " 87% 299/342 [00:27<00:03, 11.27it/s]\u001b[A\n",
            " 88% 301/342 [00:27<00:03, 11.26it/s]\u001b[A\n",
            " 89% 303/342 [00:27<00:03, 11.15it/s]\u001b[A\n",
            " 89% 305/342 [00:27<00:03, 11.42it/s]\u001b[A\n",
            " 90% 307/342 [00:28<00:03, 10.16it/s]\u001b[A\n",
            " 90% 309/342 [00:28<00:03, 10.82it/s]\u001b[A\n",
            " 91% 311/342 [00:28<00:02, 11.54it/s]\u001b[A\n",
            " 92% 313/342 [00:28<00:02, 11.48it/s]\u001b[A\n",
            " 92% 315/342 [00:28<00:02, 11.34it/s]\u001b[A\n",
            " 93% 317/342 [00:28<00:02, 12.04it/s]\u001b[A\n",
            " 93% 319/342 [00:29<00:02, 10.72it/s]\u001b[A\n",
            " 94% 321/342 [00:29<00:01, 11.27it/s]\u001b[A\n",
            " 94% 323/342 [00:29<00:01, 11.58it/s]\u001b[A\n",
            " 95% 325/342 [00:29<00:01, 11.53it/s]\u001b[A\n",
            " 96% 327/342 [00:29<00:01, 10.98it/s]\u001b[A\n",
            " 96% 329/342 [00:30<00:01, 10.81it/s]\u001b[A\n",
            " 97% 331/342 [00:30<00:01, 10.82it/s]\u001b[A\n",
            " 97% 333/342 [00:30<00:00, 11.02it/s]\u001b[A\n",
            " 98% 335/342 [00:30<00:00, 11.05it/s]\u001b[A\n",
            " 99% 337/342 [00:30<00:00, 11.43it/s]\u001b[A\n",
            " 99% 339/342 [00:30<00:00, 12.34it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.3927394151687622, 'eval_accuracy': 0.9139666849716274, 'eval_runtime': 31.1845, 'eval_samples_per_second': 175.183, 'eval_steps_per_second': 10.967, 'epoch': 3.0}\n",
            " 60% 19641/32735 [1:32:12<51:44,  4.22it/s]\n",
            "100% 342/342 [00:31<00:00, 12.16it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-qnli/checkpoint-19641\n",
            "Configuration saved in bert-base-uncased-finetuned-qnli/checkpoint-19641/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-qnli/checkpoint-19641/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-qnli/checkpoint-19641/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-qnli/checkpoint-19641/special_tokens_map.json\n",
            "{'loss': 0.0754, 'learning_rate': 7.780662899037727e-06, 'epoch': 3.05}\n",
            "{'loss': 0.0655, 'learning_rate': 7.47517947151367e-06, 'epoch': 3.13}\n",
            "{'loss': 0.0801, 'learning_rate': 7.169696043989614e-06, 'epoch': 3.21}\n",
            "{'loss': 0.0702, 'learning_rate': 6.8642126164655576e-06, 'epoch': 3.28}\n",
            "{'loss': 0.0698, 'learning_rate': 6.558729188941501e-06, 'epoch': 3.36}\n",
            "{'loss': 0.061, 'learning_rate': 6.253245761417443e-06, 'epoch': 3.44}\n",
            "{'loss': 0.0687, 'learning_rate': 5.9477623338933865e-06, 'epoch': 3.51}\n",
            "{'loss': 0.0727, 'learning_rate': 5.64227890636933e-06, 'epoch': 3.59}\n",
            "{'loss': 0.0706, 'learning_rate': 5.336795478845274e-06, 'epoch': 3.67}\n",
            "{'loss': 0.0681, 'learning_rate': 5.031312051321216e-06, 'epoch': 3.74}\n",
            "{'loss': 0.0712, 'learning_rate': 4.7258286237971595e-06, 'epoch': 3.82}\n",
            "{'loss': 0.0631, 'learning_rate': 4.420345196273103e-06, 'epoch': 3.89}\n",
            "{'loss': 0.0674, 'learning_rate': 4.114861768749045e-06, 'epoch': 3.97}\n",
            " 80% 26188/32735 [2:02:25<26:27,  4.12it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/342 [00:00<00:19, 17.84it/s]\u001b[A\n",
            "  1% 4/342 [00:00<00:33,  9.98it/s]\u001b[A\n",
            "  2% 6/342 [00:00<00:32, 10.41it/s]\u001b[A\n",
            "  2% 8/342 [00:00<00:32, 10.20it/s]\u001b[A\n",
            "  3% 10/342 [00:00<00:29, 11.14it/s]\u001b[A\n",
            "  4% 12/342 [00:01<00:28, 11.78it/s]\u001b[A\n",
            "  4% 14/342 [00:01<00:29, 11.20it/s]\u001b[A\n",
            "  5% 16/342 [00:01<00:28, 11.51it/s]\u001b[A\n",
            "  5% 18/342 [00:01<00:27, 11.69it/s]\u001b[A\n",
            "  6% 20/342 [00:01<00:27, 11.71it/s]\u001b[A\n",
            "  6% 22/342 [00:01<00:27, 11.69it/s]\u001b[A\n",
            "  7% 24/342 [00:02<00:28, 11.30it/s]\u001b[A\n",
            "  8% 26/342 [00:02<00:30, 10.39it/s]\u001b[A\n",
            "  8% 28/342 [00:02<00:28, 10.92it/s]\u001b[A\n",
            "  9% 30/342 [00:02<00:37,  8.34it/s]\u001b[A\n",
            "  9% 32/342 [00:03<00:32,  9.47it/s]\u001b[A\n",
            " 10% 34/342 [00:03<00:30, 10.01it/s]\u001b[A\n",
            " 11% 36/342 [00:03<00:29, 10.33it/s]\u001b[A\n",
            " 11% 38/342 [00:03<00:28, 10.58it/s]\u001b[A\n",
            " 12% 40/342 [00:03<00:26, 11.27it/s]\u001b[A\n",
            " 12% 42/342 [00:03<00:25, 11.76it/s]\u001b[A\n",
            " 13% 44/342 [00:04<00:25, 11.57it/s]\u001b[A\n",
            " 13% 46/342 [00:04<00:28, 10.49it/s]\u001b[A\n",
            " 14% 48/342 [00:04<00:28, 10.49it/s]\u001b[A\n",
            " 15% 50/342 [00:04<00:30,  9.50it/s]\u001b[A\n",
            " 15% 52/342 [00:04<00:30,  9.44it/s]\u001b[A\n",
            " 16% 54/342 [00:05<00:28, 10.24it/s]\u001b[A\n",
            " 16% 56/342 [00:05<00:26, 10.89it/s]\u001b[A\n",
            " 17% 58/342 [00:05<00:27, 10.27it/s]\u001b[A\n",
            " 18% 60/342 [00:05<00:26, 10.83it/s]\u001b[A\n",
            " 18% 62/342 [00:05<00:27, 10.32it/s]\u001b[A\n",
            " 19% 64/342 [00:06<00:26, 10.42it/s]\u001b[A\n",
            " 19% 66/342 [00:06<00:25, 11.03it/s]\u001b[A\n",
            " 20% 68/342 [00:06<00:24, 11.08it/s]\u001b[A\n",
            " 20% 70/342 [00:06<00:29,  9.15it/s]\u001b[A\n",
            " 21% 72/342 [00:06<00:27,  9.64it/s]\u001b[A\n",
            " 22% 74/342 [00:07<00:26, 10.29it/s]\u001b[A\n",
            " 22% 76/342 [00:07<00:23, 11.52it/s]\u001b[A\n",
            " 23% 78/342 [00:07<00:22, 11.71it/s]\u001b[A\n",
            " 23% 80/342 [00:07<00:21, 12.03it/s]\u001b[A\n",
            " 24% 82/342 [00:07<00:21, 12.11it/s]\u001b[A\n",
            " 25% 84/342 [00:07<00:21, 12.17it/s]\u001b[A\n",
            " 25% 86/342 [00:07<00:21, 12.14it/s]\u001b[A\n",
            " 26% 88/342 [00:08<00:23, 11.03it/s]\u001b[A\n",
            " 26% 90/342 [00:08<00:23, 10.81it/s]\u001b[A\n",
            " 27% 92/342 [00:08<00:22, 11.21it/s]\u001b[A\n",
            " 27% 94/342 [00:08<00:21, 11.47it/s]\u001b[A\n",
            " 28% 96/342 [00:08<00:19, 12.70it/s]\u001b[A\n",
            " 29% 98/342 [00:09<00:20, 11.94it/s]\u001b[A\n",
            " 29% 100/342 [00:09<00:19, 12.29it/s]\u001b[A\n",
            " 30% 102/342 [00:09<00:19, 12.10it/s]\u001b[A\n",
            " 30% 104/342 [00:09<00:19, 12.11it/s]\u001b[A\n",
            " 31% 106/342 [00:09<00:20, 11.48it/s]\u001b[A\n",
            " 32% 108/342 [00:09<00:19, 11.76it/s]\u001b[A\n",
            " 32% 110/342 [00:10<00:19, 11.79it/s]\u001b[A\n",
            " 33% 112/342 [00:10<00:19, 11.93it/s]\u001b[A\n",
            " 33% 114/342 [00:10<00:19, 11.94it/s]\u001b[A\n",
            " 34% 116/342 [00:10<00:21, 10.60it/s]\u001b[A\n",
            " 35% 118/342 [00:10<00:21, 10.23it/s]\u001b[A\n",
            " 35% 120/342 [00:10<00:20, 10.95it/s]\u001b[A\n",
            " 36% 122/342 [00:11<00:21, 10.20it/s]\u001b[A\n",
            " 36% 124/342 [00:11<00:20, 10.86it/s]\u001b[A\n",
            " 37% 126/342 [00:11<00:19, 11.26it/s]\u001b[A\n",
            " 37% 128/342 [00:11<00:18, 11.78it/s]\u001b[A\n",
            " 38% 130/342 [00:11<00:19, 10.71it/s]\u001b[A\n",
            " 39% 132/342 [00:12<00:19, 10.90it/s]\u001b[A\n",
            " 39% 134/342 [00:12<00:18, 11.34it/s]\u001b[A\n",
            " 40% 136/342 [00:12<00:18, 11.04it/s]\u001b[A\n",
            " 40% 138/342 [00:12<00:19, 10.61it/s]\u001b[A\n",
            " 41% 140/342 [00:12<00:19, 10.63it/s]\u001b[A\n",
            " 42% 142/342 [00:12<00:18, 10.53it/s]\u001b[A\n",
            " 42% 144/342 [00:13<00:18, 10.98it/s]\u001b[A\n",
            " 43% 146/342 [00:13<00:17, 11.43it/s]\u001b[A\n",
            " 43% 148/342 [00:13<00:16, 11.82it/s]\u001b[A\n",
            " 44% 150/342 [00:13<00:16, 11.33it/s]\u001b[A\n",
            " 44% 152/342 [00:13<00:18, 10.01it/s]\u001b[A\n",
            " 45% 154/342 [00:14<00:19,  9.44it/s]\u001b[A\n",
            " 46% 156/342 [00:14<00:18, 10.10it/s]\u001b[A\n",
            " 46% 158/342 [00:14<00:19,  9.44it/s]\u001b[A\n",
            " 46% 159/342 [00:14<00:21,  8.44it/s]\u001b[A\n",
            " 47% 161/342 [00:14<00:21,  8.57it/s]\u001b[A\n",
            " 48% 163/342 [00:15<00:19,  9.04it/s]\u001b[A\n",
            " 48% 165/342 [00:15<00:17,  9.89it/s]\u001b[A\n",
            " 49% 167/342 [00:15<00:16, 10.75it/s]\u001b[A\n",
            " 49% 169/342 [00:15<00:14, 11.93it/s]\u001b[A\n",
            " 50% 171/342 [00:15<00:14, 11.66it/s]\u001b[A\n",
            " 51% 173/342 [00:15<00:13, 12.58it/s]\u001b[A\n",
            " 51% 175/342 [00:16<00:14, 11.88it/s]\u001b[A\n",
            " 52% 177/342 [00:16<00:14, 11.28it/s]\u001b[A\n",
            " 52% 179/342 [00:16<00:14, 11.23it/s]\u001b[A\n",
            " 53% 181/342 [00:16<00:14, 10.95it/s]\u001b[A\n",
            " 54% 183/342 [00:16<00:14, 11.27it/s]\u001b[A\n",
            " 54% 185/342 [00:16<00:13, 11.56it/s]\u001b[A\n",
            " 55% 187/342 [00:17<00:14, 10.43it/s]\u001b[A\n",
            " 55% 189/342 [00:17<00:14, 10.86it/s]\u001b[A\n",
            " 56% 191/342 [00:17<00:14, 10.37it/s]\u001b[A\n",
            " 56% 193/342 [00:17<00:14, 10.23it/s]\u001b[A\n",
            " 57% 195/342 [00:17<00:13, 11.15it/s]\u001b[A\n",
            " 58% 197/342 [00:18<00:12, 11.43it/s]\u001b[A\n",
            " 58% 199/342 [00:18<00:14, 10.19it/s]\u001b[A\n",
            " 59% 201/342 [00:18<00:14,  9.42it/s]\u001b[A\n",
            " 59% 203/342 [00:18<00:13, 10.27it/s]\u001b[A\n",
            " 60% 205/342 [00:19<00:15,  9.02it/s]\u001b[A\n",
            " 61% 207/342 [00:19<00:13,  9.85it/s]\u001b[A\n",
            " 61% 209/342 [00:19<00:13,  9.60it/s]\u001b[A\n",
            " 62% 211/342 [00:19<00:13,  9.74it/s]\u001b[A\n",
            " 62% 213/342 [00:19<00:12, 10.32it/s]\u001b[A\n",
            " 63% 215/342 [00:19<00:12, 10.56it/s]\u001b[A\n",
            " 63% 217/342 [00:20<00:11, 11.05it/s]\u001b[A\n",
            " 64% 219/342 [00:20<00:12,  9.85it/s]\u001b[A\n",
            " 65% 221/342 [00:20<00:11, 10.51it/s]\u001b[A\n",
            " 65% 223/342 [00:20<00:10, 11.26it/s]\u001b[A\n",
            " 66% 225/342 [00:20<00:10, 11.58it/s]\u001b[A\n",
            " 66% 227/342 [00:21<00:09, 12.20it/s]\u001b[A\n",
            " 67% 229/342 [00:21<00:08, 12.59it/s]\u001b[A\n",
            " 68% 231/342 [00:21<00:09, 11.95it/s]\u001b[A\n",
            " 68% 233/342 [00:21<00:09, 11.55it/s]\u001b[A\n",
            " 69% 235/342 [00:21<00:09, 11.26it/s]\u001b[A\n",
            " 69% 237/342 [00:21<00:09, 10.99it/s]\u001b[A\n",
            " 70% 239/342 [00:22<00:09, 10.97it/s]\u001b[A\n",
            " 70% 241/342 [00:22<00:08, 11.50it/s]\u001b[A\n",
            " 71% 243/342 [00:22<00:08, 11.82it/s]\u001b[A\n",
            " 72% 245/342 [00:22<00:07, 12.18it/s]\u001b[A\n",
            " 72% 247/342 [00:22<00:08, 11.77it/s]\u001b[A\n",
            " 73% 249/342 [00:22<00:07, 11.92it/s]\u001b[A\n",
            " 73% 251/342 [00:23<00:07, 11.68it/s]\u001b[A\n",
            " 74% 253/342 [00:23<00:07, 12.22it/s]\u001b[A\n",
            " 75% 255/342 [00:23<00:07, 12.20it/s]\u001b[A\n",
            " 75% 257/342 [00:23<00:07, 11.91it/s]\u001b[A\n",
            " 76% 259/342 [00:23<00:07, 11.81it/s]\u001b[A\n",
            " 76% 261/342 [00:23<00:07, 11.03it/s]\u001b[A\n",
            " 77% 263/342 [00:24<00:07, 11.25it/s]\u001b[A\n",
            " 77% 265/342 [00:24<00:06, 11.25it/s]\u001b[A\n",
            " 78% 267/342 [00:24<00:07, 10.38it/s]\u001b[A\n",
            " 79% 269/342 [00:24<00:06, 11.04it/s]\u001b[A\n",
            " 79% 271/342 [00:24<00:06, 11.78it/s]\u001b[A\n",
            " 80% 273/342 [00:25<00:05, 11.64it/s]\u001b[A\n",
            " 80% 275/342 [00:25<00:05, 11.76it/s]\u001b[A\n",
            " 81% 277/342 [00:25<00:05, 12.06it/s]\u001b[A\n",
            " 82% 279/342 [00:25<00:05, 12.07it/s]\u001b[A\n",
            " 82% 281/342 [00:25<00:04, 12.44it/s]\u001b[A\n",
            " 83% 283/342 [00:25<00:04, 12.12it/s]\u001b[A\n",
            " 83% 285/342 [00:26<00:05, 10.22it/s]\u001b[A\n",
            " 84% 287/342 [00:26<00:04, 11.06it/s]\u001b[A\n",
            " 85% 289/342 [00:26<00:04, 11.77it/s]\u001b[A\n",
            " 85% 291/342 [00:26<00:04, 11.17it/s]\u001b[A\n",
            " 86% 293/342 [00:26<00:04, 10.80it/s]\u001b[A\n",
            " 86% 295/342 [00:26<00:04, 11.17it/s]\u001b[A\n",
            " 87% 297/342 [00:27<00:04, 11.08it/s]\u001b[A\n",
            " 87% 299/342 [00:27<00:03, 11.20it/s]\u001b[A\n",
            " 88% 301/342 [00:27<00:03, 11.20it/s]\u001b[A\n",
            " 89% 303/342 [00:27<00:03, 11.03it/s]\u001b[A\n",
            " 89% 305/342 [00:27<00:03, 11.36it/s]\u001b[A\n",
            " 90% 307/342 [00:28<00:03, 10.05it/s]\u001b[A\n",
            " 90% 309/342 [00:28<00:03, 10.77it/s]\u001b[A\n",
            " 91% 311/342 [00:28<00:02, 11.53it/s]\u001b[A\n",
            " 92% 313/342 [00:28<00:02, 11.56it/s]\u001b[A\n",
            " 92% 315/342 [00:28<00:02, 11.39it/s]\u001b[A\n",
            " 93% 317/342 [00:28<00:02, 12.10it/s]\u001b[A\n",
            " 93% 319/342 [00:29<00:02, 10.78it/s]\u001b[A\n",
            " 94% 321/342 [00:29<00:01, 11.31it/s]\u001b[A\n",
            " 94% 323/342 [00:29<00:01, 11.63it/s]\u001b[A\n",
            " 95% 325/342 [00:29<00:01, 11.58it/s]\u001b[A\n",
            " 96% 327/342 [00:29<00:01, 11.09it/s]\u001b[A\n",
            " 96% 329/342 [00:29<00:01, 10.87it/s]\u001b[A\n",
            " 97% 331/342 [00:30<00:01, 10.84it/s]\u001b[A\n",
            " 97% 333/342 [00:30<00:00, 11.00it/s]\u001b[A\n",
            " 98% 335/342 [00:30<00:00, 11.08it/s]\u001b[A\n",
            " 99% 337/342 [00:30<00:00, 11.59it/s]\u001b[A\n",
            " 99% 339/342 [00:30<00:00, 12.38it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.49877285957336426, 'eval_accuracy': 0.9112209408749771, 'eval_runtime': 31.1392, 'eval_samples_per_second': 175.438, 'eval_steps_per_second': 10.983, 'epoch': 4.0}\n",
            " 80% 26188/32735 [2:02:56<26:27,  4.12it/s]\n",
            "100% 342/342 [00:31<00:00, 12.25it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-qnli/checkpoint-26188\n",
            "Configuration saved in bert-base-uncased-finetuned-qnli/checkpoint-26188/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-qnli/checkpoint-26188/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-qnli/checkpoint-26188/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-qnli/checkpoint-26188/special_tokens_map.json\n",
            "{'loss': 0.0492, 'learning_rate': 3.809378341224989e-06, 'epoch': 4.05}\n",
            "{'loss': 0.0316, 'learning_rate': 3.503894913700932e-06, 'epoch': 4.12}\n",
            "{'loss': 0.0386, 'learning_rate': 3.198411486176875e-06, 'epoch': 4.2}\n",
            "{'loss': 0.0336, 'learning_rate': 2.8929280586528187e-06, 'epoch': 4.28}\n",
            "{'loss': 0.0383, 'learning_rate': 2.5874446311287615e-06, 'epoch': 4.35}\n",
            "{'loss': 0.0343, 'learning_rate': 2.2819612036047043e-06, 'epoch': 4.43}\n",
            "{'loss': 0.0306, 'learning_rate': 1.9764777760806476e-06, 'epoch': 4.51}\n",
            "{'loss': 0.0334, 'learning_rate': 1.670994348556591e-06, 'epoch': 4.58}\n",
            "{'loss': 0.0447, 'learning_rate': 1.3655109210325341e-06, 'epoch': 4.66}\n",
            "{'loss': 0.0326, 'learning_rate': 1.0600274935084774e-06, 'epoch': 4.73}\n",
            "{'loss': 0.0372, 'learning_rate': 7.545440659844204e-07, 'epoch': 4.81}\n",
            "{'loss': 0.0344, 'learning_rate': 4.490606384603636e-07, 'epoch': 4.89}\n",
            "{'loss': 0.0319, 'learning_rate': 1.4357721093630674e-07, 'epoch': 4.96}\n",
            "100% 32735/32735 [2:33:10<00:00,  4.00it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/342 [00:00<00:18, 18.82it/s]\u001b[A\n",
            "  1% 4/342 [00:00<00:33, 10.18it/s]\u001b[A\n",
            "  2% 6/342 [00:00<00:32, 10.33it/s]\u001b[A\n",
            "  2% 8/342 [00:00<00:32, 10.16it/s]\u001b[A\n",
            "  3% 10/342 [00:00<00:29, 11.20it/s]\u001b[A\n",
            "  4% 12/342 [00:01<00:28, 11.74it/s]\u001b[A\n",
            "  4% 14/342 [00:01<00:29, 11.29it/s]\u001b[A\n",
            "  5% 16/342 [00:01<00:28, 11.42it/s]\u001b[A\n",
            "  5% 18/342 [00:01<00:27, 11.58it/s]\u001b[A\n",
            "  6% 20/342 [00:01<00:27, 11.68it/s]\u001b[A\n",
            "  6% 22/342 [00:01<00:27, 11.66it/s]\u001b[A\n",
            "  7% 24/342 [00:02<00:27, 11.40it/s]\u001b[A\n",
            "  8% 26/342 [00:02<00:29, 10.54it/s]\u001b[A\n",
            "  8% 28/342 [00:02<00:28, 11.03it/s]\u001b[A\n",
            "  9% 30/342 [00:02<00:37,  8.38it/s]\u001b[A\n",
            "  9% 32/342 [00:03<00:32,  9.53it/s]\u001b[A\n",
            " 10% 34/342 [00:03<00:30, 10.13it/s]\u001b[A\n",
            " 11% 36/342 [00:03<00:29, 10.37it/s]\u001b[A\n",
            " 11% 38/342 [00:03<00:28, 10.64it/s]\u001b[A\n",
            " 12% 40/342 [00:03<00:26, 11.24it/s]\u001b[A\n",
            " 12% 42/342 [00:03<00:25, 11.76it/s]\u001b[A\n",
            " 13% 44/342 [00:04<00:25, 11.55it/s]\u001b[A\n",
            " 13% 46/342 [00:04<00:28, 10.55it/s]\u001b[A\n",
            " 14% 48/342 [00:04<00:27, 10.50it/s]\u001b[A\n",
            " 15% 50/342 [00:04<00:30,  9.47it/s]\u001b[A\n",
            " 15% 52/342 [00:04<00:30,  9.43it/s]\u001b[A\n",
            " 16% 54/342 [00:05<00:28, 10.24it/s]\u001b[A\n",
            " 16% 56/342 [00:05<00:26, 10.90it/s]\u001b[A\n",
            " 17% 58/342 [00:05<00:27, 10.29it/s]\u001b[A\n",
            " 18% 60/342 [00:05<00:26, 10.84it/s]\u001b[A\n",
            " 18% 62/342 [00:05<00:27, 10.35it/s]\u001b[A\n",
            " 19% 64/342 [00:06<00:26, 10.53it/s]\u001b[A\n",
            " 19% 66/342 [00:06<00:24, 11.18it/s]\u001b[A\n",
            " 20% 68/342 [00:06<00:24, 11.21it/s]\u001b[A\n",
            " 20% 70/342 [00:06<00:29,  9.24it/s]\u001b[A\n",
            " 21% 72/342 [00:06<00:27,  9.71it/s]\u001b[A\n",
            " 22% 74/342 [00:06<00:25, 10.34it/s]\u001b[A\n",
            " 22% 76/342 [00:07<00:23, 11.53it/s]\u001b[A\n",
            " 23% 78/342 [00:07<00:22, 11.66it/s]\u001b[A\n",
            " 23% 80/342 [00:07<00:21, 11.99it/s]\u001b[A\n",
            " 24% 82/342 [00:07<00:21, 12.07it/s]\u001b[A\n",
            " 25% 84/342 [00:07<00:21, 12.01it/s]\u001b[A\n",
            " 25% 86/342 [00:07<00:21, 12.00it/s]\u001b[A\n",
            " 26% 88/342 [00:08<00:23, 11.01it/s]\u001b[A\n",
            " 26% 90/342 [00:08<00:23, 10.77it/s]\u001b[A\n",
            " 27% 92/342 [00:08<00:22, 11.34it/s]\u001b[A\n",
            " 27% 94/342 [00:08<00:21, 11.57it/s]\u001b[A\n",
            " 28% 96/342 [00:08<00:19, 12.83it/s]\u001b[A\n",
            " 29% 98/342 [00:08<00:20, 12.04it/s]\u001b[A\n",
            " 29% 100/342 [00:09<00:19, 12.19it/s]\u001b[A\n",
            " 30% 102/342 [00:09<00:20, 11.94it/s]\u001b[A\n",
            " 30% 104/342 [00:09<00:19, 12.03it/s]\u001b[A\n",
            " 31% 106/342 [00:09<00:20, 11.52it/s]\u001b[A\n",
            " 32% 108/342 [00:09<00:20, 11.70it/s]\u001b[A\n",
            " 32% 110/342 [00:09<00:19, 11.77it/s]\u001b[A\n",
            " 33% 112/342 [00:10<00:19, 11.86it/s]\u001b[A\n",
            " 33% 114/342 [00:10<00:19, 11.86it/s]\u001b[A\n",
            " 34% 116/342 [00:10<00:21, 10.59it/s]\u001b[A\n",
            " 35% 118/342 [00:10<00:21, 10.32it/s]\u001b[A\n",
            " 35% 120/342 [00:10<00:20, 11.09it/s]\u001b[A\n",
            " 36% 122/342 [00:11<00:21, 10.35it/s]\u001b[A\n",
            " 36% 124/342 [00:11<00:19, 11.00it/s]\u001b[A\n",
            " 37% 126/342 [00:11<00:18, 11.42it/s]\u001b[A\n",
            " 37% 128/342 [00:11<00:18, 11.89it/s]\u001b[A\n",
            " 38% 130/342 [00:11<00:19, 10.80it/s]\u001b[A\n",
            " 39% 132/342 [00:12<00:19, 10.92it/s]\u001b[A\n",
            " 39% 134/342 [00:12<00:18, 11.34it/s]\u001b[A\n",
            " 40% 136/342 [00:12<00:18, 11.05it/s]\u001b[A\n",
            " 40% 138/342 [00:12<00:19, 10.67it/s]\u001b[A\n",
            " 41% 140/342 [00:12<00:18, 10.67it/s]\u001b[A\n",
            " 42% 142/342 [00:12<00:18, 10.57it/s]\u001b[A\n",
            " 42% 144/342 [00:13<00:18, 11.00it/s]\u001b[A\n",
            " 43% 146/342 [00:13<00:17, 11.42it/s]\u001b[A\n",
            " 43% 148/342 [00:13<00:16, 11.79it/s]\u001b[A\n",
            " 44% 150/342 [00:13<00:16, 11.36it/s]\u001b[A\n",
            " 44% 152/342 [00:13<00:18, 10.08it/s]\u001b[A\n",
            " 45% 154/342 [00:14<00:19,  9.51it/s]\u001b[A\n",
            " 46% 156/342 [00:14<00:18, 10.16it/s]\u001b[A\n",
            " 46% 158/342 [00:14<00:19,  9.42it/s]\u001b[A\n",
            " 46% 159/342 [00:14<00:21,  8.42it/s]\u001b[A\n",
            " 47% 161/342 [00:14<00:21,  8.55it/s]\u001b[A\n",
            " 48% 163/342 [00:15<00:19,  9.04it/s]\u001b[A\n",
            " 48% 165/342 [00:15<00:17,  9.87it/s]\u001b[A\n",
            " 49% 167/342 [00:15<00:16, 10.70it/s]\u001b[A\n",
            " 49% 169/342 [00:15<00:14, 11.92it/s]\u001b[A\n",
            " 50% 171/342 [00:15<00:14, 11.65it/s]\u001b[A\n",
            " 51% 173/342 [00:15<00:13, 12.57it/s]\u001b[A\n",
            " 51% 175/342 [00:16<00:14, 11.86it/s]\u001b[A\n",
            " 52% 177/342 [00:16<00:14, 11.23it/s]\u001b[A\n",
            " 52% 179/342 [00:16<00:14, 11.19it/s]\u001b[A\n",
            " 53% 181/342 [00:16<00:14, 11.04it/s]\u001b[A\n",
            " 54% 183/342 [00:16<00:13, 11.39it/s]\u001b[A\n",
            " 54% 185/342 [00:16<00:13, 11.78it/s]\u001b[A\n",
            " 55% 187/342 [00:17<00:14, 10.53it/s]\u001b[A\n",
            " 55% 189/342 [00:17<00:14, 10.87it/s]\u001b[A\n",
            " 56% 191/342 [00:17<00:14, 10.43it/s]\u001b[A\n",
            " 56% 193/342 [00:17<00:14, 10.33it/s]\u001b[A\n",
            " 57% 195/342 [00:17<00:13, 11.29it/s]\u001b[A\n",
            " 58% 197/342 [00:18<00:12, 11.64it/s]\u001b[A\n",
            " 58% 199/342 [00:18<00:13, 10.28it/s]\u001b[A\n",
            " 59% 201/342 [00:18<00:14,  9.43it/s]\u001b[A\n",
            " 59% 203/342 [00:18<00:13, 10.30it/s]\u001b[A\n",
            " 60% 205/342 [00:18<00:15,  9.07it/s]\u001b[A\n",
            " 61% 207/342 [00:19<00:13,  9.88it/s]\u001b[A\n",
            " 61% 209/342 [00:19<00:13,  9.60it/s]\u001b[A\n",
            " 62% 211/342 [00:19<00:13,  9.70it/s]\u001b[A\n",
            " 62% 213/342 [00:19<00:12, 10.33it/s]\u001b[A\n",
            " 63% 215/342 [00:19<00:11, 10.59it/s]\u001b[A\n",
            " 63% 217/342 [00:20<00:11, 11.09it/s]\u001b[A\n",
            " 64% 219/342 [00:20<00:12,  9.91it/s]\u001b[A\n",
            " 65% 221/342 [00:20<00:11, 10.59it/s]\u001b[A\n",
            " 65% 223/342 [00:20<00:10, 11.28it/s]\u001b[A\n",
            " 66% 225/342 [00:20<00:10, 11.55it/s]\u001b[A\n",
            " 66% 227/342 [00:20<00:09, 12.19it/s]\u001b[A\n",
            " 67% 229/342 [00:21<00:08, 12.58it/s]\u001b[A\n",
            " 68% 231/342 [00:21<00:09, 11.94it/s]\u001b[A\n",
            " 68% 233/342 [00:21<00:09, 11.58it/s]\u001b[A\n",
            " 69% 235/342 [00:21<00:09, 11.27it/s]\u001b[A\n",
            " 69% 237/342 [00:21<00:09, 10.94it/s]\u001b[A\n",
            " 70% 239/342 [00:22<00:09, 10.92it/s]\u001b[A\n",
            " 70% 241/342 [00:22<00:08, 11.45it/s]\u001b[A\n",
            " 71% 243/342 [00:22<00:08, 11.83it/s]\u001b[A\n",
            " 72% 245/342 [00:22<00:07, 12.15it/s]\u001b[A\n",
            " 72% 247/342 [00:22<00:08, 11.66it/s]\u001b[A\n",
            " 73% 249/342 [00:22<00:07, 11.84it/s]\u001b[A\n",
            " 73% 251/342 [00:23<00:07, 11.62it/s]\u001b[A\n",
            " 74% 253/342 [00:23<00:07, 12.19it/s]\u001b[A\n",
            " 75% 255/342 [00:23<00:07, 12.19it/s]\u001b[A\n",
            " 75% 257/342 [00:23<00:07, 12.02it/s]\u001b[A\n",
            " 76% 259/342 [00:23<00:07, 11.85it/s]\u001b[A\n",
            " 76% 261/342 [00:23<00:07, 11.07it/s]\u001b[A\n",
            " 77% 263/342 [00:24<00:06, 11.29it/s]\u001b[A\n",
            " 77% 265/342 [00:24<00:06, 11.29it/s]\u001b[A\n",
            " 78% 267/342 [00:24<00:07, 10.41it/s]\u001b[A\n",
            " 79% 269/342 [00:24<00:06, 11.05it/s]\u001b[A\n",
            " 79% 271/342 [00:24<00:06, 11.71it/s]\u001b[A\n",
            " 80% 273/342 [00:24<00:05, 11.58it/s]\u001b[A\n",
            " 80% 275/342 [00:25<00:05, 11.83it/s]\u001b[A\n",
            " 81% 277/342 [00:25<00:05, 12.13it/s]\u001b[A\n",
            " 82% 279/342 [00:25<00:05, 12.12it/s]\u001b[A\n",
            " 82% 281/342 [00:25<00:04, 12.43it/s]\u001b[A\n",
            " 83% 283/342 [00:25<00:04, 12.13it/s]\u001b[A\n",
            " 83% 285/342 [00:26<00:05, 10.21it/s]\u001b[A\n",
            " 84% 287/342 [00:26<00:04, 11.01it/s]\u001b[A\n",
            " 85% 289/342 [00:26<00:04, 11.63it/s]\u001b[A\n",
            " 85% 291/342 [00:26<00:04, 11.08it/s]\u001b[A\n",
            " 86% 293/342 [00:26<00:04, 10.82it/s]\u001b[A\n",
            " 86% 295/342 [00:26<00:04, 11.27it/s]\u001b[A\n",
            " 87% 297/342 [00:27<00:03, 11.25it/s]\u001b[A\n",
            " 87% 299/342 [00:27<00:03, 11.30it/s]\u001b[A\n",
            " 88% 301/342 [00:27<00:03, 11.23it/s]\u001b[A\n",
            " 89% 303/342 [00:27<00:03, 11.20it/s]\u001b[A\n",
            " 89% 305/342 [00:27<00:03, 11.41it/s]\u001b[A\n",
            " 90% 307/342 [00:28<00:03, 10.19it/s]\u001b[A\n",
            " 90% 309/342 [00:28<00:03, 10.86it/s]\u001b[A\n",
            " 91% 311/342 [00:28<00:02, 11.60it/s]\u001b[A\n",
            " 92% 313/342 [00:28<00:02, 11.53it/s]\u001b[A\n",
            " 92% 315/342 [00:28<00:02, 11.35it/s]\u001b[A\n",
            " 93% 317/342 [00:28<00:02, 12.08it/s]\u001b[A\n",
            " 93% 319/342 [00:29<00:02, 10.78it/s]\u001b[A\n",
            " 94% 321/342 [00:29<00:01, 11.36it/s]\u001b[A\n",
            " 94% 323/342 [00:29<00:01, 11.60it/s]\u001b[A\n",
            " 95% 325/342 [00:29<00:01, 11.55it/s]\u001b[A\n",
            " 96% 327/342 [00:29<00:01, 11.00it/s]\u001b[A\n",
            " 96% 329/342 [00:29<00:01, 10.81it/s]\u001b[A\n",
            " 97% 331/342 [00:30<00:01, 10.80it/s]\u001b[A\n",
            " 97% 333/342 [00:30<00:00, 11.03it/s]\u001b[A\n",
            " 98% 335/342 [00:30<00:00, 11.08it/s]\u001b[A\n",
            " 99% 337/342 [00:30<00:00, 11.50it/s]\u001b[A\n",
            " 99% 339/342 [00:30<00:00, 12.30it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.556268572807312, 'eval_accuracy': 0.9156141314296175, 'eval_runtime': 31.0689, 'eval_samples_per_second': 175.835, 'eval_steps_per_second': 11.008, 'epoch': 5.0}\n",
            "100% 32735/32735 [2:33:41<00:00,  4.00it/s]\n",
            "100% 342/342 [00:30<00:00, 12.29it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-qnli/checkpoint-32735\n",
            "Configuration saved in bert-base-uncased-finetuned-qnli/checkpoint-32735/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-qnli/checkpoint-32735/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-qnli/checkpoint-32735/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-qnli/checkpoint-32735/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from bert-base-uncased-finetuned-qnli/checkpoint-32735 (score: 0.9156141314296175).\n",
            "{'train_runtime': 9226.9631, 'train_samples_per_second': 56.759, 'train_steps_per_second': 3.548, 'train_loss': 0.15225660610475739, 'epoch': 5.0}\n",
            "100% 32735/32735 [2:33:46<00:00,  4.00it/s]Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/content/bert-vs-fnet/bert-base-uncased-finetuned-qnli is already a clone of https://huggingface.co/Joqsan/bert-base-uncased-finetuned-qnli. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-vs-fnet/bert-base-uncased-finetuned-qnli is already a clone of https://huggingface.co/Joqsan/bert-base-uncased-finetuned-qnli. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Saving model checkpoint to /tmp/tmpfzrs5ujj\n",
            "Configuration saved in /tmp/tmpfzrs5ujj/config.json\n",
            "Model weights saved in /tmp/tmpfzrs5ujj/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmpfzrs5ujj/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmpfzrs5ujj/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-qnli\n",
            "Configuration saved in bert-base-uncased-finetuned-qnli/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-qnli/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-qnli/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-qnli/special_tokens_map.json\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Upload file pytorch_model.bin:   0% 32.0k/418M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "Upload file pytorch_model.bin:   0% 512k/418M [00:01<14:51, 491kB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 4.59M/418M [00:02<02:39, 2.72MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   3% 12.4M/418M [00:03<01:21, 5.23MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   5% 20.2M/418M [00:04<01:05, 6.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 28.4M/418M [00:05<00:56, 7.16MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 36.7M/418M [00:06<00:52, 7.66MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  11% 45.0M/418M [00:07<00:48, 8.01MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  13% 53.3M/418M [00:08<00:46, 8.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 61.6M/418M [00:09<00:44, 8.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  17% 69.4M/418M [00:10<00:43, 8.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 77.0M/418M [00:11<00:43, 8.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  20% 84.8M/418M [00:12<00:42, 8.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  22% 92.4M/418M [00:13<00:42, 8.12MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  24% 100M/418M [00:14<00:40, 8.16MB/s] \u001b[A\n",
            "Upload file pytorch_model.bin:  26% 108M/418M [00:15<00:39, 8.17MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 116M/418M [00:16<00:38, 8.15MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  30% 124M/418M [00:17<00:37, 8.13MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 131M/418M [00:18<00:37, 8.05MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  33% 139M/418M [00:19<00:36, 8.04MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  35% 147M/418M [00:20<00:35, 8.07MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 155M/418M [00:21<00:33, 8.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 162M/418M [00:22<00:32, 8.15MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  41% 170M/418M [00:23<00:31, 8.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  43% 178M/418M [00:24<00:30, 8.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 186M/418M [00:25<00:29, 8.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 194M/418M [00:26<00:28, 8.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  48% 202M/418M [00:27<00:26, 8.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 211M/418M [00:28<00:25, 8.50MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 219M/418M [00:29<00:24, 8.49MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 227M/418M [00:30<00:23, 8.56MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 236M/418M [00:31<00:21, 8.68MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 244M/418M [00:32<00:21, 8.64MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  60% 253M/418M [00:33<00:19, 8.69MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  62% 260M/418M [00:34<00:19, 8.52MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 268M/418M [00:35<00:18, 8.44MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 277M/418M [00:36<00:17, 8.55MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  68% 285M/418M [00:37<00:16, 8.55MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  70% 293M/418M [00:38<00:15, 8.59MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 301M/418M [00:39<00:14, 8.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 308M/418M [00:40<00:13, 8.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  76% 316M/418M [00:41<00:12, 8.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 324M/418M [00:42<00:11, 8.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  79% 332M/418M [00:43<00:10, 8.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  81% 340M/418M [00:44<00:09, 8.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 348M/418M [00:45<00:08, 8.41MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  85% 356M/418M [00:46<00:07, 8.45MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 364M/418M [00:47<00:06, 8.46MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 373M/418M [00:48<00:05, 8.54MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 381M/418M [00:49<00:04, 8.58MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  93% 390M/418M [00:50<00:03, 8.70MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  95% 398M/418M [00:51<00:02, 8.74MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 407M/418M [00:52<00:01, 8.79MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  99% 415M/418M [00:53<00:00, 8.78MB/s]\u001b[Aremote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-qnli\n",
            "   79c8d8d..8d05970  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-qnli\n",
            "   79c8d8d..8d05970  main -> main\n",
            "\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 418M/418M [00:56<00:00, 4.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 418M/418M [00:56<00:00, 7.80MB/s]\n",
            "\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:56<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:56<?, ?B/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-qnli\n",
            "   8d05970..940f6af  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-qnli\n",
            "   8d05970..940f6af  main -> main\n",
            "\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Logging model artifacts. ...\n",
            "100% 32735/32735 [2:35:36<00:00,  3.51it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▇█▅▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▁▂▅▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▁▁█▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ██▁▄█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ██▁▄█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▇▆▆▆▆▅▅▄▄▄▄▄▄▄▄▂▂▃▃▂▃▃▃▂▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.91561\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.55627\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 31.0689\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 175.835\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 11.008\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 32735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0319\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 2.406620706723144e+16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.15226\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 9226.9631\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 56.759\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 3.548\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbert-base-uncased-qnli\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/cgukztyx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230130_125340-cgukztyx/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/fine_tuning.py Joqsan/custom-fnet qnli"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuNjCF8Gtpth",
        "outputId": "45798043-5d56-4220-9087-03682e69bf55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100% 3/3 [00:00<00:00, 14.71it/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-0d84b0bc6c17aad6.arrow\n",
            "100% 6/6 [00:00<00:00,  6.77ba/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6fbd49e567cf5441.arrow\n",
            "Some weights of MyFNetForSequenceClassification were not initialized from the model checkpoint at Joqsan/custom-fnet and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "models/fine_tuning.py:86: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"glue\", actual_task)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoqsan-a\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/bert-vs-fnet/wandb/run-20230130_153047-i2wefh0r\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcustom-fnet-qnli\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/i2wefh0r\u001b[0m\n",
            "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Cloning https://huggingface.co/Joqsan/custom-fnet-finetuned-qnli into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/Joqsan/custom-fnet-finetuned-qnli into local empty directory.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "The following columns in the training set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 104743\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 32735\n",
            "  Number of trainable parameters = 88222466\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "  0% 0/32735 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.7072, 'learning_rate': 1.9694516572475945e-05, 'epoch': 0.08}\n",
            "{'loss': 0.7027, 'learning_rate': 1.9389033144951888e-05, 'epoch': 0.15}\n",
            "{'loss': 0.7019, 'learning_rate': 1.908354971742783e-05, 'epoch': 0.23}\n",
            "{'loss': 0.7005, 'learning_rate': 1.8778066289903775e-05, 'epoch': 0.31}\n",
            "{'loss': 0.7006, 'learning_rate': 1.8472582862379718e-05, 'epoch': 0.38}\n",
            "{'loss': 0.699, 'learning_rate': 1.816709943485566e-05, 'epoch': 0.46}\n",
            "{'loss': 0.698, 'learning_rate': 1.7861616007331604e-05, 'epoch': 0.53}\n",
            "{'loss': 0.6965, 'learning_rate': 1.7556132579807548e-05, 'epoch': 0.61}\n",
            "{'loss': 0.6949, 'learning_rate': 1.725064915228349e-05, 'epoch': 0.69}\n",
            "{'loss': 0.6926, 'learning_rate': 1.6945165724759434e-05, 'epoch': 0.76}\n",
            "{'loss': 0.6884, 'learning_rate': 1.6639682297235374e-05, 'epoch': 0.84}\n",
            "{'loss': 0.6867, 'learning_rate': 1.633419886971132e-05, 'epoch': 0.92}\n",
            "{'loss': 0.6859, 'learning_rate': 1.6028715442187264e-05, 'epoch': 0.99}\n",
            " 20% 6547/32735 [22:51<1:15:40,  5.77it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 3/342 [00:00<00:19, 17.23it/s]\u001b[A\n",
            "  1% 5/342 [00:00<00:24, 13.53it/s]\u001b[A\n",
            "  2% 7/342 [00:00<00:23, 14.03it/s]\u001b[A\n",
            "  3% 9/342 [00:00<00:22, 14.64it/s]\u001b[A\n",
            "  3% 11/342 [00:00<00:21, 15.39it/s]\u001b[A\n",
            "  4% 13/342 [00:00<00:20, 16.30it/s]\u001b[A\n",
            "  4% 15/342 [00:01<00:22, 14.86it/s]\u001b[A\n",
            "  5% 17/342 [00:01<00:21, 15.40it/s]\u001b[A\n",
            "  6% 19/342 [00:01<00:19, 16.44it/s]\u001b[A\n",
            "  6% 21/342 [00:01<00:19, 16.43it/s]\u001b[A\n",
            "  7% 23/342 [00:01<00:20, 15.30it/s]\u001b[A\n",
            "  7% 25/342 [00:01<00:22, 14.09it/s]\u001b[A\n",
            "  8% 27/342 [00:01<00:21, 14.51it/s]\u001b[A\n",
            "  8% 29/342 [00:02<00:26, 11.62it/s]\u001b[A\n",
            "  9% 31/342 [00:02<00:25, 12.17it/s]\u001b[A\n",
            " 10% 33/342 [00:02<00:22, 13.58it/s]\u001b[A\n",
            " 10% 35/342 [00:02<00:21, 14.07it/s]\u001b[A\n",
            " 11% 37/342 [00:02<00:21, 14.24it/s]\u001b[A\n",
            " 11% 39/342 [00:02<00:20, 14.69it/s]\u001b[A\n",
            " 12% 41/342 [00:02<00:19, 15.53it/s]\u001b[A\n",
            " 13% 43/342 [00:02<00:18, 15.94it/s]\u001b[A\n",
            " 13% 45/342 [00:03<00:20, 14.84it/s]\u001b[A\n",
            " 14% 47/342 [00:03<00:21, 13.68it/s]\u001b[A\n",
            " 14% 49/342 [00:03<00:22, 13.26it/s]\u001b[A\n",
            " 15% 51/342 [00:03<00:21, 13.28it/s]\u001b[A\n",
            " 15% 53/342 [00:03<00:21, 13.21it/s]\u001b[A\n",
            " 16% 55/342 [00:03<00:20, 14.31it/s]\u001b[A\n",
            " 17% 57/342 [00:03<00:19, 14.42it/s]\u001b[A\n",
            " 17% 59/342 [00:04<00:19, 14.47it/s]\u001b[A\n",
            " 18% 61/342 [00:04<00:19, 14.42it/s]\u001b[A\n",
            " 18% 63/342 [00:04<00:20, 13.77it/s]\u001b[A\n",
            " 19% 65/342 [00:04<00:18, 15.15it/s]\u001b[A\n",
            " 20% 67/342 [00:04<00:17, 15.45it/s]\u001b[A\n",
            " 20% 69/342 [00:04<00:20, 13.43it/s]\u001b[A\n",
            " 21% 71/342 [00:04<00:21, 12.87it/s]\u001b[A\n",
            " 21% 73/342 [00:05<00:19, 13.82it/s]\u001b[A\n",
            " 22% 75/342 [00:05<00:18, 14.68it/s]\u001b[A\n",
            " 23% 77/342 [00:05<00:16, 15.71it/s]\u001b[A\n",
            " 23% 79/342 [00:05<00:16, 16.26it/s]\u001b[A\n",
            " 24% 81/342 [00:05<00:15, 16.61it/s]\u001b[A\n",
            " 24% 83/342 [00:05<00:15, 17.04it/s]\u001b[A\n",
            " 25% 85/342 [00:05<00:15, 16.14it/s]\u001b[A\n",
            " 25% 87/342 [00:05<00:16, 15.29it/s]\u001b[A\n",
            " 26% 89/342 [00:06<00:17, 14.20it/s]\u001b[A\n",
            " 27% 91/342 [00:06<00:17, 14.75it/s]\u001b[A\n",
            " 27% 93/342 [00:06<00:16, 15.09it/s]\u001b[A\n",
            " 28% 96/342 [00:06<00:14, 17.12it/s]\u001b[A\n",
            " 29% 98/342 [00:06<00:14, 16.27it/s]\u001b[A\n",
            " 29% 100/342 [00:06<00:14, 16.55it/s]\u001b[A\n",
            " 30% 102/342 [00:06<00:14, 16.20it/s]\u001b[A\n",
            " 30% 104/342 [00:07<00:14, 16.10it/s]\u001b[A\n",
            " 31% 106/342 [00:07<00:15, 15.32it/s]\u001b[A\n",
            " 32% 108/342 [00:07<00:14, 15.61it/s]\u001b[A\n",
            " 32% 110/342 [00:07<00:14, 15.61it/s]\u001b[A\n",
            " 33% 112/342 [00:07<00:14, 15.86it/s]\u001b[A\n",
            " 33% 114/342 [00:07<00:14, 15.81it/s]\u001b[A\n",
            " 34% 116/342 [00:07<00:15, 14.44it/s]\u001b[A\n",
            " 35% 118/342 [00:07<00:16, 13.91it/s]\u001b[A\n",
            " 35% 120/342 [00:08<00:14, 15.12it/s]\u001b[A\n",
            " 36% 122/342 [00:08<00:15, 13.87it/s]\u001b[A\n",
            " 36% 124/342 [00:08<00:14, 14.74it/s]\u001b[A\n",
            " 37% 126/342 [00:08<00:14, 15.23it/s]\u001b[A\n",
            " 37% 128/342 [00:08<00:13, 15.72it/s]\u001b[A\n",
            " 38% 130/342 [00:08<00:14, 14.71it/s]\u001b[A\n",
            " 39% 132/342 [00:08<00:14, 14.59it/s]\u001b[A\n",
            " 39% 134/342 [00:09<00:13, 15.22it/s]\u001b[A\n",
            " 40% 136/342 [00:09<00:13, 14.81it/s]\u001b[A\n",
            " 40% 138/342 [00:09<00:14, 14.26it/s]\u001b[A\n",
            " 41% 140/342 [00:09<00:14, 14.14it/s]\u001b[A\n",
            " 42% 142/342 [00:09<00:14, 14.01it/s]\u001b[A\n",
            " 42% 144/342 [00:09<00:13, 14.62it/s]\u001b[A\n",
            " 43% 146/342 [00:09<00:12, 15.20it/s]\u001b[A\n",
            " 43% 148/342 [00:09<00:12, 15.64it/s]\u001b[A\n",
            " 44% 150/342 [00:10<00:12, 15.36it/s]\u001b[A\n",
            " 44% 152/342 [00:10<00:13, 13.69it/s]\u001b[A\n",
            " 45% 154/342 [00:10<00:14, 12.66it/s]\u001b[A\n",
            " 46% 156/342 [00:10<00:13, 13.67it/s]\u001b[A\n",
            " 46% 158/342 [00:10<00:14, 12.74it/s]\u001b[A\n",
            " 47% 160/342 [00:10<00:15, 11.79it/s]\u001b[A\n",
            " 47% 162/342 [00:11<00:15, 11.91it/s]\u001b[A\n",
            " 48% 164/342 [00:11<00:14, 12.42it/s]\u001b[A\n",
            " 49% 166/342 [00:11<00:12, 13.78it/s]\u001b[A\n",
            " 49% 168/342 [00:11<00:11, 15.11it/s]\u001b[A\n",
            " 50% 170/342 [00:11<00:11, 15.59it/s]\u001b[A\n",
            " 50% 172/342 [00:11<00:10, 16.09it/s]\u001b[A\n",
            " 51% 174/342 [00:11<00:10, 15.90it/s]\u001b[A\n",
            " 51% 176/342 [00:12<00:10, 15.56it/s]\u001b[A\n",
            " 52% 178/342 [00:12<00:11, 14.25it/s]\u001b[A\n",
            " 53% 180/342 [00:12<00:11, 14.27it/s]\u001b[A\n",
            " 53% 182/342 [00:12<00:11, 14.41it/s]\u001b[A\n",
            " 54% 184/342 [00:12<00:10, 15.34it/s]\u001b[A\n",
            " 54% 186/342 [00:12<00:10, 15.01it/s]\u001b[A\n",
            " 55% 188/342 [00:12<00:10, 14.53it/s]\u001b[A\n",
            " 56% 190/342 [00:12<00:09, 15.29it/s]\u001b[A\n",
            " 56% 192/342 [00:13<00:10, 14.22it/s]\u001b[A\n",
            " 57% 194/342 [00:13<00:10, 14.13it/s]\u001b[A\n",
            " 57% 196/342 [00:13<00:09, 15.23it/s]\u001b[A\n",
            " 58% 198/342 [00:13<00:09, 14.71it/s]\u001b[A\n",
            " 58% 200/342 [00:13<00:11, 12.24it/s]\u001b[A\n",
            " 59% 202/342 [00:13<00:10, 13.28it/s]\u001b[A\n",
            " 60% 204/342 [00:14<00:10, 12.61it/s]\u001b[A\n",
            " 60% 206/342 [00:14<00:10, 13.16it/s]\u001b[A\n",
            " 61% 208/342 [00:14<00:09, 14.07it/s]\u001b[A\n",
            " 61% 210/342 [00:14<00:10, 12.69it/s]\u001b[A\n",
            " 62% 212/342 [00:14<00:09, 13.23it/s]\u001b[A\n",
            " 63% 214/342 [00:14<00:09, 13.65it/s]\u001b[A\n",
            " 63% 216/342 [00:14<00:09, 14.00it/s]\u001b[A\n",
            " 64% 218/342 [00:15<00:09, 13.59it/s]\u001b[A\n",
            " 64% 220/342 [00:15<00:08, 14.00it/s]\u001b[A\n",
            " 65% 222/342 [00:15<00:08, 14.20it/s]\u001b[A\n",
            " 66% 225/342 [00:15<00:07, 15.51it/s]\u001b[A\n",
            " 66% 227/342 [00:15<00:07, 16.43it/s]\u001b[A\n",
            " 67% 229/342 [00:15<00:06, 16.61it/s]\u001b[A\n",
            " 68% 231/342 [00:15<00:06, 15.88it/s]\u001b[A\n",
            " 68% 233/342 [00:15<00:07, 15.55it/s]\u001b[A\n",
            " 69% 235/342 [00:16<00:06, 15.33it/s]\u001b[A\n",
            " 69% 237/342 [00:16<00:07, 14.91it/s]\u001b[A\n",
            " 70% 239/342 [00:16<00:07, 14.70it/s]\u001b[A\n",
            " 70% 241/342 [00:16<00:06, 15.25it/s]\u001b[A\n",
            " 71% 243/342 [00:16<00:06, 15.67it/s]\u001b[A\n",
            " 72% 245/342 [00:16<00:06, 16.16it/s]\u001b[A\n",
            " 72% 247/342 [00:16<00:06, 15.73it/s]\u001b[A\n",
            " 73% 249/342 [00:17<00:05, 15.79it/s]\u001b[A\n",
            " 73% 251/342 [00:17<00:05, 15.60it/s]\u001b[A\n",
            " 74% 253/342 [00:17<00:05, 16.33it/s]\u001b[A\n",
            " 75% 255/342 [00:17<00:05, 16.20it/s]\u001b[A\n",
            " 75% 257/342 [00:17<00:05, 16.03it/s]\u001b[A\n",
            " 76% 259/342 [00:17<00:05, 15.87it/s]\u001b[A\n",
            " 76% 261/342 [00:17<00:05, 14.79it/s]\u001b[A\n",
            " 77% 263/342 [00:17<00:05, 14.90it/s]\u001b[A\n",
            " 77% 265/342 [00:18<00:05, 15.06it/s]\u001b[A\n",
            " 78% 267/342 [00:18<00:05, 13.93it/s]\u001b[A\n",
            " 79% 269/342 [00:18<00:04, 14.90it/s]\u001b[A\n",
            " 79% 271/342 [00:18<00:04, 15.87it/s]\u001b[A\n",
            " 80% 273/342 [00:18<00:04, 15.51it/s]\u001b[A\n",
            " 80% 275/342 [00:18<00:04, 15.81it/s]\u001b[A\n",
            " 81% 277/342 [00:18<00:04, 16.11it/s]\u001b[A\n",
            " 82% 279/342 [00:18<00:03, 16.11it/s]\u001b[A\n",
            " 82% 281/342 [00:19<00:03, 16.81it/s]\u001b[A\n",
            " 83% 283/342 [00:19<00:03, 16.45it/s]\u001b[A\n",
            " 83% 285/342 [00:19<00:04, 13.81it/s]\u001b[A\n",
            " 84% 287/342 [00:19<00:03, 15.02it/s]\u001b[A\n",
            " 85% 289/342 [00:19<00:03, 15.97it/s]\u001b[A\n",
            " 85% 291/342 [00:19<00:03, 14.99it/s]\u001b[A\n",
            " 86% 293/342 [00:19<00:03, 14.27it/s]\u001b[A\n",
            " 86% 295/342 [00:20<00:03, 14.93it/s]\u001b[A\n",
            " 87% 297/342 [00:20<00:02, 15.02it/s]\u001b[A\n",
            " 87% 299/342 [00:20<00:02, 14.78it/s]\u001b[A\n",
            " 88% 301/342 [00:20<00:02, 14.71it/s]\u001b[A\n",
            " 89% 303/342 [00:20<00:02, 14.90it/s]\u001b[A\n",
            " 89% 305/342 [00:20<00:02, 15.19it/s]\u001b[A\n",
            " 90% 307/342 [00:20<00:02, 13.50it/s]\u001b[A\n",
            " 90% 309/342 [00:20<00:02, 14.40it/s]\u001b[A\n",
            " 91% 311/342 [00:21<00:02, 15.44it/s]\u001b[A\n",
            " 92% 313/342 [00:21<00:01, 15.26it/s]\u001b[A\n",
            " 92% 315/342 [00:21<00:01, 14.91it/s]\u001b[A\n",
            " 93% 317/342 [00:21<00:01, 16.07it/s]\u001b[A\n",
            " 93% 319/342 [00:21<00:01, 14.59it/s]\u001b[A\n",
            " 94% 321/342 [00:21<00:01, 15.14it/s]\u001b[A\n",
            " 94% 323/342 [00:21<00:01, 15.51it/s]\u001b[A\n",
            " 95% 325/342 [00:22<00:01, 15.33it/s]\u001b[A\n",
            " 96% 327/342 [00:22<00:01, 14.73it/s]\u001b[A\n",
            " 96% 329/342 [00:22<00:00, 14.42it/s]\u001b[A\n",
            " 97% 331/342 [00:22<00:00, 14.55it/s]\u001b[A\n",
            " 97% 333/342 [00:22<00:00, 14.89it/s]\u001b[A\n",
            " 98% 335/342 [00:22<00:00, 14.87it/s]\u001b[A\n",
            " 99% 337/342 [00:22<00:00, 15.15it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.6714408993721008, 'eval_accuracy': 0.5802672524254073, 'eval_runtime': 23.1978, 'eval_samples_per_second': 235.496, 'eval_steps_per_second': 14.743, 'epoch': 1.0}\n",
            " 20% 6547/32735 [23:15<1:15:40,  5.77it/s]\n",
            "100% 342/342 [00:23<00:00, 16.41it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to custom-fnet-finetuned-qnli/checkpoint-6547\n",
            "Configuration saved in custom-fnet-finetuned-qnli/checkpoint-6547/config.json\n",
            "Model weights saved in custom-fnet-finetuned-qnli/checkpoint-6547/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-qnli/checkpoint-6547/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-qnli/checkpoint-6547/special_tokens_map.json\n",
            "{'loss': 0.6804, 'learning_rate': 1.5723232014663207e-05, 'epoch': 1.07}\n",
            "{'loss': 0.6809, 'learning_rate': 1.541774858713915e-05, 'epoch': 1.15}\n",
            "{'loss': 0.6814, 'learning_rate': 1.5112265159615092e-05, 'epoch': 1.22}\n",
            "{'loss': 0.6738, 'learning_rate': 1.4806781732091035e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6782, 'learning_rate': 1.4501298304566977e-05, 'epoch': 1.37}\n",
            "{'loss': 0.6779, 'learning_rate': 1.4195814877042922e-05, 'epoch': 1.45}\n",
            "{'loss': 0.6747, 'learning_rate': 1.3890331449518865e-05, 'epoch': 1.53}\n",
            "{'loss': 0.6708, 'learning_rate': 1.3584848021994808e-05, 'epoch': 1.6}\n",
            "{'loss': 0.6718, 'learning_rate': 1.3279364594470752e-05, 'epoch': 1.68}\n",
            "{'loss': 0.6751, 'learning_rate': 1.2973881166946693e-05, 'epoch': 1.76}\n",
            "{'loss': 0.6759, 'learning_rate': 1.2668397739422638e-05, 'epoch': 1.83}\n",
            "{'loss': 0.6735, 'learning_rate': 1.236291431189858e-05, 'epoch': 1.91}\n",
            "{'loss': 0.6684, 'learning_rate': 1.2057430884374523e-05, 'epoch': 1.99}\n",
            " 40% 13093/32735 [46:10<1:14:12,  4.41it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 3/342 [00:00<00:19, 17.31it/s]\u001b[A\n",
            "  1% 5/342 [00:00<00:25, 13.30it/s]\u001b[A\n",
            "  2% 7/342 [00:00<00:24, 13.78it/s]\u001b[A\n",
            "  3% 9/342 [00:00<00:23, 14.38it/s]\u001b[A\n",
            "  3% 11/342 [00:00<00:21, 15.35it/s]\u001b[A\n",
            "  4% 13/342 [00:00<00:20, 15.87it/s]\u001b[A\n",
            "  4% 15/342 [00:01<00:22, 14.58it/s]\u001b[A\n",
            "  5% 17/342 [00:01<00:21, 15.07it/s]\u001b[A\n",
            "  6% 19/342 [00:01<00:20, 16.13it/s]\u001b[A\n",
            "  6% 21/342 [00:01<00:19, 16.08it/s]\u001b[A\n",
            "  7% 23/342 [00:01<00:21, 15.12it/s]\u001b[A\n",
            "  7% 25/342 [00:01<00:22, 14.20it/s]\u001b[A\n",
            "  8% 27/342 [00:01<00:21, 14.51it/s]\u001b[A\n",
            "  8% 29/342 [00:02<00:27, 11.56it/s]\u001b[A\n",
            "  9% 31/342 [00:02<00:25, 12.20it/s]\u001b[A\n",
            " 10% 33/342 [00:02<00:22, 13.65it/s]\u001b[A\n",
            " 10% 35/342 [00:02<00:21, 14.14it/s]\u001b[A\n",
            " 11% 37/342 [00:02<00:21, 14.28it/s]\u001b[A\n",
            " 11% 39/342 [00:02<00:20, 14.76it/s]\u001b[A\n",
            " 12% 41/342 [00:02<00:19, 15.52it/s]\u001b[A\n",
            " 13% 43/342 [00:02<00:18, 15.88it/s]\u001b[A\n",
            " 13% 45/342 [00:03<00:20, 14.76it/s]\u001b[A\n",
            " 14% 47/342 [00:03<00:21, 13.69it/s]\u001b[A\n",
            " 14% 49/342 [00:03<00:22, 13.25it/s]\u001b[A\n",
            " 15% 51/342 [00:03<00:22, 13.21it/s]\u001b[A\n",
            " 15% 53/342 [00:03<00:21, 13.23it/s]\u001b[A\n",
            " 16% 55/342 [00:03<00:20, 14.19it/s]\u001b[A\n",
            " 17% 57/342 [00:03<00:19, 14.40it/s]\u001b[A\n",
            " 17% 59/342 [00:04<00:19, 14.48it/s]\u001b[A\n",
            " 18% 61/342 [00:04<00:19, 14.39it/s]\u001b[A\n",
            " 18% 63/342 [00:04<00:20, 13.59it/s]\u001b[A\n",
            " 19% 65/342 [00:04<00:18, 14.80it/s]\u001b[A\n",
            " 20% 67/342 [00:04<00:18, 15.22it/s]\u001b[A\n",
            " 20% 69/342 [00:04<00:20, 13.11it/s]\u001b[A\n",
            " 21% 71/342 [00:05<00:21, 12.70it/s]\u001b[A\n",
            " 21% 73/342 [00:05<00:19, 13.53it/s]\u001b[A\n",
            " 22% 75/342 [00:05<00:18, 14.49it/s]\u001b[A\n",
            " 23% 77/342 [00:05<00:16, 15.63it/s]\u001b[A\n",
            " 23% 79/342 [00:05<00:16, 15.94it/s]\u001b[A\n",
            " 24% 81/342 [00:05<00:15, 16.33it/s]\u001b[A\n",
            " 24% 83/342 [00:05<00:15, 16.86it/s]\u001b[A\n",
            " 25% 85/342 [00:05<00:16, 15.83it/s]\u001b[A\n",
            " 25% 87/342 [00:06<00:16, 15.13it/s]\u001b[A\n",
            " 26% 89/342 [00:06<00:17, 14.22it/s]\u001b[A\n",
            " 27% 91/342 [00:06<00:16, 14.83it/s]\u001b[A\n",
            " 27% 93/342 [00:06<00:16, 15.12it/s]\u001b[A\n",
            " 28% 96/342 [00:06<00:14, 17.01it/s]\u001b[A\n",
            " 29% 98/342 [00:06<00:15, 16.05it/s]\u001b[A\n",
            " 29% 100/342 [00:06<00:14, 16.39it/s]\u001b[A\n",
            " 30% 102/342 [00:06<00:14, 16.07it/s]\u001b[A\n",
            " 30% 104/342 [00:07<00:14, 15.97it/s]\u001b[A\n",
            " 31% 106/342 [00:07<00:15, 15.11it/s]\u001b[A\n",
            " 32% 108/342 [00:07<00:14, 15.69it/s]\u001b[A\n",
            " 32% 110/342 [00:07<00:14, 15.80it/s]\u001b[A\n",
            " 33% 112/342 [00:07<00:14, 15.89it/s]\u001b[A\n",
            " 33% 114/342 [00:07<00:14, 15.72it/s]\u001b[A\n",
            " 34% 116/342 [00:07<00:15, 14.32it/s]\u001b[A\n",
            " 35% 118/342 [00:08<00:16, 13.86it/s]\u001b[A\n",
            " 35% 120/342 [00:08<00:14, 14.99it/s]\u001b[A\n",
            " 36% 122/342 [00:08<00:15, 13.84it/s]\u001b[A\n",
            " 36% 124/342 [00:08<00:14, 14.83it/s]\u001b[A\n",
            " 37% 126/342 [00:08<00:14, 15.29it/s]\u001b[A\n",
            " 37% 128/342 [00:08<00:13, 15.64it/s]\u001b[A\n",
            " 38% 130/342 [00:08<00:14, 14.43it/s]\u001b[A\n",
            " 39% 132/342 [00:08<00:14, 14.42it/s]\u001b[A\n",
            " 39% 134/342 [00:09<00:13, 14.98it/s]\u001b[A\n",
            " 40% 136/342 [00:09<00:14, 14.58it/s]\u001b[A\n",
            " 40% 138/342 [00:09<00:14, 14.13it/s]\u001b[A\n",
            " 41% 140/342 [00:09<00:14, 14.26it/s]\u001b[A\n",
            " 42% 142/342 [00:09<00:14, 14.27it/s]\u001b[A\n",
            " 42% 144/342 [00:09<00:13, 14.83it/s]\u001b[A\n",
            " 43% 146/342 [00:09<00:12, 15.35it/s]\u001b[A\n",
            " 43% 148/342 [00:10<00:12, 15.83it/s]\u001b[A\n",
            " 44% 150/342 [00:10<00:12, 15.33it/s]\u001b[A\n",
            " 44% 152/342 [00:10<00:14, 13.48it/s]\u001b[A\n",
            " 45% 154/342 [00:10<00:14, 12.61it/s]\u001b[A\n",
            " 46% 156/342 [00:10<00:13, 13.67it/s]\u001b[A\n",
            " 46% 158/342 [00:10<00:14, 12.62it/s]\u001b[A\n",
            " 47% 160/342 [00:11<00:15, 11.76it/s]\u001b[A\n",
            " 47% 162/342 [00:11<00:15, 11.86it/s]\u001b[A\n",
            " 48% 164/342 [00:11<00:14, 12.27it/s]\u001b[A\n",
            " 49% 166/342 [00:11<00:12, 13.68it/s]\u001b[A\n",
            " 49% 168/342 [00:11<00:11, 15.11it/s]\u001b[A\n",
            " 50% 170/342 [00:11<00:10, 15.65it/s]\u001b[A\n",
            " 50% 172/342 [00:11<00:10, 16.03it/s]\u001b[A\n",
            " 51% 174/342 [00:11<00:10, 15.74it/s]\u001b[A\n",
            " 51% 176/342 [00:12<00:10, 15.68it/s]\u001b[A\n",
            " 52% 178/342 [00:12<00:11, 14.65it/s]\u001b[A\n",
            " 53% 180/342 [00:12<00:11, 14.69it/s]\u001b[A\n",
            " 53% 182/342 [00:12<00:10, 14.71it/s]\u001b[A\n",
            " 54% 184/342 [00:12<00:10, 15.52it/s]\u001b[A\n",
            " 54% 186/342 [00:12<00:10, 15.29it/s]\u001b[A\n",
            " 55% 188/342 [00:12<00:10, 14.43it/s]\u001b[A\n",
            " 56% 190/342 [00:13<00:10, 15.07it/s]\u001b[A\n",
            " 56% 192/342 [00:13<00:10, 14.25it/s]\u001b[A\n",
            " 57% 194/342 [00:13<00:10, 14.23it/s]\u001b[A\n",
            " 57% 196/342 [00:13<00:09, 15.37it/s]\u001b[A\n",
            " 58% 198/342 [00:13<00:09, 14.83it/s]\u001b[A\n",
            " 58% 200/342 [00:13<00:11, 12.36it/s]\u001b[A\n",
            " 59% 202/342 [00:13<00:10, 13.33it/s]\u001b[A\n",
            " 60% 204/342 [00:14<00:10, 12.60it/s]\u001b[A\n",
            " 60% 206/342 [00:14<00:10, 13.03it/s]\u001b[A\n",
            " 61% 208/342 [00:14<00:09, 13.95it/s]\u001b[A\n",
            " 61% 210/342 [00:14<00:10, 12.91it/s]\u001b[A\n",
            " 62% 212/342 [00:14<00:09, 13.45it/s]\u001b[A\n",
            " 63% 214/342 [00:14<00:09, 13.87it/s]\u001b[A\n",
            " 63% 216/342 [00:14<00:08, 14.07it/s]\u001b[A\n",
            " 64% 218/342 [00:15<00:09, 13.62it/s]\u001b[A\n",
            " 64% 220/342 [00:15<00:08, 14.03it/s]\u001b[A\n",
            " 65% 222/342 [00:15<00:08, 14.19it/s]\u001b[A\n",
            " 65% 224/342 [00:15<00:07, 15.52it/s]\u001b[A\n",
            " 66% 226/342 [00:15<00:07, 15.81it/s]\u001b[A\n",
            " 67% 228/342 [00:15<00:07, 16.10it/s]\u001b[A\n",
            " 67% 230/342 [00:15<00:06, 16.06it/s]\u001b[A\n",
            " 68% 232/342 [00:15<00:06, 16.29it/s]\u001b[A\n",
            " 68% 234/342 [00:16<00:07, 14.84it/s]\u001b[A\n",
            " 69% 236/342 [00:16<00:07, 14.90it/s]\u001b[A\n",
            " 70% 238/342 [00:16<00:07, 14.56it/s]\u001b[A\n",
            " 70% 240/342 [00:16<00:06, 15.66it/s]\u001b[A\n",
            " 71% 242/342 [00:16<00:06, 15.88it/s]\u001b[A\n",
            " 71% 244/342 [00:16<00:05, 16.79it/s]\u001b[A\n",
            " 72% 246/342 [00:16<00:06, 15.60it/s]\u001b[A\n",
            " 73% 248/342 [00:17<00:05, 15.77it/s]\u001b[A\n",
            " 73% 250/342 [00:17<00:05, 15.80it/s]\u001b[A\n",
            " 74% 252/342 [00:17<00:05, 16.16it/s]\u001b[A\n",
            " 74% 254/342 [00:17<00:05, 16.81it/s]\u001b[A\n",
            " 75% 256/342 [00:17<00:05, 16.93it/s]\u001b[A\n",
            " 75% 258/342 [00:17<00:05, 15.81it/s]\u001b[A\n",
            " 76% 260/342 [00:17<00:05, 15.48it/s]\u001b[A\n",
            " 77% 262/342 [00:17<00:05, 15.21it/s]\u001b[A\n",
            " 77% 264/342 [00:18<00:05, 15.47it/s]\u001b[A\n",
            " 78% 266/342 [00:18<00:05, 15.11it/s]\u001b[A\n",
            " 78% 268/342 [00:18<00:05, 14.49it/s]\u001b[A\n",
            " 79% 270/342 [00:18<00:04, 15.40it/s]\u001b[A\n",
            " 80% 272/342 [00:18<00:04, 15.77it/s]\u001b[A\n",
            " 80% 274/342 [00:18<00:04, 15.70it/s]\u001b[A\n",
            " 81% 276/342 [00:18<00:04, 15.55it/s]\u001b[A\n",
            " 81% 278/342 [00:18<00:03, 16.29it/s]\u001b[A\n",
            " 82% 280/342 [00:19<00:03, 16.54it/s]\u001b[A\n",
            " 82% 282/342 [00:19<00:03, 16.50it/s]\u001b[A\n",
            " 83% 284/342 [00:19<00:03, 15.19it/s]\u001b[A\n",
            " 84% 286/342 [00:19<00:04, 13.97it/s]\u001b[A\n",
            " 84% 288/342 [00:19<00:03, 15.24it/s]\u001b[A\n",
            " 85% 290/342 [00:19<00:03, 15.09it/s]\u001b[A\n",
            " 85% 292/342 [00:19<00:03, 15.03it/s]\u001b[A\n",
            " 86% 294/342 [00:19<00:03, 14.60it/s]\u001b[A\n",
            " 87% 296/342 [00:20<00:02, 15.55it/s]\u001b[A\n",
            " 87% 298/342 [00:20<00:02, 14.83it/s]\u001b[A\n",
            " 88% 300/342 [00:20<00:02, 14.62it/s]\u001b[A\n",
            " 88% 302/342 [00:20<00:02, 14.40it/s]\u001b[A\n",
            " 89% 304/342 [00:20<00:02, 14.86it/s]\u001b[A\n",
            " 89% 306/342 [00:20<00:02, 14.05it/s]\u001b[A\n",
            " 90% 308/342 [00:20<00:02, 13.89it/s]\u001b[A\n",
            " 91% 310/342 [00:21<00:02, 15.21it/s]\u001b[A\n",
            " 91% 312/342 [00:21<00:01, 15.58it/s]\u001b[A\n",
            " 92% 314/342 [00:21<00:01, 14.75it/s]\u001b[A\n",
            " 92% 316/342 [00:21<00:01, 15.83it/s]\u001b[A\n",
            " 93% 318/342 [00:21<00:01, 15.16it/s]\u001b[A\n",
            " 94% 320/342 [00:21<00:01, 14.54it/s]\u001b[A\n",
            " 94% 322/342 [00:21<00:01, 15.66it/s]\u001b[A\n",
            " 95% 324/342 [00:21<00:01, 15.55it/s]\u001b[A\n",
            " 95% 326/342 [00:22<00:01, 14.52it/s]\u001b[A\n",
            " 96% 328/342 [00:22<00:00, 14.40it/s]\u001b[A\n",
            " 96% 330/342 [00:22<00:00, 14.13it/s]\u001b[A\n",
            " 97% 332/342 [00:22<00:00, 14.71it/s]\u001b[A\n",
            " 98% 334/342 [00:22<00:00, 14.90it/s]\u001b[A\n",
            " 98% 336/342 [00:22<00:00, 14.68it/s]\u001b[A\n",
            " 99% 339/342 [00:22<00:00, 16.53it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.6639118194580078, 'eval_accuracy': 0.5938129233022149, 'eval_runtime': 23.2188, 'eval_samples_per_second': 235.284, 'eval_steps_per_second': 14.729, 'epoch': 2.0}\n",
            " 40% 13094/32735 [46:33<1:14:12,  4.41it/s]\n",
            "100% 342/342 [00:23<00:00, 16.45it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to custom-fnet-finetuned-qnli/checkpoint-13094\n",
            "Configuration saved in custom-fnet-finetuned-qnli/checkpoint-13094/config.json\n",
            "Model weights saved in custom-fnet-finetuned-qnli/checkpoint-13094/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-qnli/checkpoint-13094/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-qnli/checkpoint-13094/special_tokens_map.json\n",
            "{'loss': 0.6669, 'learning_rate': 1.1751947456850468e-05, 'epoch': 2.06}\n",
            "{'loss': 0.6646, 'learning_rate': 1.144646402932641e-05, 'epoch': 2.14}\n",
            "{'loss': 0.6652, 'learning_rate': 1.1140980601802354e-05, 'epoch': 2.21}\n",
            "{'loss': 0.667, 'learning_rate': 1.0835497174278296e-05, 'epoch': 2.29}\n",
            "{'loss': 0.6686, 'learning_rate': 1.053001374675424e-05, 'epoch': 2.37}\n",
            "{'loss': 0.6682, 'learning_rate': 1.0224530319230184e-05, 'epoch': 2.44}\n",
            "{'loss': 0.6657, 'learning_rate': 9.919046891706126e-06, 'epoch': 2.52}\n",
            "{'loss': 0.6648, 'learning_rate': 9.613563464182069e-06, 'epoch': 2.6}\n",
            "{'loss': 0.6611, 'learning_rate': 9.308080036658012e-06, 'epoch': 2.67}\n",
            "{'loss': 0.6628, 'learning_rate': 9.002596609133956e-06, 'epoch': 2.75}\n",
            "{'loss': 0.6592, 'learning_rate': 8.697113181609899e-06, 'epoch': 2.83}\n",
            "{'loss': 0.6625, 'learning_rate': 8.391629754085842e-06, 'epoch': 2.9}\n",
            "{'loss': 0.6558, 'learning_rate': 8.086146326561785e-06, 'epoch': 2.98}\n",
            " 60% 19641/32735 [1:09:26<38:34,  5.66it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 3/342 [00:00<00:20, 16.90it/s]\u001b[A\n",
            "  1% 5/342 [00:00<00:24, 13.69it/s]\u001b[A\n",
            "  2% 7/342 [00:00<00:23, 14.20it/s]\u001b[A\n",
            "  3% 9/342 [00:00<00:22, 14.69it/s]\u001b[A\n",
            "  3% 11/342 [00:00<00:21, 15.50it/s]\u001b[A\n",
            "  4% 13/342 [00:00<00:20, 16.21it/s]\u001b[A\n",
            "  4% 15/342 [00:01<00:22, 14.73it/s]\u001b[A\n",
            "  5% 17/342 [00:01<00:21, 15.17it/s]\u001b[A\n",
            "  6% 19/342 [00:01<00:19, 16.24it/s]\u001b[A\n",
            "  6% 21/342 [00:01<00:19, 16.17it/s]\u001b[A\n",
            "  7% 23/342 [00:01<00:21, 15.07it/s]\u001b[A\n",
            "  7% 25/342 [00:01<00:22, 14.17it/s]\u001b[A\n",
            "  8% 27/342 [00:01<00:21, 14.61it/s]\u001b[A\n",
            "  8% 29/342 [00:02<00:26, 11.61it/s]\u001b[A\n",
            "  9% 31/342 [00:02<00:25, 12.14it/s]\u001b[A\n",
            " 10% 33/342 [00:02<00:22, 13.55it/s]\u001b[A\n",
            " 10% 35/342 [00:02<00:21, 13.98it/s]\u001b[A\n",
            " 11% 37/342 [00:02<00:21, 14.25it/s]\u001b[A\n",
            " 11% 39/342 [00:02<00:20, 14.77it/s]\u001b[A\n",
            " 12% 41/342 [00:02<00:19, 15.63it/s]\u001b[A\n",
            " 13% 43/342 [00:02<00:18, 15.84it/s]\u001b[A\n",
            " 13% 45/342 [00:03<00:20, 14.66it/s]\u001b[A\n",
            " 14% 47/342 [00:03<00:21, 13.60it/s]\u001b[A\n",
            " 14% 49/342 [00:03<00:22, 13.11it/s]\u001b[A\n",
            " 15% 51/342 [00:03<00:22, 13.01it/s]\u001b[A\n",
            " 15% 53/342 [00:03<00:22, 13.04it/s]\u001b[A\n",
            " 16% 55/342 [00:03<00:20, 13.99it/s]\u001b[A\n",
            " 17% 57/342 [00:03<00:20, 14.23it/s]\u001b[A\n",
            " 17% 59/342 [00:04<00:19, 14.51it/s]\u001b[A\n",
            " 18% 61/342 [00:04<00:19, 14.55it/s]\u001b[A\n",
            " 18% 63/342 [00:04<00:20, 13.67it/s]\u001b[A\n",
            " 19% 65/342 [00:04<00:18, 14.88it/s]\u001b[A\n",
            " 20% 67/342 [00:04<00:17, 15.41it/s]\u001b[A\n",
            " 20% 69/342 [00:04<00:20, 13.33it/s]\u001b[A\n",
            " 21% 71/342 [00:05<00:21, 12.75it/s]\u001b[A\n",
            " 21% 73/342 [00:05<00:19, 13.65it/s]\u001b[A\n",
            " 22% 75/342 [00:05<00:18, 14.63it/s]\u001b[A\n",
            " 23% 77/342 [00:05<00:16, 15.72it/s]\u001b[A\n",
            " 23% 79/342 [00:05<00:16, 16.15it/s]\u001b[A\n",
            " 24% 81/342 [00:05<00:15, 16.48it/s]\u001b[A\n",
            " 24% 83/342 [00:05<00:15, 16.79it/s]\u001b[A\n",
            " 25% 85/342 [00:05<00:16, 16.04it/s]\u001b[A\n",
            " 25% 87/342 [00:05<00:16, 15.33it/s]\u001b[A\n",
            " 26% 89/342 [00:06<00:17, 14.23it/s]\u001b[A\n",
            " 27% 91/342 [00:06<00:16, 14.87it/s]\u001b[A\n",
            " 27% 93/342 [00:06<00:16, 15.16it/s]\u001b[A\n",
            " 28% 96/342 [00:06<00:14, 17.11it/s]\u001b[A\n",
            " 29% 98/342 [00:06<00:15, 16.15it/s]\u001b[A\n",
            " 29% 100/342 [00:06<00:14, 16.53it/s]\u001b[A\n",
            " 30% 102/342 [00:06<00:14, 16.30it/s]\u001b[A\n",
            " 30% 104/342 [00:07<00:14, 16.16it/s]\u001b[A\n",
            " 31% 106/342 [00:07<00:15, 15.41it/s]\u001b[A\n",
            " 32% 108/342 [00:07<00:14, 15.72it/s]\u001b[A\n",
            " 32% 110/342 [00:07<00:14, 15.64it/s]\u001b[A\n",
            " 33% 112/342 [00:07<00:14, 15.71it/s]\u001b[A\n",
            " 33% 114/342 [00:07<00:14, 15.75it/s]\u001b[A\n",
            " 34% 116/342 [00:07<00:15, 14.44it/s]\u001b[A\n",
            " 35% 118/342 [00:08<00:16, 13.99it/s]\u001b[A\n",
            " 35% 120/342 [00:08<00:14, 15.21it/s]\u001b[A\n",
            " 36% 122/342 [00:08<00:15, 14.12it/s]\u001b[A\n",
            " 36% 124/342 [00:08<00:14, 14.81it/s]\u001b[A\n",
            " 37% 126/342 [00:08<00:14, 15.38it/s]\u001b[A\n",
            " 37% 128/342 [00:08<00:13, 15.81it/s]\u001b[A\n",
            " 38% 130/342 [00:08<00:14, 14.74it/s]\u001b[A\n",
            " 39% 132/342 [00:08<00:14, 14.62it/s]\u001b[A\n",
            " 39% 134/342 [00:09<00:13, 15.14it/s]\u001b[A\n",
            " 40% 136/342 [00:09<00:13, 14.73it/s]\u001b[A\n",
            " 40% 138/342 [00:09<00:14, 14.06it/s]\u001b[A\n",
            " 41% 140/342 [00:09<00:14, 13.95it/s]\u001b[A\n",
            " 42% 142/342 [00:09<00:14, 13.96it/s]\u001b[A\n",
            " 42% 144/342 [00:09<00:13, 14.58it/s]\u001b[A\n",
            " 43% 146/342 [00:09<00:12, 15.18it/s]\u001b[A\n",
            " 43% 148/342 [00:10<00:12, 15.65it/s]\u001b[A\n",
            " 44% 150/342 [00:10<00:12, 15.40it/s]\u001b[A\n",
            " 44% 152/342 [00:10<00:13, 13.63it/s]\u001b[A\n",
            " 45% 154/342 [00:10<00:15, 12.51it/s]\u001b[A\n",
            " 46% 156/342 [00:10<00:13, 13.53it/s]\u001b[A\n",
            " 46% 158/342 [00:10<00:14, 12.60it/s]\u001b[A\n",
            " 47% 160/342 [00:11<00:15, 11.63it/s]\u001b[A\n",
            " 47% 162/342 [00:11<00:15, 11.83it/s]\u001b[A\n",
            " 48% 164/342 [00:11<00:14, 12.23it/s]\u001b[A\n",
            " 49% 166/342 [00:11<00:12, 13.58it/s]\u001b[A\n",
            " 49% 168/342 [00:11<00:11, 15.02it/s]\u001b[A\n",
            " 50% 170/342 [00:11<00:11, 15.48it/s]\u001b[A\n",
            " 50% 172/342 [00:11<00:10, 16.10it/s]\u001b[A\n",
            " 51% 174/342 [00:11<00:10, 15.83it/s]\u001b[A\n",
            " 51% 176/342 [00:12<00:10, 15.59it/s]\u001b[A\n",
            " 52% 178/342 [00:12<00:11, 14.51it/s]\u001b[A\n",
            " 53% 180/342 [00:12<00:11, 14.45it/s]\u001b[A\n",
            " 53% 182/342 [00:12<00:10, 14.69it/s]\u001b[A\n",
            " 54% 184/342 [00:12<00:10, 15.57it/s]\u001b[A\n",
            " 54% 186/342 [00:12<00:10, 15.31it/s]\u001b[A\n",
            " 55% 188/342 [00:12<00:10, 14.58it/s]\u001b[A\n",
            " 56% 190/342 [00:12<00:09, 15.21it/s]\u001b[A\n",
            " 56% 192/342 [00:13<00:10, 14.34it/s]\u001b[A\n",
            " 57% 194/342 [00:13<00:10, 14.31it/s]\u001b[A\n",
            " 57% 196/342 [00:13<00:09, 15.45it/s]\u001b[A\n",
            " 58% 198/342 [00:13<00:09, 14.88it/s]\u001b[A\n",
            " 58% 200/342 [00:13<00:11, 12.41it/s]\u001b[A\n",
            " 59% 202/342 [00:13<00:10, 13.38it/s]\u001b[A\n",
            " 60% 204/342 [00:14<00:10, 12.61it/s]\u001b[A\n",
            " 60% 206/342 [00:14<00:10, 13.02it/s]\u001b[A\n",
            " 61% 208/342 [00:14<00:09, 13.89it/s]\u001b[A\n",
            " 61% 210/342 [00:14<00:10, 12.77it/s]\u001b[A\n",
            " 62% 212/342 [00:14<00:09, 13.16it/s]\u001b[A\n",
            " 63% 214/342 [00:14<00:09, 13.54it/s]\u001b[A\n",
            " 63% 216/342 [00:14<00:09, 13.92it/s]\u001b[A\n",
            " 64% 218/342 [00:15<00:09, 13.43it/s]\u001b[A\n",
            " 64% 220/342 [00:15<00:08, 13.83it/s]\u001b[A\n",
            " 65% 222/342 [00:15<00:08, 14.03it/s]\u001b[A\n",
            " 66% 225/342 [00:15<00:07, 15.48it/s]\u001b[A\n",
            " 66% 227/342 [00:15<00:07, 16.35it/s]\u001b[A\n",
            " 67% 229/342 [00:15<00:06, 16.61it/s]\u001b[A\n",
            " 68% 231/342 [00:15<00:06, 15.92it/s]\u001b[A\n",
            " 68% 233/342 [00:16<00:06, 15.73it/s]\u001b[A\n",
            " 69% 235/342 [00:16<00:06, 15.38it/s]\u001b[A\n",
            " 69% 237/342 [00:16<00:06, 15.00it/s]\u001b[A\n",
            " 70% 239/342 [00:16<00:06, 14.82it/s]\u001b[A\n",
            " 70% 241/342 [00:16<00:06, 15.59it/s]\u001b[A\n",
            " 71% 243/342 [00:16<00:06, 15.90it/s]\u001b[A\n",
            " 72% 245/342 [00:16<00:05, 16.38it/s]\u001b[A\n",
            " 72% 247/342 [00:16<00:05, 15.88it/s]\u001b[A\n",
            " 73% 249/342 [00:17<00:05, 16.09it/s]\u001b[A\n",
            " 73% 251/342 [00:17<00:05, 15.79it/s]\u001b[A\n",
            " 74% 253/342 [00:17<00:05, 16.58it/s]\u001b[A\n",
            " 75% 255/342 [00:17<00:05, 16.21it/s]\u001b[A\n",
            " 75% 257/342 [00:17<00:05, 16.00it/s]\u001b[A\n",
            " 76% 259/342 [00:17<00:05, 15.75it/s]\u001b[A\n",
            " 76% 261/342 [00:17<00:05, 14.80it/s]\u001b[A\n",
            " 77% 263/342 [00:17<00:05, 14.98it/s]\u001b[A\n",
            " 77% 265/342 [00:18<00:05, 15.20it/s]\u001b[A\n",
            " 78% 267/342 [00:18<00:05, 14.02it/s]\u001b[A\n",
            " 79% 269/342 [00:18<00:04, 14.86it/s]\u001b[A\n",
            " 79% 271/342 [00:18<00:04, 15.88it/s]\u001b[A\n",
            " 80% 273/342 [00:18<00:04, 15.52it/s]\u001b[A\n",
            " 80% 275/342 [00:18<00:04, 15.85it/s]\u001b[A\n",
            " 81% 277/342 [00:18<00:04, 16.18it/s]\u001b[A\n",
            " 82% 279/342 [00:18<00:03, 16.20it/s]\u001b[A\n",
            " 82% 281/342 [00:19<00:03, 16.88it/s]\u001b[A\n",
            " 83% 283/342 [00:19<00:03, 16.49it/s]\u001b[A\n",
            " 83% 285/342 [00:19<00:04, 13.73it/s]\u001b[A\n",
            " 84% 287/342 [00:19<00:03, 14.87it/s]\u001b[A\n",
            " 85% 289/342 [00:19<00:03, 15.79it/s]\u001b[A\n",
            " 85% 291/342 [00:19<00:03, 14.86it/s]\u001b[A\n",
            " 86% 293/342 [00:19<00:03, 14.41it/s]\u001b[A\n",
            " 86% 295/342 [00:20<00:03, 14.95it/s]\u001b[A\n",
            " 87% 297/342 [00:20<00:02, 15.15it/s]\u001b[A\n",
            " 87% 299/342 [00:20<00:02, 14.95it/s]\u001b[A\n",
            " 88% 301/342 [00:20<00:02, 14.77it/s]\u001b[A\n",
            " 89% 303/342 [00:20<00:02, 14.87it/s]\u001b[A\n",
            " 89% 305/342 [00:20<00:02, 15.21it/s]\u001b[A\n",
            " 90% 307/342 [00:20<00:02, 13.61it/s]\u001b[A\n",
            " 90% 309/342 [00:21<00:02, 14.44it/s]\u001b[A\n",
            " 91% 311/342 [00:21<00:01, 15.58it/s]\u001b[A\n",
            " 92% 313/342 [00:21<00:01, 15.48it/s]\u001b[A\n",
            " 92% 315/342 [00:21<00:01, 15.11it/s]\u001b[A\n",
            " 93% 317/342 [00:21<00:01, 16.08it/s]\u001b[A\n",
            " 93% 319/342 [00:21<00:01, 14.50it/s]\u001b[A\n",
            " 94% 321/342 [00:21<00:01, 15.04it/s]\u001b[A\n",
            " 94% 323/342 [00:21<00:01, 15.54it/s]\u001b[A\n",
            " 95% 325/342 [00:22<00:01, 15.45it/s]\u001b[A\n",
            " 96% 327/342 [00:22<00:01, 14.74it/s]\u001b[A\n",
            " 96% 329/342 [00:22<00:00, 14.42it/s]\u001b[A\n",
            " 97% 331/342 [00:22<00:00, 14.64it/s]\u001b[A\n",
            " 97% 333/342 [00:22<00:00, 14.86it/s]\u001b[A\n",
            " 98% 335/342 [00:22<00:00, 14.81it/s]\u001b[A\n",
            " 99% 337/342 [00:22<00:00, 15.28it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.6582670211791992, 'eval_accuracy': 0.603880651656599, 'eval_runtime': 23.1987, 'eval_samples_per_second': 235.487, 'eval_steps_per_second': 14.742, 'epoch': 3.0}\n",
            " 60% 19641/32735 [1:09:49<38:34,  5.66it/s]\n",
            "100% 342/342 [00:23<00:00, 16.49it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to custom-fnet-finetuned-qnli/checkpoint-19641\n",
            "Configuration saved in custom-fnet-finetuned-qnli/checkpoint-19641/config.json\n",
            "Model weights saved in custom-fnet-finetuned-qnli/checkpoint-19641/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-qnli/checkpoint-19641/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-qnli/checkpoint-19641/special_tokens_map.json\n",
            "{'loss': 0.6564, 'learning_rate': 7.780662899037727e-06, 'epoch': 3.05}\n",
            "{'loss': 0.6505, 'learning_rate': 7.47517947151367e-06, 'epoch': 3.13}\n",
            "{'loss': 0.6548, 'learning_rate': 7.169696043989614e-06, 'epoch': 3.21}\n",
            "{'loss': 0.655, 'learning_rate': 6.8642126164655576e-06, 'epoch': 3.28}\n",
            "{'loss': 0.6553, 'learning_rate': 6.558729188941501e-06, 'epoch': 3.36}\n",
            "{'loss': 0.6517, 'learning_rate': 6.253245761417443e-06, 'epoch': 3.44}\n",
            "{'loss': 0.654, 'learning_rate': 5.9477623338933865e-06, 'epoch': 3.51}\n",
            "{'loss': 0.6513, 'learning_rate': 5.64227890636933e-06, 'epoch': 3.59}\n",
            "{'loss': 0.6514, 'learning_rate': 5.336795478845274e-06, 'epoch': 3.67}\n",
            "{'loss': 0.6507, 'learning_rate': 5.031312051321216e-06, 'epoch': 3.74}\n",
            "{'loss': 0.6539, 'learning_rate': 4.7258286237971595e-06, 'epoch': 3.82}\n",
            "{'loss': 0.6411, 'learning_rate': 4.420345196273103e-06, 'epoch': 3.89}\n",
            "{'loss': 0.6571, 'learning_rate': 4.114861768749045e-06, 'epoch': 3.97}\n",
            " 80% 26187/32735 [1:32:41<24:59,  4.37it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 3/342 [00:00<00:19, 17.17it/s]\u001b[A\n",
            "  1% 5/342 [00:00<00:25, 13.40it/s]\u001b[A\n",
            "  2% 7/342 [00:00<00:23, 14.11it/s]\u001b[A\n",
            "  3% 9/342 [00:00<00:22, 14.78it/s]\u001b[A\n",
            "  3% 11/342 [00:00<00:21, 15.75it/s]\u001b[A\n",
            "  4% 13/342 [00:00<00:19, 16.51it/s]\u001b[A\n",
            "  4% 15/342 [00:00<00:21, 14.97it/s]\u001b[A\n",
            "  5% 17/342 [00:01<00:21, 15.43it/s]\u001b[A\n",
            "  6% 19/342 [00:01<00:19, 16.34it/s]\u001b[A\n",
            "  6% 21/342 [00:01<00:19, 16.19it/s]\u001b[A\n",
            "  7% 23/342 [00:01<00:20, 15.20it/s]\u001b[A\n",
            "  7% 25/342 [00:01<00:22, 14.10it/s]\u001b[A\n",
            "  8% 27/342 [00:01<00:21, 14.64it/s]\u001b[A\n",
            "  8% 29/342 [00:02<00:26, 11.73it/s]\u001b[A\n",
            "  9% 31/342 [00:02<00:25, 12.34it/s]\u001b[A\n",
            " 10% 33/342 [00:02<00:22, 13.65it/s]\u001b[A\n",
            " 10% 35/342 [00:02<00:21, 14.07it/s]\u001b[A\n",
            " 11% 37/342 [00:02<00:21, 14.27it/s]\u001b[A\n",
            " 11% 39/342 [00:02<00:20, 14.90it/s]\u001b[A\n",
            " 12% 41/342 [00:02<00:19, 15.69it/s]\u001b[A\n",
            " 13% 43/342 [00:02<00:18, 16.06it/s]\u001b[A\n",
            " 13% 45/342 [00:03<00:19, 14.93it/s]\u001b[A\n",
            " 14% 47/342 [00:03<00:21, 13.75it/s]\u001b[A\n",
            " 14% 49/342 [00:03<00:22, 13.24it/s]\u001b[A\n",
            " 15% 51/342 [00:03<00:22, 13.12it/s]\u001b[A\n",
            " 15% 53/342 [00:03<00:21, 13.19it/s]\u001b[A\n",
            " 16% 55/342 [00:03<00:20, 14.16it/s]\u001b[A\n",
            " 17% 57/342 [00:03<00:19, 14.47it/s]\u001b[A\n",
            " 17% 59/342 [00:04<00:19, 14.55it/s]\u001b[A\n",
            " 18% 61/342 [00:04<00:19, 14.45it/s]\u001b[A\n",
            " 18% 63/342 [00:04<00:20, 13.59it/s]\u001b[A\n",
            " 19% 65/342 [00:04<00:18, 14.73it/s]\u001b[A\n",
            " 20% 67/342 [00:04<00:18, 15.18it/s]\u001b[A\n",
            " 20% 69/342 [00:04<00:20, 13.21it/s]\u001b[A\n",
            " 21% 71/342 [00:04<00:21, 12.79it/s]\u001b[A\n",
            " 21% 73/342 [00:05<00:19, 13.69it/s]\u001b[A\n",
            " 22% 75/342 [00:05<00:18, 14.66it/s]\u001b[A\n",
            " 23% 77/342 [00:05<00:16, 15.84it/s]\u001b[A\n",
            " 23% 79/342 [00:05<00:16, 16.18it/s]\u001b[A\n",
            " 24% 81/342 [00:05<00:15, 16.59it/s]\u001b[A\n",
            " 24% 83/342 [00:05<00:15, 16.92it/s]\u001b[A\n",
            " 25% 85/342 [00:05<00:16, 16.00it/s]\u001b[A\n",
            " 25% 87/342 [00:05<00:16, 15.32it/s]\u001b[A\n",
            " 26% 89/342 [00:06<00:17, 14.33it/s]\u001b[A\n",
            " 27% 91/342 [00:06<00:16, 14.93it/s]\u001b[A\n",
            " 27% 93/342 [00:06<00:16, 15.18it/s]\u001b[A\n",
            " 28% 95/342 [00:06<00:15, 16.35it/s]\u001b[A\n",
            " 29% 98/342 [00:06<00:14, 16.44it/s]\u001b[A\n",
            " 29% 100/342 [00:06<00:14, 16.69it/s]\u001b[A\n",
            " 30% 102/342 [00:06<00:14, 16.25it/s]\u001b[A\n",
            " 30% 104/342 [00:07<00:14, 16.15it/s]\u001b[A\n",
            " 31% 106/342 [00:07<00:15, 15.33it/s]\u001b[A\n",
            " 32% 108/342 [00:07<00:14, 15.76it/s]\u001b[A\n",
            " 32% 110/342 [00:07<00:14, 15.63it/s]\u001b[A\n",
            " 33% 112/342 [00:07<00:14, 15.80it/s]\u001b[A\n",
            " 33% 114/342 [00:07<00:14, 15.86it/s]\u001b[A\n",
            " 34% 116/342 [00:07<00:15, 14.44it/s]\u001b[A\n",
            " 35% 118/342 [00:07<00:16, 13.96it/s]\u001b[A\n",
            " 35% 120/342 [00:08<00:14, 15.12it/s]\u001b[A\n",
            " 36% 122/342 [00:08<00:15, 13.93it/s]\u001b[A\n",
            " 36% 124/342 [00:08<00:14, 14.69it/s]\u001b[A\n",
            " 37% 126/342 [00:08<00:14, 15.06it/s]\u001b[A\n",
            " 37% 128/342 [00:08<00:13, 15.49it/s]\u001b[A\n",
            " 38% 130/342 [00:08<00:14, 14.41it/s]\u001b[A\n",
            " 39% 132/342 [00:08<00:14, 14.42it/s]\u001b[A\n",
            " 39% 134/342 [00:09<00:13, 15.01it/s]\u001b[A\n",
            " 40% 136/342 [00:09<00:13, 14.72it/s]\u001b[A\n",
            " 40% 138/342 [00:09<00:14, 14.07it/s]\u001b[A\n",
            " 41% 140/342 [00:09<00:14, 14.18it/s]\u001b[A\n",
            " 42% 142/342 [00:09<00:14, 14.24it/s]\u001b[A\n",
            " 42% 144/342 [00:09<00:13, 14.79it/s]\u001b[A\n",
            " 43% 146/342 [00:09<00:12, 15.32it/s]\u001b[A\n",
            " 43% 148/342 [00:09<00:12, 15.79it/s]\u001b[A\n",
            " 44% 150/342 [00:10<00:12, 15.60it/s]\u001b[A\n",
            " 44% 152/342 [00:10<00:13, 13.79it/s]\u001b[A\n",
            " 45% 154/342 [00:10<00:14, 12.73it/s]\u001b[A\n",
            " 46% 156/342 [00:10<00:13, 13.79it/s]\u001b[A\n",
            " 46% 158/342 [00:10<00:14, 12.83it/s]\u001b[A\n",
            " 47% 160/342 [00:10<00:15, 11.72it/s]\u001b[A\n",
            " 47% 162/342 [00:11<00:15, 11.89it/s]\u001b[A\n",
            " 48% 164/342 [00:11<00:14, 12.30it/s]\u001b[A\n",
            " 49% 166/342 [00:11<00:12, 13.64it/s]\u001b[A\n",
            " 49% 169/342 [00:11<00:11, 15.71it/s]\u001b[A\n",
            " 50% 171/342 [00:11<00:11, 15.24it/s]\u001b[A\n",
            " 51% 173/342 [00:11<00:10, 16.30it/s]\u001b[A\n",
            " 51% 175/342 [00:11<00:10, 15.50it/s]\u001b[A\n",
            " 52% 177/342 [00:12<00:11, 14.78it/s]\u001b[A\n",
            " 52% 179/342 [00:12<00:10, 14.84it/s]\u001b[A\n",
            " 53% 181/342 [00:12<00:11, 14.44it/s]\u001b[A\n",
            " 54% 183/342 [00:12<00:10, 14.98it/s]\u001b[A\n",
            " 54% 185/342 [00:12<00:10, 15.64it/s]\u001b[A\n",
            " 55% 187/342 [00:12<00:11, 14.01it/s]\u001b[A\n",
            " 55% 189/342 [00:12<00:10, 14.58it/s]\u001b[A\n",
            " 56% 191/342 [00:13<00:10, 14.02it/s]\u001b[A\n",
            " 56% 193/342 [00:13<00:10, 13.98it/s]\u001b[A\n",
            " 57% 195/342 [00:13<00:09, 15.31it/s]\u001b[A\n",
            " 58% 197/342 [00:13<00:09, 15.76it/s]\u001b[A\n",
            " 58% 199/342 [00:13<00:10, 14.15it/s]\u001b[A\n",
            " 59% 201/342 [00:13<00:10, 12.90it/s]\u001b[A\n",
            " 59% 203/342 [00:13<00:09, 14.17it/s]\u001b[A\n",
            " 60% 205/342 [00:14<00:11, 12.22it/s]\u001b[A\n",
            " 61% 207/342 [00:14<00:10, 13.16it/s]\u001b[A\n",
            " 61% 209/342 [00:14<00:10, 12.82it/s]\u001b[A\n",
            " 62% 211/342 [00:14<00:10, 12.94it/s]\u001b[A\n",
            " 62% 213/342 [00:14<00:09, 13.67it/s]\u001b[A\n",
            " 63% 215/342 [00:14<00:09, 13.97it/s]\u001b[A\n",
            " 63% 217/342 [00:14<00:08, 14.70it/s]\u001b[A\n",
            " 64% 219/342 [00:15<00:09, 13.08it/s]\u001b[A\n",
            " 65% 221/342 [00:15<00:08, 14.06it/s]\u001b[A\n",
            " 65% 223/342 [00:15<00:07, 15.02it/s]\u001b[A\n",
            " 66% 225/342 [00:15<00:07, 15.43it/s]\u001b[A\n",
            " 66% 227/342 [00:15<00:06, 16.49it/s]\u001b[A\n",
            " 67% 229/342 [00:15<00:06, 16.69it/s]\u001b[A\n",
            " 68% 231/342 [00:15<00:06, 15.96it/s]\u001b[A\n",
            " 68% 233/342 [00:15<00:06, 15.70it/s]\u001b[A\n",
            " 69% 235/342 [00:16<00:07, 15.20it/s]\u001b[A\n",
            " 69% 237/342 [00:16<00:07, 14.72it/s]\u001b[A\n",
            " 70% 239/342 [00:16<00:07, 14.61it/s]\u001b[A\n",
            " 70% 241/342 [00:16<00:06, 15.37it/s]\u001b[A\n",
            " 71% 243/342 [00:16<00:06, 16.04it/s]\u001b[A\n",
            " 72% 245/342 [00:16<00:05, 16.51it/s]\u001b[A\n",
            " 72% 247/342 [00:16<00:05, 15.87it/s]\u001b[A\n",
            " 73% 249/342 [00:16<00:05, 16.08it/s]\u001b[A\n",
            " 73% 251/342 [00:17<00:05, 15.90it/s]\u001b[A\n",
            " 74% 253/342 [00:17<00:05, 16.57it/s]\u001b[A\n",
            " 75% 255/342 [00:17<00:05, 16.36it/s]\u001b[A\n",
            " 75% 257/342 [00:17<00:05, 16.33it/s]\u001b[A\n",
            " 76% 259/342 [00:17<00:05, 16.21it/s]\u001b[A\n",
            " 76% 261/342 [00:17<00:05, 15.28it/s]\u001b[A\n",
            " 77% 263/342 [00:17<00:05, 15.31it/s]\u001b[A\n",
            " 77% 265/342 [00:18<00:05, 15.37it/s]\u001b[A\n",
            " 78% 267/342 [00:18<00:05, 14.10it/s]\u001b[A\n",
            " 79% 269/342 [00:18<00:04, 15.03it/s]\u001b[A\n",
            " 79% 271/342 [00:18<00:04, 16.01it/s]\u001b[A\n",
            " 80% 273/342 [00:18<00:04, 15.60it/s]\u001b[A\n",
            " 80% 275/342 [00:18<00:04, 15.89it/s]\u001b[A\n",
            " 81% 277/342 [00:18<00:04, 16.23it/s]\u001b[A\n",
            " 82% 279/342 [00:18<00:03, 16.13it/s]\u001b[A\n",
            " 82% 281/342 [00:19<00:03, 16.83it/s]\u001b[A\n",
            " 83% 283/342 [00:19<00:03, 16.49it/s]\u001b[A\n",
            " 83% 285/342 [00:19<00:04, 13.78it/s]\u001b[A\n",
            " 84% 287/342 [00:19<00:03, 14.94it/s]\u001b[A\n",
            " 85% 289/342 [00:19<00:03, 15.81it/s]\u001b[A\n",
            " 85% 291/342 [00:19<00:03, 15.06it/s]\u001b[A\n",
            " 86% 293/342 [00:19<00:03, 14.39it/s]\u001b[A\n",
            " 86% 295/342 [00:19<00:03, 14.96it/s]\u001b[A\n",
            " 87% 297/342 [00:20<00:02, 15.08it/s]\u001b[A\n",
            " 87% 299/342 [00:20<00:02, 14.82it/s]\u001b[A\n",
            " 88% 301/342 [00:20<00:02, 14.74it/s]\u001b[A\n",
            " 89% 303/342 [00:20<00:02, 14.87it/s]\u001b[A\n",
            " 89% 305/342 [00:20<00:02, 15.26it/s]\u001b[A\n",
            " 90% 307/342 [00:20<00:02, 13.61it/s]\u001b[A\n",
            " 90% 309/342 [00:20<00:02, 14.47it/s]\u001b[A\n",
            " 91% 311/342 [00:21<00:01, 15.63it/s]\u001b[A\n",
            " 92% 313/342 [00:21<00:01, 15.45it/s]\u001b[A\n",
            " 92% 315/342 [00:21<00:01, 15.06it/s]\u001b[A\n",
            " 93% 317/342 [00:21<00:01, 16.13it/s]\u001b[A\n",
            " 93% 319/342 [00:21<00:01, 14.46it/s]\u001b[A\n",
            " 94% 321/342 [00:21<00:01, 15.21it/s]\u001b[A\n",
            " 94% 323/342 [00:21<00:01, 15.70it/s]\u001b[A\n",
            " 95% 325/342 [00:21<00:01, 15.50it/s]\u001b[A\n",
            " 96% 327/342 [00:22<00:01, 14.72it/s]\u001b[A\n",
            " 96% 329/342 [00:22<00:00, 14.42it/s]\u001b[A\n",
            " 97% 331/342 [00:22<00:00, 14.47it/s]\u001b[A\n",
            " 97% 333/342 [00:22<00:00, 14.64it/s]\u001b[A\n",
            " 98% 335/342 [00:22<00:00, 14.66it/s]\u001b[A\n",
            " 99% 337/342 [00:22<00:00, 15.20it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.657609224319458, 'eval_accuracy': 0.6060772469339191, 'eval_runtime': 23.1465, 'eval_samples_per_second': 236.018, 'eval_steps_per_second': 14.775, 'epoch': 4.0}\n",
            " 80% 26188/32735 [1:33:05<24:59,  4.37it/s]\n",
            "100% 342/342 [00:23<00:00, 16.43it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to custom-fnet-finetuned-qnli/checkpoint-26188\n",
            "Configuration saved in custom-fnet-finetuned-qnli/checkpoint-26188/config.json\n",
            "Model weights saved in custom-fnet-finetuned-qnli/checkpoint-26188/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-qnli/checkpoint-26188/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-qnli/checkpoint-26188/special_tokens_map.json\n",
            "{'loss': 0.6481, 'learning_rate': 3.809378341224989e-06, 'epoch': 4.05}\n",
            "{'loss': 0.6398, 'learning_rate': 3.503894913700932e-06, 'epoch': 4.12}\n",
            "{'loss': 0.6411, 'learning_rate': 3.198411486176875e-06, 'epoch': 4.2}\n",
            "{'loss': 0.6436, 'learning_rate': 2.8929280586528187e-06, 'epoch': 4.28}\n",
            "{'loss': 0.6456, 'learning_rate': 2.5874446311287615e-06, 'epoch': 4.35}\n",
            "{'loss': 0.6396, 'learning_rate': 2.2819612036047043e-06, 'epoch': 4.43}\n",
            "{'loss': 0.6414, 'learning_rate': 1.9764777760806476e-06, 'epoch': 4.51}\n",
            "{'loss': 0.6457, 'learning_rate': 1.670994348556591e-06, 'epoch': 4.58}\n",
            "{'loss': 0.6445, 'learning_rate': 1.3655109210325341e-06, 'epoch': 4.66}\n",
            "{'loss': 0.6417, 'learning_rate': 1.0600274935084774e-06, 'epoch': 4.73}\n",
            "{'loss': 0.6371, 'learning_rate': 7.545440659844204e-07, 'epoch': 4.81}\n",
            "{'loss': 0.6337, 'learning_rate': 4.490606384603636e-07, 'epoch': 4.89}\n",
            "{'loss': 0.6415, 'learning_rate': 1.4357721093630674e-07, 'epoch': 4.96}\n",
            "100% 32735/32735 [1:55:57<00:00,  5.32it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: question, idx, sentence. If question, idx, sentence are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5463\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/342 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 3/342 [00:00<00:19, 17.41it/s]\u001b[A\n",
            "  1% 5/342 [00:00<00:24, 13.59it/s]\u001b[A\n",
            "  2% 7/342 [00:00<00:23, 14.23it/s]\u001b[A\n",
            "  3% 9/342 [00:00<00:22, 14.72it/s]\u001b[A\n",
            "  3% 11/342 [00:00<00:21, 15.61it/s]\u001b[A\n",
            "  4% 13/342 [00:00<00:20, 16.20it/s]\u001b[A\n",
            "  4% 15/342 [00:01<00:22, 14.74it/s]\u001b[A\n",
            "  5% 17/342 [00:01<00:21, 15.14it/s]\u001b[A\n",
            "  6% 19/342 [00:01<00:19, 16.16it/s]\u001b[A\n",
            "  6% 21/342 [00:01<00:19, 16.07it/s]\u001b[A\n",
            "  7% 23/342 [00:01<00:21, 15.11it/s]\u001b[A\n",
            "  7% 25/342 [00:01<00:22, 14.27it/s]\u001b[A\n",
            "  8% 27/342 [00:01<00:21, 14.62it/s]\u001b[A\n",
            "  8% 29/342 [00:02<00:26, 11.64it/s]\u001b[A\n",
            "  9% 31/342 [00:02<00:25, 12.22it/s]\u001b[A\n",
            " 10% 33/342 [00:02<00:22, 13.61it/s]\u001b[A\n",
            " 10% 35/342 [00:02<00:21, 14.06it/s]\u001b[A\n",
            " 11% 37/342 [00:02<00:21, 14.26it/s]\u001b[A\n",
            " 11% 39/342 [00:02<00:20, 14.79it/s]\u001b[A\n",
            " 12% 41/342 [00:02<00:19, 15.61it/s]\u001b[A\n",
            " 13% 43/342 [00:02<00:18, 15.86it/s]\u001b[A\n",
            " 13% 45/342 [00:03<00:20, 14.79it/s]\u001b[A\n",
            " 14% 47/342 [00:03<00:21, 13.69it/s]\u001b[A\n",
            " 14% 49/342 [00:03<00:22, 13.26it/s]\u001b[A\n",
            " 15% 51/342 [00:03<00:21, 13.24it/s]\u001b[A\n",
            " 15% 53/342 [00:03<00:21, 13.24it/s]\u001b[A\n",
            " 16% 55/342 [00:03<00:19, 14.36it/s]\u001b[A\n",
            " 17% 57/342 [00:03<00:19, 14.41it/s]\u001b[A\n",
            " 17% 59/342 [00:04<00:19, 14.47it/s]\u001b[A\n",
            " 18% 61/342 [00:04<00:19, 14.41it/s]\u001b[A\n",
            " 18% 63/342 [00:04<00:20, 13.70it/s]\u001b[A\n",
            " 19% 65/342 [00:04<00:18, 15.07it/s]\u001b[A\n",
            " 20% 67/342 [00:04<00:17, 15.38it/s]\u001b[A\n",
            " 20% 69/342 [00:04<00:20, 13.13it/s]\u001b[A\n",
            " 21% 71/342 [00:05<00:21, 12.56it/s]\u001b[A\n",
            " 21% 73/342 [00:05<00:19, 13.56it/s]\u001b[A\n",
            " 22% 75/342 [00:05<00:18, 14.54it/s]\u001b[A\n",
            " 23% 77/342 [00:05<00:17, 15.59it/s]\u001b[A\n",
            " 23% 79/342 [00:05<00:16, 16.06it/s]\u001b[A\n",
            " 24% 81/342 [00:05<00:15, 16.50it/s]\u001b[A\n",
            " 24% 83/342 [00:05<00:15, 16.92it/s]\u001b[A\n",
            " 25% 85/342 [00:05<00:15, 16.06it/s]\u001b[A\n",
            " 25% 87/342 [00:05<00:16, 15.10it/s]\u001b[A\n",
            " 26% 89/342 [00:06<00:17, 14.20it/s]\u001b[A\n",
            " 27% 91/342 [00:06<00:16, 14.82it/s]\u001b[A\n",
            " 27% 93/342 [00:06<00:16, 15.22it/s]\u001b[A\n",
            " 28% 96/342 [00:06<00:14, 17.31it/s]\u001b[A\n",
            " 29% 98/342 [00:06<00:14, 16.32it/s]\u001b[A\n",
            " 29% 100/342 [00:06<00:14, 16.60it/s]\u001b[A\n",
            " 30% 102/342 [00:06<00:14, 16.05it/s]\u001b[A\n",
            " 30% 104/342 [00:07<00:14, 15.88it/s]\u001b[A\n",
            " 31% 106/342 [00:07<00:15, 15.21it/s]\u001b[A\n",
            " 32% 108/342 [00:07<00:14, 15.65it/s]\u001b[A\n",
            " 32% 110/342 [00:07<00:14, 15.75it/s]\u001b[A\n",
            " 33% 112/342 [00:07<00:14, 15.90it/s]\u001b[A\n",
            " 33% 114/342 [00:07<00:14, 15.81it/s]\u001b[A\n",
            " 34% 116/342 [00:07<00:15, 14.41it/s]\u001b[A\n",
            " 35% 118/342 [00:08<00:16, 13.84it/s]\u001b[A\n",
            " 35% 120/342 [00:08<00:14, 14.96it/s]\u001b[A\n",
            " 36% 122/342 [00:08<00:15, 13.77it/s]\u001b[A\n",
            " 36% 124/342 [00:08<00:14, 14.84it/s]\u001b[A\n",
            " 37% 126/342 [00:08<00:14, 15.33it/s]\u001b[A\n",
            " 37% 128/342 [00:08<00:13, 15.74it/s]\u001b[A\n",
            " 38% 130/342 [00:08<00:14, 14.66it/s]\u001b[A\n",
            " 39% 132/342 [00:08<00:14, 14.55it/s]\u001b[A\n",
            " 39% 134/342 [00:09<00:13, 15.21it/s]\u001b[A\n",
            " 40% 136/342 [00:09<00:13, 14.82it/s]\u001b[A\n",
            " 40% 138/342 [00:09<00:14, 14.35it/s]\u001b[A\n",
            " 41% 140/342 [00:09<00:14, 14.34it/s]\u001b[A\n",
            " 42% 142/342 [00:09<00:13, 14.40it/s]\u001b[A\n",
            " 42% 144/342 [00:09<00:13, 14.98it/s]\u001b[A\n",
            " 43% 146/342 [00:09<00:12, 15.52it/s]\u001b[A\n",
            " 43% 148/342 [00:09<00:12, 15.81it/s]\u001b[A\n",
            " 44% 150/342 [00:10<00:12, 15.45it/s]\u001b[A\n",
            " 44% 152/342 [00:10<00:14, 13.52it/s]\u001b[A\n",
            " 45% 154/342 [00:10<00:14, 12.60it/s]\u001b[A\n",
            " 46% 156/342 [00:10<00:13, 13.67it/s]\u001b[A\n",
            " 46% 158/342 [00:10<00:14, 12.70it/s]\u001b[A\n",
            " 47% 160/342 [00:11<00:15, 11.64it/s]\u001b[A\n",
            " 47% 162/342 [00:11<00:15, 11.82it/s]\u001b[A\n",
            " 48% 164/342 [00:11<00:14, 12.28it/s]\u001b[A\n",
            " 49% 166/342 [00:11<00:12, 13.72it/s]\u001b[A\n",
            " 49% 168/342 [00:11<00:11, 15.13it/s]\u001b[A\n",
            " 50% 170/342 [00:11<00:11, 15.59it/s]\u001b[A\n",
            " 50% 172/342 [00:11<00:10, 16.16it/s]\u001b[A\n",
            " 51% 174/342 [00:11<00:10, 15.78it/s]\u001b[A\n",
            " 51% 176/342 [00:12<00:10, 15.51it/s]\u001b[A\n",
            " 52% 178/342 [00:12<00:11, 14.15it/s]\u001b[A\n",
            " 53% 180/342 [00:12<00:11, 14.16it/s]\u001b[A\n",
            " 53% 182/342 [00:12<00:11, 14.47it/s]\u001b[A\n",
            " 54% 184/342 [00:12<00:10, 15.41it/s]\u001b[A\n",
            " 54% 186/342 [00:12<00:10, 15.09it/s]\u001b[A\n",
            " 55% 188/342 [00:12<00:10, 14.46it/s]\u001b[A\n",
            " 56% 190/342 [00:12<00:10, 15.17it/s]\u001b[A\n",
            " 56% 192/342 [00:13<00:10, 14.18it/s]\u001b[A\n",
            " 57% 194/342 [00:13<00:10, 14.09it/s]\u001b[A\n",
            " 57% 196/342 [00:13<00:09, 15.24it/s]\u001b[A\n",
            " 58% 198/342 [00:13<00:09, 14.75it/s]\u001b[A\n",
            " 58% 200/342 [00:13<00:11, 12.30it/s]\u001b[A\n",
            " 59% 202/342 [00:13<00:10, 13.31it/s]\u001b[A\n",
            " 60% 204/342 [00:14<00:10, 12.60it/s]\u001b[A\n",
            " 60% 206/342 [00:14<00:10, 12.95it/s]\u001b[A\n",
            " 61% 208/342 [00:14<00:09, 13.82it/s]\u001b[A\n",
            " 61% 210/342 [00:14<00:10, 12.85it/s]\u001b[A\n",
            " 62% 212/342 [00:14<00:09, 13.23it/s]\u001b[A\n",
            " 63% 214/342 [00:14<00:09, 13.62it/s]\u001b[A\n",
            " 63% 216/342 [00:14<00:09, 13.97it/s]\u001b[A\n",
            " 64% 218/342 [00:15<00:09, 13.45it/s]\u001b[A\n",
            " 64% 220/342 [00:15<00:08, 13.75it/s]\u001b[A\n",
            " 65% 222/342 [00:15<00:08, 14.01it/s]\u001b[A\n",
            " 66% 225/342 [00:15<00:07, 15.39it/s]\u001b[A\n",
            " 66% 227/342 [00:15<00:07, 16.35it/s]\u001b[A\n",
            " 67% 229/342 [00:15<00:06, 16.60it/s]\u001b[A\n",
            " 68% 231/342 [00:15<00:06, 15.94it/s]\u001b[A\n",
            " 68% 233/342 [00:16<00:06, 15.69it/s]\u001b[A\n",
            " 69% 235/342 [00:16<00:06, 15.29it/s]\u001b[A\n",
            " 69% 237/342 [00:16<00:07, 14.96it/s]\u001b[A\n",
            " 70% 239/342 [00:16<00:06, 14.73it/s]\u001b[A\n",
            " 70% 241/342 [00:16<00:06, 15.43it/s]\u001b[A\n",
            " 71% 243/342 [00:16<00:06, 16.06it/s]\u001b[A\n",
            " 72% 245/342 [00:16<00:05, 16.55it/s]\u001b[A\n",
            " 72% 247/342 [00:16<00:05, 16.07it/s]\u001b[A\n",
            " 73% 249/342 [00:17<00:05, 16.13it/s]\u001b[A\n",
            " 73% 251/342 [00:17<00:05, 15.87it/s]\u001b[A\n",
            " 74% 253/342 [00:17<00:05, 16.57it/s]\u001b[A\n",
            " 75% 255/342 [00:17<00:05, 16.32it/s]\u001b[A\n",
            " 75% 257/342 [00:17<00:05, 16.18it/s]\u001b[A\n",
            " 76% 259/342 [00:17<00:05, 15.98it/s]\u001b[A\n",
            " 76% 261/342 [00:17<00:05, 14.84it/s]\u001b[A\n",
            " 77% 263/342 [00:17<00:05, 15.05it/s]\u001b[A\n",
            " 77% 265/342 [00:18<00:05, 15.06it/s]\u001b[A\n",
            " 78% 267/342 [00:18<00:05, 13.99it/s]\u001b[A\n",
            " 79% 269/342 [00:18<00:04, 14.93it/s]\u001b[A\n",
            " 79% 271/342 [00:18<00:04, 15.80it/s]\u001b[A\n",
            " 80% 273/342 [00:18<00:04, 15.51it/s]\u001b[A\n",
            " 80% 275/342 [00:18<00:04, 15.73it/s]\u001b[A\n",
            " 81% 277/342 [00:18<00:04, 16.05it/s]\u001b[A\n",
            " 82% 279/342 [00:18<00:03, 16.16it/s]\u001b[A\n",
            " 82% 281/342 [00:19<00:03, 16.72it/s]\u001b[A\n",
            " 83% 283/342 [00:19<00:03, 16.36it/s]\u001b[A\n",
            " 83% 285/342 [00:19<00:04, 13.72it/s]\u001b[A\n",
            " 84% 287/342 [00:19<00:03, 14.81it/s]\u001b[A\n",
            " 85% 289/342 [00:19<00:03, 15.74it/s]\u001b[A\n",
            " 85% 291/342 [00:19<00:03, 14.72it/s]\u001b[A\n",
            " 86% 293/342 [00:19<00:03, 14.38it/s]\u001b[A\n",
            " 86% 295/342 [00:20<00:03, 14.80it/s]\u001b[A\n",
            " 87% 297/342 [00:20<00:03, 14.99it/s]\u001b[A\n",
            " 87% 299/342 [00:20<00:02, 14.77it/s]\u001b[A\n",
            " 88% 301/342 [00:20<00:02, 14.69it/s]\u001b[A\n",
            " 89% 303/342 [00:20<00:02, 14.73it/s]\u001b[A\n",
            " 89% 305/342 [00:20<00:02, 14.95it/s]\u001b[A\n",
            " 90% 307/342 [00:20<00:02, 13.44it/s]\u001b[A\n",
            " 90% 309/342 [00:21<00:02, 14.31it/s]\u001b[A\n",
            " 91% 311/342 [00:21<00:02, 15.31it/s]\u001b[A\n",
            " 92% 313/342 [00:21<00:01, 15.13it/s]\u001b[A\n",
            " 92% 315/342 [00:21<00:01, 15.03it/s]\u001b[A\n",
            " 93% 317/342 [00:21<00:01, 16.14it/s]\u001b[A\n",
            " 93% 319/342 [00:21<00:01, 14.44it/s]\u001b[A\n",
            " 94% 321/342 [00:21<00:01, 15.08it/s]\u001b[A\n",
            " 94% 323/342 [00:21<00:01, 15.57it/s]\u001b[A\n",
            " 95% 325/342 [00:22<00:01, 15.36it/s]\u001b[A\n",
            " 96% 327/342 [00:22<00:01, 14.55it/s]\u001b[A\n",
            " 96% 329/342 [00:22<00:00, 14.40it/s]\u001b[A\n",
            " 97% 331/342 [00:22<00:00, 14.63it/s]\u001b[A\n",
            " 97% 333/342 [00:22<00:00, 14.93it/s]\u001b[A\n",
            " 98% 335/342 [00:22<00:00, 14.92it/s]\u001b[A\n",
            " 99% 337/342 [00:22<00:00, 15.34it/s]\u001b[A\n",
            " 99% 339/342 [00:22<00:00, 16.47it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.6622180938720703, 'eval_accuracy': 0.6009518579535054, 'eval_runtime': 23.2152, 'eval_samples_per_second': 235.32, 'eval_steps_per_second': 14.732, 'epoch': 5.0}\n",
            "100% 32735/32735 [1:56:20<00:00,  5.32it/s]\n",
            "100% 342/342 [00:23<00:00, 16.43it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to custom-fnet-finetuned-qnli/checkpoint-32735\n",
            "Configuration saved in custom-fnet-finetuned-qnli/checkpoint-32735/config.json\n",
            "Model weights saved in custom-fnet-finetuned-qnli/checkpoint-32735/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-qnli/checkpoint-32735/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-qnli/checkpoint-32735/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from custom-fnet-finetuned-qnli/checkpoint-26188 (score: 0.6060772469339191).\n",
            "{'train_runtime': 6984.5791, 'train_samples_per_second': 74.982, 'train_steps_per_second': 4.687, 'train_loss': 0.6659264350822359, 'epoch': 5.0}\n",
            "100% 32735/32735 [1:56:24<00:00,  5.32it/s]Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/content/bert-vs-fnet/custom-fnet-finetuned-qnli is already a clone of https://huggingface.co/Joqsan/custom-fnet-finetuned-qnli. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-vs-fnet/custom-fnet-finetuned-qnli is already a clone of https://huggingface.co/Joqsan/custom-fnet-finetuned-qnli. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Saving model checkpoint to /tmp/tmpkh4oq6dw\n",
            "Configuration saved in /tmp/tmpkh4oq6dw/config.json\n",
            "Model weights saved in /tmp/tmpkh4oq6dw/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmpkh4oq6dw/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmpkh4oq6dw/special_tokens_map.json\n",
            "Saving model checkpoint to custom-fnet-finetuned-qnli\n",
            "Configuration saved in custom-fnet-finetuned-qnli/config.json\n",
            "Model weights saved in custom-fnet-finetuned-qnli/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-qnli/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-qnli/special_tokens_map.json\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Upload file pytorch_model.bin:   0% 32.0k/337M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "Upload file pytorch_model.bin:   0% 576k/337M [00:01<10:33, 556kB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   2% 5.50M/337M [00:02<01:46, 3.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 14.1M/337M [00:03<00:57, 5.88MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 22.9M/337M [00:04<00:45, 7.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 31.7M/337M [00:05<00:40, 7.93MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  12% 40.5M/337M [00:06<00:37, 8.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 49.2M/337M [00:07<00:34, 8.62MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  17% 58.2M/337M [00:08<00:32, 8.85MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  20% 67.4M/337M [00:09<00:31, 9.10MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 76.9M/337M [00:10<00:29, 9.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  26% 86.4M/337M [00:11<00:27, 9.55MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 95.6M/337M [00:12<00:26, 9.57MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 105M/337M [00:13<00:25, 9.56MB/s] \u001b[A\n",
            "Upload file pytorch_model.bin:  34% 114M/337M [00:14<00:24, 9.55MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 123M/337M [00:15<00:23, 9.62MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 132M/337M [00:16<00:22, 9.58MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 142M/337M [00:17<00:21, 9.60MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 151M/337M [00:18<00:20, 9.64MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  48% 160M/337M [00:19<00:19, 9.68MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 169M/337M [00:20<00:18, 9.68MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  53% 179M/337M [00:21<00:17, 9.64MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 188M/337M [00:22<00:16, 9.58MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 197M/337M [00:23<00:15, 9.57MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 206M/337M [00:24<00:14, 9.57MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 215M/337M [00:25<00:13, 9.59MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 224M/337M [00:26<00:12, 9.59MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 234M/337M [00:27<00:11, 9.64MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 243M/337M [00:28<00:10, 9.59MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  75% 252M/337M [00:29<00:09, 9.68MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 261M/337M [00:30<00:08, 9.72MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  80% 271M/337M [00:31<00:07, 9.72MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 280M/337M [00:32<00:06, 9.73MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 289M/337M [00:33<00:05, 9.75MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 299M/337M [00:34<00:04, 9.75MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 308M/337M [00:35<00:03, 9.74MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 317M/337M [00:36<00:02, 9.72MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 326M/337M [00:37<00:01, 9.71MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 336M/337M [00:38<00:00, 9.69MB/s]\u001b[Aremote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/custom-fnet-finetuned-qnli\n",
            "   d13df27..cc2baf1  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/custom-fnet-finetuned-qnli\n",
            "   d13df27..cc2baf1  main -> main\n",
            "\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 337M/337M [00:41<00:00, 8.59MB/s]\n",
            "\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:41<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:41<?, ?B/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "To https://huggingface.co/Joqsan/custom-fnet-finetuned-qnli\n",
            "   cc2baf1..b3609de  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/Joqsan/custom-fnet-finetuned-qnli\n",
            "   cc2baf1..b3609de  main -> main\n",
            "\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Logging model artifacts. ...\n",
            "100% 32735/32735 [1:57:56<00:00,  4.63it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▁▅▇█▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▄▁▁▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▆█▆▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▃▁▃█▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▃▁▃█▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ██▇▇▇▇▇▆▅▅▅▅▅▄▅▅▄▄▄▄▄▃▃▄▃▃▃▂▃▂▃▁▂▁▂▁▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.60095\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.66222\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 23.2152\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 235.32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 14.732\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 32735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.6415\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.8092006146405584e+16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.66593\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 6984.5791\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 74.982\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 4.687\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcustom-fnet-qnli\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/i2wefh0r\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230130_153047-i2wefh0r/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/fine_tuning.py bert-base-uncased rte"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtIKAVddtpmR",
        "outputId": "607993a0-fee5-4c58-90aa-e1fb5d056032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "Downloading and preparing dataset glue/rte to /root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n",
            "Downloading data: 100% 697k/697k [00:01<00:00, 645kB/s]\n",
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 733.06it/s]\n",
            "100% 3/3 [00:00<00:00,  7.39ba/s]\n",
            "100% 1/1 [00:00<00:00, 23.24ba/s]\n",
            "100% 3/3 [00:00<00:00,  4.67ba/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "models/fine_tuning.py:86: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"glue\", actual_task)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoqsan-a\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/bert-vs-fnet/wandb/run-20230130_181327-12mjp8g4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbert-base-uncased-rte\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/12mjp8g4\u001b[0m\n",
            "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Cloning https://huggingface.co/Joqsan/bert-base-uncased-finetuned-rte into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/Joqsan/bert-base-uncased-finetuned-rte into local empty directory.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2. If sentence1, idx, sentence2 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 2490\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 780\n",
            "  Number of trainable parameters = 109483778\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "  0% 0/780 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            " 20% 156/780 [01:13<04:54,  2.12it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2. If sentence1, idx, sentence2 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:01, 14.58it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01,  8.07it/s]\u001b[A\n",
            " 28% 5/18 [00:00<00:01,  7.62it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  6.86it/s]\u001b[A\n",
            " 39% 7/18 [00:00<00:01,  6.35it/s]\u001b[A\n",
            " 44% 8/18 [00:01<00:01,  6.11it/s]\u001b[A\n",
            " 50% 9/18 [00:01<00:01,  6.55it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:01,  6.49it/s]\u001b[A\n",
            " 61% 11/18 [00:01<00:01,  6.93it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  7.00it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  6.63it/s]\u001b[A\n",
            " 78% 14/18 [00:02<00:00,  6.17it/s]\u001b[A\n",
            " 83% 15/18 [00:02<00:00,  6.11it/s]\u001b[A\n",
            " 89% 16/18 [00:02<00:00,  5.44it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7084569931030273, 'eval_accuracy': 0.5306859205776173, 'eval_runtime': 2.8589, 'eval_samples_per_second': 96.891, 'eval_steps_per_second': 6.296, 'epoch': 1.0}\n",
            " 20% 156/780 [01:16<04:54,  2.12it/s]\n",
            "100% 18/18 [00:02<00:00,  5.33it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-rte/checkpoint-156\n",
            "Configuration saved in bert-base-uncased-finetuned-rte/checkpoint-156/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-rte/checkpoint-156/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-rte/checkpoint-156/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-rte/checkpoint-156/special_tokens_map.json\n",
            " 40% 312/780 [02:34<03:24,  2.29it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2. If sentence1, idx, sentence2 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:01, 14.11it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01,  7.80it/s]\u001b[A\n",
            " 28% 5/18 [00:00<00:01,  7.40it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  6.87it/s]\u001b[A\n",
            " 39% 7/18 [00:00<00:01,  6.29it/s]\u001b[A\n",
            " 44% 8/18 [00:01<00:01,  6.10it/s]\u001b[A\n",
            " 50% 9/18 [00:01<00:01,  6.46it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:01,  6.51it/s]\u001b[A\n",
            " 61% 11/18 [00:01<00:01,  6.86it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  7.02it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  6.59it/s]\u001b[A\n",
            " 78% 14/18 [00:02<00:00,  6.23it/s]\u001b[A\n",
            " 83% 15/18 [00:02<00:00,  6.09it/s]\u001b[A\n",
            " 89% 16/18 [00:02<00:00,  5.35it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7141496539115906, 'eval_accuracy': 0.6353790613718412, 'eval_runtime': 2.88, 'eval_samples_per_second': 96.182, 'eval_steps_per_second': 6.25, 'epoch': 2.0}\n",
            " 40% 312/780 [02:37<03:24,  2.29it/s]\n",
            "100% 18/18 [00:02<00:00,  5.29it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-rte/checkpoint-312\n",
            "Configuration saved in bert-base-uncased-finetuned-rte/checkpoint-312/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-rte/checkpoint-312/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-rte/checkpoint-312/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-rte/checkpoint-312/special_tokens_map.json\n",
            " 60% 468/780 [03:54<02:13,  2.33it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2. If sentence1, idx, sentence2 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:01, 13.92it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01,  7.87it/s]\u001b[A\n",
            " 28% 5/18 [00:00<00:01,  7.47it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  6.92it/s]\u001b[A\n",
            " 39% 7/18 [00:00<00:01,  6.24it/s]\u001b[A\n",
            " 44% 8/18 [00:01<00:01,  6.06it/s]\u001b[A\n",
            " 50% 9/18 [00:01<00:01,  6.51it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:01,  6.56it/s]\u001b[A\n",
            " 61% 11/18 [00:01<00:01,  6.95it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  7.03it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  6.59it/s]\u001b[A\n",
            " 78% 14/18 [00:02<00:00,  6.15it/s]\u001b[A\n",
            " 83% 15/18 [00:02<00:00,  5.99it/s]\u001b[A\n",
            " 89% 16/18 [00:02<00:00,  5.37it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.772047758102417, 'eval_accuracy': 0.6425992779783394, 'eval_runtime': 2.8841, 'eval_samples_per_second': 96.045, 'eval_steps_per_second': 6.241, 'epoch': 3.0}\n",
            " 60% 468/780 [03:57<02:13,  2.33it/s]\n",
            "100% 18/18 [00:02<00:00,  5.31it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-rte/checkpoint-468\n",
            "Configuration saved in bert-base-uncased-finetuned-rte/checkpoint-468/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-rte/checkpoint-468/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-rte/checkpoint-468/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-rte/checkpoint-468/special_tokens_map.json\n",
            "{'loss': 0.5214, 'learning_rate': 7.17948717948718e-06, 'epoch': 3.21}\n",
            " 80% 624/780 [05:16<01:10,  2.23it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2. If sentence1, idx, sentence2 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:01, 14.20it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01,  7.79it/s]\u001b[A\n",
            " 28% 5/18 [00:00<00:01,  7.29it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  6.86it/s]\u001b[A\n",
            " 39% 7/18 [00:00<00:01,  6.25it/s]\u001b[A\n",
            " 44% 8/18 [00:01<00:01,  6.08it/s]\u001b[A\n",
            " 50% 9/18 [00:01<00:01,  6.45it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:01,  6.47it/s]\u001b[A\n",
            " 61% 11/18 [00:01<00:01,  6.85it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  7.02it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  6.59it/s]\u001b[A\n",
            " 78% 14/18 [00:02<00:00,  6.17it/s]\u001b[A\n",
            " 83% 15/18 [00:02<00:00,  6.03it/s]\u001b[A\n",
            " 89% 16/18 [00:02<00:00,  5.34it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.9367539286613464, 'eval_accuracy': 0.6534296028880866, 'eval_runtime': 2.8977, 'eval_samples_per_second': 95.595, 'eval_steps_per_second': 6.212, 'epoch': 4.0}\n",
            " 80% 624/780 [05:18<01:10,  2.23it/s]\n",
            "100% 18/18 [00:02<00:00,  5.29it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-rte/checkpoint-624\n",
            "Configuration saved in bert-base-uncased-finetuned-rte/checkpoint-624/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-rte/checkpoint-624/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-rte/checkpoint-624/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-rte/checkpoint-624/special_tokens_map.json\n",
            "100% 780/780 [06:38<00:00,  2.24it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2. If sentence1, idx, sentence2 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:01, 14.52it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01,  7.90it/s]\u001b[A\n",
            " 28% 5/18 [00:00<00:01,  7.39it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  6.82it/s]\u001b[A\n",
            " 39% 7/18 [00:00<00:01,  6.21it/s]\u001b[A\n",
            " 44% 8/18 [00:01<00:01,  6.11it/s]\u001b[A\n",
            " 50% 9/18 [00:01<00:01,  6.48it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:01,  6.50it/s]\u001b[A\n",
            " 61% 11/18 [00:01<00:01,  6.88it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  6.98it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  6.55it/s]\u001b[A\n",
            " 78% 14/18 [00:02<00:00,  6.09it/s]\u001b[A\n",
            " 83% 15/18 [00:02<00:00,  6.02it/s]\u001b[A\n",
            " 89% 16/18 [00:02<00:00,  5.34it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 1.0746842622756958, 'eval_accuracy': 0.6570397111913358, 'eval_runtime': 2.9029, 'eval_samples_per_second': 95.423, 'eval_steps_per_second': 6.201, 'epoch': 5.0}\n",
            "100% 780/780 [06:41<00:00,  2.24it/s]\n",
            "100% 18/18 [00:02<00:00,  5.28it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to bert-base-uncased-finetuned-rte/checkpoint-780\n",
            "Configuration saved in bert-base-uncased-finetuned-rte/checkpoint-780/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-rte/checkpoint-780/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-rte/checkpoint-780/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-rte/checkpoint-780/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from bert-base-uncased-finetuned-rte/checkpoint-780 (score: 0.6570397111913358).\n",
            "{'train_runtime': 406.3773, 'train_samples_per_second': 30.637, 'train_steps_per_second': 1.919, 'train_loss': 0.396820934002216, 'epoch': 5.0}\n",
            "100% 780/780 [06:46<00:00,  2.24it/s]Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/content/bert-vs-fnet/bert-base-uncased-finetuned-rte is already a clone of https://huggingface.co/Joqsan/bert-base-uncased-finetuned-rte. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-vs-fnet/bert-base-uncased-finetuned-rte is already a clone of https://huggingface.co/Joqsan/bert-base-uncased-finetuned-rte. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Saving model checkpoint to /tmp/tmpruzfpx5d\n",
            "Configuration saved in /tmp/tmpruzfpx5d/config.json\n",
            "Model weights saved in /tmp/tmpruzfpx5d/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmpruzfpx5d/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmpruzfpx5d/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-rte\n",
            "Configuration saved in bert-base-uncased-finetuned-rte/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-rte/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-rte/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-rte/special_tokens_map.json\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Upload file pytorch_model.bin:   0% 32.0k/418M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "Upload file pytorch_model.bin:   0% 608k/418M [00:01<12:22, 589kB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 5.81M/418M [00:02<02:05, 3.46MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   3% 14.3M/418M [00:03<01:11, 5.95MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 23.4M/418M [00:04<00:56, 7.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 32.1M/418M [00:05<00:50, 7.96MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 40.7M/418M [00:06<00:47, 8.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  12% 49.8M/418M [00:07<00:44, 8.74MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 59.1M/418M [00:08<00:41, 9.05MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 68.6M/418M [00:09<00:39, 9.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  19% 77.7M/418M [00:10<00:38, 9.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 86.6M/418M [00:11<00:37, 9.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 95.6M/418M [00:12<00:36, 9.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  25% 105M/418M [00:13<00:35, 9.37MB/s] \u001b[A\n",
            "Upload file pytorch_model.bin:  27% 114M/418M [00:14<00:34, 9.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  29% 123M/418M [00:15<00:32, 9.43MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  32% 132M/418M [00:16<00:31, 9.57MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  34% 141M/418M [00:17<00:30, 9.57MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  36% 150M/418M [00:18<00:29, 9.53MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 160M/418M [00:19<00:28, 9.63MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 169M/418M [00:20<00:26, 9.67MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  43% 178M/418M [00:21<00:25, 9.68MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 188M/418M [00:22<00:24, 9.74MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 197M/418M [00:23<00:23, 9.74MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  49% 207M/418M [00:24<00:22, 9.82MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 216M/418M [00:25<00:21, 9.85MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 226M/418M [00:26<00:20, 9.84MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 235M/418M [00:27<00:19, 9.78MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 244M/418M [00:28<00:18, 9.72MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 253M/418M [00:29<00:17, 9.73MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  63% 262M/418M [00:30<00:16, 9.71MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  65% 272M/418M [00:31<00:15, 9.78MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 282M/418M [00:32<00:14, 9.92MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  70% 291M/418M [00:33<00:13, 9.94MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 300M/418M [00:34<00:12, 9.78MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 309M/418M [00:35<00:11, 9.69MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  76% 318M/418M [00:36<00:10, 9.64MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 328M/418M [00:37<00:09, 9.64MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  81% 337M/418M [00:38<00:08, 9.69MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 346M/418M [00:39<00:07, 9.68MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  85% 356M/418M [00:40<00:06, 9.76MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 365M/418M [00:41<00:05, 9.71MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  90% 374M/418M [00:42<00:04, 9.65MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 383M/418M [00:43<00:03, 9.56MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 392M/418M [00:44<00:02, 9.68MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 402M/418M [00:45<00:01, 9.72MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  98% 411M/418M [00:46<00:00, 9.76MB/s]\u001b[Aremote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-rte\n",
            "   bca9a86..c9a01bb  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-rte\n",
            "   bca9a86..c9a01bb  main -> main\n",
            "\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 418M/418M [00:49<00:00, 5.54MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 418M/418M [00:49<00:00, 8.92MB/s]\n",
            "\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:49<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.50k/3.50k [00:49<?, ?B/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-rte\n",
            "   c9a01bb..eba3089  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/Joqsan/bert-base-uncased-finetuned-rte\n",
            "   c9a01bb..eba3089  main -> main\n",
            "\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Logging model artifacts. ...\n",
            "100% 780/780 [08:30<00:00,  1.53it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▁▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▁▁▂▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▁▄▅▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second █▅▄▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second █▅▄▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▃▅▅▆██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▃▅▅▆██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.65704\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 1.07468\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 2.9029\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 95.423\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 6.201\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 780\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.5214\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1046969250377880.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.39682\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 406.3773\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 30.637\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 1.919\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbert-base-uncased-rte\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/12mjp8g4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230130_181327-12mjp8g4/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/fine_tuning.py Joqsan/custom-fnet rte"
      ],
      "metadata": {
        "id": "nfhGWPsnKTKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd41d1c-b212-4ca1-da5a-6b7b8a97879a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100% 3/3 [00:00<00:00, 114.14it/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f46263219b6ef93d.arrow\n",
            "100% 1/1 [00:00<00:00, 16.44ba/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-94f437e395c48c32.arrow\n",
            "Some weights of MyFNetForSequenceClassification were not initialized from the model checkpoint at Joqsan/custom-fnet and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "models/fine_tuning.py:86: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"glue\", actual_task)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoqsan-a\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/bert-vs-fnet/wandb/run-20230130_182415-i8dwh3c6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcustom-fnet-rte\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/i8dwh3c6\u001b[0m\n",
            "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Cloning https://huggingface.co/Joqsan/custom-fnet-finetuned-rte into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/Joqsan/custom-fnet-finetuned-rte into local empty directory.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "The following columns in the training set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: sentence2, sentence1, idx. If sentence2, sentence1, idx are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 2490\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 780\n",
            "  Number of trainable parameters = 88222466\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "  0% 0/780 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            " 20% 156/780 [00:56<03:46,  2.76it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: sentence2, sentence1, idx. If sentence2, sentence1, idx are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:00, 17.06it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01, 10.11it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  9.00it/s]\u001b[A\n",
            " 39% 7/18 [00:00<00:01,  8.40it/s]\u001b[A\n",
            " 44% 8/18 [00:00<00:01,  8.15it/s]\u001b[A\n",
            " 50% 9/18 [00:01<00:01,  8.51it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:00,  8.54it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  9.12it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  8.65it/s]\u001b[A\n",
            " 78% 14/18 [00:01<00:00,  8.04it/s]\u001b[A\n",
            " 83% 15/18 [00:01<00:00,  7.87it/s]\u001b[A\n",
            " 89% 16/18 [00:01<00:00,  7.18it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7068780660629272, 'eval_accuracy': 0.4729241877256318, 'eval_runtime': 2.2295, 'eval_samples_per_second': 124.244, 'eval_steps_per_second': 8.074, 'epoch': 1.0}\n",
            " 20% 156/780 [00:58<03:46,  2.76it/s]\n",
            "100% 18/18 [00:02<00:00,  7.11it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-rte/checkpoint-156\n",
            "Configuration saved in custom-fnet-finetuned-rte/checkpoint-156/config.json\n",
            "Model weights saved in custom-fnet-finetuned-rte/checkpoint-156/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-rte/checkpoint-156/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-rte/checkpoint-156/special_tokens_map.json\n",
            " 40% 312/780 [01:56<02:35,  3.00it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: sentence2, sentence1, idx. If sentence2, sentence1, idx are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:00, 17.80it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01, 10.34it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  9.20it/s]\u001b[A\n",
            " 44% 8/18 [00:00<00:01,  8.27it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:00,  8.58it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  8.96it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  8.69it/s]\u001b[A\n",
            " 78% 14/18 [00:01<00:00,  8.22it/s]\u001b[A\n",
            " 83% 15/18 [00:01<00:00,  8.04it/s]\u001b[A\n",
            " 89% 16/18 [00:01<00:00,  7.33it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.691705048084259, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 2.2121, 'eval_samples_per_second': 125.221, 'eval_steps_per_second': 8.137, 'epoch': 2.0}\n",
            " 40% 312/780 [01:59<02:35,  3.00it/s]\n",
            "100% 18/18 [00:02<00:00,  7.25it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-rte/checkpoint-312\n",
            "Configuration saved in custom-fnet-finetuned-rte/checkpoint-312/config.json\n",
            "Model weights saved in custom-fnet-finetuned-rte/checkpoint-312/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-rte/checkpoint-312/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-rte/checkpoint-312/special_tokens_map.json\n",
            " 60% 468/780 [02:57<01:41,  3.08it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: sentence2, sentence1, idx. If sentence2, sentence1, idx are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:00, 18.01it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01, 10.46it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  9.24it/s]\u001b[A\n",
            " 44% 8/18 [00:00<00:01,  8.31it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:00,  8.62it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  9.01it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  8.72it/s]\u001b[A\n",
            " 78% 14/18 [00:01<00:00,  8.23it/s]\u001b[A\n",
            " 83% 15/18 [00:01<00:00,  8.08it/s]\u001b[A\n",
            " 89% 16/18 [00:01<00:00,  7.37it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.69377201795578, 'eval_accuracy': 0.4729241877256318, 'eval_runtime': 2.1903, 'eval_samples_per_second': 126.466, 'eval_steps_per_second': 8.218, 'epoch': 3.0}\n",
            " 60% 468/780 [02:59<01:41,  3.08it/s]\n",
            "100% 18/18 [00:02<00:00,  7.33it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-rte/checkpoint-468\n",
            "Configuration saved in custom-fnet-finetuned-rte/checkpoint-468/config.json\n",
            "Model weights saved in custom-fnet-finetuned-rte/checkpoint-468/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-rte/checkpoint-468/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-rte/checkpoint-468/special_tokens_map.json\n",
            "{'loss': 0.701, 'learning_rate': 7.17948717948718e-06, 'epoch': 3.21}\n",
            " 80% 624/780 [03:59<00:53,  2.92it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: sentence2, sentence1, idx. If sentence2, sentence1, idx are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:00, 18.13it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01, 10.28it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  9.20it/s]\u001b[A\n",
            " 44% 8/18 [00:00<00:01,  8.27it/s]\u001b[A\n",
            " 50% 9/18 [00:00<00:01,  8.55it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:00,  8.50it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  9.06it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  8.74it/s]\u001b[A\n",
            " 78% 14/18 [00:01<00:00,  8.22it/s]\u001b[A\n",
            " 83% 15/18 [00:01<00:00,  8.03it/s]\u001b[A\n",
            " 89% 16/18 [00:01<00:00,  7.29it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.6935849785804749, 'eval_accuracy': 0.48014440433212996, 'eval_runtime': 2.2033, 'eval_samples_per_second': 125.718, 'eval_steps_per_second': 8.169, 'epoch': 4.0}\n",
            " 80% 624/780 [04:01<00:53,  2.92it/s]\n",
            "100% 18/18 [00:02<00:00,  7.26it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-rte/checkpoint-624\n",
            "Configuration saved in custom-fnet-finetuned-rte/checkpoint-624/config.json\n",
            "Model weights saved in custom-fnet-finetuned-rte/checkpoint-624/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-rte/checkpoint-624/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-rte/checkpoint-624/special_tokens_map.json\n",
            "100% 780/780 [05:00<00:00,  2.95it/s]The following columns in the evaluation set don't have a corresponding argument in `MyFNetForSequenceClassification.forward` and have been ignored: sentence2, sentence1, idx. If sentence2, sentence1, idx are not expected by `MyFNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 277\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/18 [00:00<00:00, 18.55it/s]\u001b[A\n",
            " 22% 4/18 [00:00<00:01, 10.44it/s]\u001b[A\n",
            " 33% 6/18 [00:00<00:01,  9.24it/s]\u001b[A\n",
            " 44% 8/18 [00:00<00:01,  8.31it/s]\u001b[A\n",
            " 50% 9/18 [00:00<00:01,  8.63it/s]\u001b[A\n",
            " 56% 10/18 [00:01<00:00,  8.62it/s]\u001b[A\n",
            " 67% 12/18 [00:01<00:00,  9.10it/s]\u001b[A\n",
            " 72% 13/18 [00:01<00:00,  8.78it/s]\u001b[A\n",
            " 78% 14/18 [00:01<00:00,  8.19it/s]\u001b[A\n",
            " 83% 15/18 [00:01<00:00,  8.02it/s]\u001b[A\n",
            " 89% 16/18 [00:01<00:00,  7.31it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.6931568384170532, 'eval_accuracy': 0.48375451263537905, 'eval_runtime': 2.1892, 'eval_samples_per_second': 126.529, 'eval_steps_per_second': 8.222, 'epoch': 5.0}\n",
            "100% 780/780 [05:03<00:00,  2.95it/s]\n",
            "100% 18/18 [00:02<00:00,  7.31it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to custom-fnet-finetuned-rte/checkpoint-780\n",
            "Configuration saved in custom-fnet-finetuned-rte/checkpoint-780/config.json\n",
            "Model weights saved in custom-fnet-finetuned-rte/checkpoint-780/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-rte/checkpoint-780/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-rte/checkpoint-780/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from custom-fnet-finetuned-rte/checkpoint-312 (score: 0.5270758122743683).\n",
            "{'train_runtime': 308.7479, 'train_samples_per_second': 40.324, 'train_steps_per_second': 2.526, 'train_loss': 0.7002730149489182, 'epoch': 5.0}\n",
            "100% 780/780 [05:08<00:00,  2.95it/s]Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/content/bert-vs-fnet/custom-fnet-finetuned-rte is already a clone of https://huggingface.co/Joqsan/custom-fnet-finetuned-rte. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-vs-fnet/custom-fnet-finetuned-rte is already a clone of https://huggingface.co/Joqsan/custom-fnet-finetuned-rte. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Saving model checkpoint to /tmp/tmp_8br2jat\n",
            "Configuration saved in /tmp/tmp_8br2jat/config.json\n",
            "Model weights saved in /tmp/tmp_8br2jat/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmp_8br2jat/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmp_8br2jat/special_tokens_map.json\n",
            "Saving model checkpoint to custom-fnet-finetuned-rte\n",
            "Configuration saved in custom-fnet-finetuned-rte/config.json\n",
            "Model weights saved in custom-fnet-finetuned-rte/pytorch_model.bin\n",
            "tokenizer config file saved in custom-fnet-finetuned-rte/tokenizer_config.json\n",
            "Special tokens file saved in custom-fnet-finetuned-rte/special_tokens_map.json\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "Upload file pytorch_model.bin:   0% 32.0k/337M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.43k/3.43k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "Upload file pytorch_model.bin:   0% 608k/337M [00:01<09:58, 589kB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   2% 6.38M/337M [00:02<01:31, 3.80MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   5% 15.3M/337M [00:03<00:53, 6.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 24.5M/337M [00:04<00:42, 7.64MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 33.7M/337M [00:05<00:38, 8.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  13% 42.6M/337M [00:06<00:35, 8.67MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 51.8M/337M [00:07<00:33, 8.97MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 60.6M/337M [00:08<00:31, 9.06MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 69.6M/337M [00:09<00:30, 9.16MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 78.4M/337M [00:10<00:29, 9.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  26% 87.3M/337M [00:11<00:28, 9.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  29% 96.4M/337M [00:12<00:27, 9.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 105M/337M [00:13<00:25, 9.35MB/s] \u001b[A\n",
            "Upload file pytorch_model.bin:  34% 114M/337M [00:14<00:25, 9.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 123M/337M [00:15<00:23, 9.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 132M/337M [00:16<00:22, 9.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 141M/337M [00:17<00:21, 9.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 150M/337M [00:18<00:21, 9.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 159M/337M [00:19<00:20, 9.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 167M/337M [00:20<00:19, 9.23MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 176M/337M [00:21<00:18, 9.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  55% 185M/337M [00:22<00:16, 9.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 195M/337M [00:23<00:15, 9.45MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 204M/337M [00:24<00:14, 9.52MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  63% 213M/337M [00:25<00:13, 9.57MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 222M/337M [00:26<00:12, 9.56MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 232M/337M [00:27<00:11, 9.62MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 241M/337M [00:28<00:10, 9.61MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 250M/337M [00:29<00:09, 9.67MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 260M/337M [00:30<00:08, 9.76MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  80% 270M/337M [00:31<00:07, 9.91MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 279M/337M [00:32<00:06, 9.92MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 288M/337M [00:33<00:05, 9.82MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  88% 297M/337M [00:34<00:04, 9.65MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 306M/337M [00:35<00:03, 9.56MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 315M/337M [00:36<00:02, 9.44MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 324M/337M [00:37<00:01, 9.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  99% 332M/337M [00:38<00:00, 9.34MB/s]\u001b[Aremote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/custom-fnet-finetuned-rte\n",
            "   7df87f2..5ef3fa3  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Joqsan/custom-fnet-finetuned-rte\n",
            "   7df87f2..5ef3fa3  main -> main\n",
            "\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 337M/337M [00:41<00:00, 4.91MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 337M/337M [00:41<00:00, 8.59MB/s]\n",
            "\n",
            "\n",
            "Upload file training_args.bin: 100% 3.43k/3.43k [00:41<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Upload file training_args.bin: 100% 3.43k/3.43k [00:41<?, ?B/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "To https://huggingface.co/Joqsan/custom-fnet-finetuned-rte\n",
            "   5ef3fa3..f441ba7  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/Joqsan/custom-fnet-finetuned-rte\n",
            "   5ef3fa3..f441ba7  main -> main\n",
            "\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Logging model artifacts. ...\n",
            "100% 780/780 [06:42<00:00,  1.94it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▁█▁▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▁▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▅▁▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁▄█▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁▄█▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▃▅▅▆██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▃▅▅▆██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.48375\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.69316\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 2.1892\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 126.529\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 8.222\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 780\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.701\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 787069356630168.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.70027\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 308.7479\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 40.324\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 2.526\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcustom-fnet-rte\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/joqsan-a/comparison-bert-fnet/runs/i8dwh3c6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230130_182415-i8dwh3c6/logs\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}